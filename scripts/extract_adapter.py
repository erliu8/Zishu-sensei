#!/usr/bin/env python3
"""
é€‚é…å™¨è§£å‹å’Œé›†æˆè„šæœ¬
å¤„ç† zishu-base-adapter çš„è§£å‹ã€éªŒè¯å’Œé›†æˆ
"""

import os
import tarfile
import shutil
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional
import hashlib

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class AdapterExtractor:
    """é€‚é…å™¨è§£å‹å™¨"""
    
    def __init__(self, project_root: Optional[Path] = None):
        """
        åˆå§‹åŒ–é€‚é…å™¨è§£å‹å™¨
        
        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•ï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹
        """
        if project_root is None:
            # è‡ªåŠ¨æ£€æµ‹é¡¹ç›®æ ¹ç›®å½•
            current_dir = Path(__file__).resolve()
            for parent in current_dir.parents:
                if (parent / "requirements.txt").exists():
                    project_root = parent
                    break
            else:
                project_root = current_dir.parent.parent
                
        self.project_root = Path(project_root)
        self.models_dir = self.project_root / "models"
        self.extracted_dir = self.models_dir / "extracted"
        self.config_dir = self.project_root / "configs"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.extracted_dir.mkdir(parents=True, exist_ok=True)
        self.config_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"Project root: {self.project_root}")
        logger.info(f"Models dir: {self.models_dir}")
        logger.info(f"Extracted dir: {self.extracted_dir}")

    def find_adapter_archive(self, pattern: str = "zishu-base-adapter*.tar.gz") -> Optional[Path]:
        """
        æŸ¥æ‰¾é€‚é…å™¨å‹ç¼©æ–‡ä»¶
        
        Args:
            pattern: æ–‡ä»¶ååŒ¹é…æ¨¡å¼
            
        Returns:
            æ‰¾åˆ°çš„å‹ç¼©æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæ²¡æ‰¾åˆ°åˆ™è¿”å›None
        """
        import glob
        
        search_paths = [
            self.models_dir,
            self.models_dir / "zishu-base",
            self.project_root,
        ]
        
        for search_dir in search_paths:
            if not search_dir.exists():
                continue
                
            matches = list(search_dir.glob(pattern))
            if matches:
                archive_path = matches[0]  # å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„æ–‡ä»¶
                logger.info(f"Found adapter archive: {archive_path}")
                logger.info(f"Archive size: {archive_path.stat().st_size / (1024*1024):.1f} MB")
                return archive_path
                
        logger.error(f"No adapter archive found with pattern: {pattern}")
        return None

    def calculate_file_hash(self, file_path: Path, algorithm: str = "sha256") -> str:
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼"""
        hasher = getattr(hashlib, algorithm)()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(8192), b""):
                hasher.update(chunk)
        return hasher.hexdigest()

    def extract_adapter(self, archive_path: Path, target_name: str = "zishu-base") -> Dict[str, Any]:
        """
        è§£å‹é€‚é…å™¨æ–‡ä»¶
        
        Args:
            archive_path: å‹ç¼©æ–‡ä»¶è·¯å¾„
            target_name: ç›®æ ‡é€‚é…å™¨åç§°
            
        Returns:
            è§£å‹ç»“æœä¿¡æ¯
        """
        logger.info(f"Starting to extract adapter: {archive_path}")
        
        # åˆ›å»ºç›®æ ‡ç›®å½•
        target_dir = self.extracted_dir / target_name
        if target_dir.exists():
            logger.warning(f"Target directory exists, removing: {target_dir}")
            shutil.rmtree(target_dir)
            
        target_dir.mkdir(parents=True)
        
        try:
            # éªŒè¯å‹ç¼©æ–‡ä»¶
            if not tarfile.is_tarfile(archive_path):
                raise ValueError(f"Invalid tar file: {archive_path}")
                
            # è®¡ç®—åŸæ–‡ä»¶å“ˆå¸Œ
            original_hash = self.calculate_file_hash(archive_path)
            
            # è§£å‹æ–‡ä»¶
            extracted_files = []
            with tarfile.open(archive_path, "r:gz") as tar:
                # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢ç›®å½•éå†æ”»å‡»
                members = tar.getmembers()
                for member in members:
                    if not self._is_safe_path(member.name):
                        logger.warning(f"Skipping unsafe path: {member.name}")
                        continue
                        
                    tar.extract(member, target_dir)
                    extracted_files.append(member.name)
                    
            logger.info(f"Extracted {len(extracted_files)} files to: {target_dir}")
            
            # éªŒè¯è§£å‹ç»“æœ
            validation_result = self._validate_extracted_adapter(target_dir)
            
            # ç”Ÿæˆé€‚é…å™¨é…ç½®
            adapter_config = self._generate_adapter_config(
                target_name, target_dir, archive_path, original_hash, validation_result
            )
            
            # ä¿å­˜é€‚é…å™¨é…ç½®
            config_file = self.config_dir / f"{target_name}_adapter.json"
            with open(config_file, "w", encoding="utf-8") as f:
                json.dump(adapter_config, f, indent=2, ensure_ascii=False)
                
            logger.info(f"Adapter configuration saved: {config_file}")
            
            return {
                "success": True,
                "adapter_name": target_name,
                "adapter_path": str(target_dir),
                "config_file": str(config_file),
                "extracted_files_count": len(extracted_files),
                "validation_result": validation_result,
                "original_hash": original_hash
            }
            
        except Exception as e:
            logger.error(f"Failed to extract adapter: {e}")
            # æ¸…ç†å¤±è´¥çš„è§£å‹ç›®å½•
            if target_dir.exists():
                shutil.rmtree(target_dir)
            raise

    def _is_safe_path(self, path: str) -> bool:
        """æ£€æŸ¥è·¯å¾„æ˜¯å¦å®‰å…¨ï¼ˆé˜²æ­¢ç›®å½•éå†æ”»å‡»ï¼‰"""
        return not (path.startswith("/") or ".." in path)

    def _validate_extracted_adapter(self, adapter_dir: Path) -> Dict[str, Any]:
        """
        éªŒè¯è§£å‹çš„é€‚é…å™¨æ–‡ä»¶
        
        Args:
            adapter_dir: é€‚é…å™¨ç›®å½•
            
        Returns:
            éªŒè¯ç»“æœ
        """
        logger.info(f"Validating extracted adapter: {adapter_dir}")
        
        validation_result = {
            "valid": True,
            "errors": [],
            "warnings": [],
            "files": {},
            "structure": {}
        }
        
        try:
            # æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶
            required_files = [
                "adapter_config.json",
                "adapter_model.safetensors",
                "pytorch_model.bin",
            ]
            
            optional_files = [
                "config.json",
                "tokenizer.json",
                "tokenizer_config.json",
                "special_tokens_map.json",
                "README.md"
            ]
            
            all_files = list(adapter_dir.rglob("*"))
            existing_files = {f.name: str(f) for f in all_files if f.is_file()}
            
            validation_result["files"]["total_count"] = len(all_files)
            validation_result["files"]["file_list"] = list(existing_files.keys())
            
            # æ£€æŸ¥å¿…è¦æ–‡ä»¶
            for required_file in required_files:
                if not any(f.name == required_file for f in all_files):
                    validation_result["warnings"].append(f"Required file missing: {required_file}")
            
            # æ£€æŸ¥å¯é€‰æ–‡ä»¶
            for optional_file in optional_files:
                if any(f.name == optional_file for f in all_files):
                    validation_result["structure"][optional_file] = "found"
                else:
                    validation_result["structure"][optional_file] = "missing"
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            total_size = sum(f.stat().st_size for f in all_files if f.is_file())
            validation_result["files"]["total_size_mb"] = round(total_size / (1024*1024), 2)
            
            # æ£€æŸ¥é…ç½®æ–‡ä»¶
            config_files = [f for f in all_files if f.name.endswith('.json')]
            for config_file in config_files:
                try:
                    with open(config_file, 'r', encoding='utf-8') as f:
                        config_data = json.load(f)
                    validation_result["structure"][config_file.name] = {
                        "status": "valid_json",
                        "keys": list(config_data.keys()) if isinstance(config_data, dict) else "not_dict"
                    }
                except Exception as e:
                    validation_result["errors"].append(f"Invalid JSON in {config_file.name}: {str(e)}")
                    validation_result["structure"][config_file.name] = {"status": "invalid_json", "error": str(e)}
            
            # å¦‚æœæœ‰é”™è¯¯ï¼Œè®¾ç½®éªŒè¯å¤±è´¥
            if validation_result["errors"]:
                validation_result["valid"] = False
                
            logger.info(f"Validation completed. Valid: {validation_result['valid']}")
            logger.info(f"Files: {validation_result['files']['total_count']}, Size: {validation_result['files']['total_size_mb']} MB")
            
            return validation_result
            
        except Exception as e:
            logger.error(f"Validation failed: {e}")
            validation_result["valid"] = False
            validation_result["errors"].append(f"Validation error: {str(e)}")
            return validation_result

    def _generate_adapter_config(
        self, 
        adapter_name: str, 
        adapter_path: Path, 
        original_archive: Path,
        original_hash: str,
        validation_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ç”Ÿæˆé€‚é…å™¨é…ç½®"""
        
        from datetime import datetime
        
        return {
            "adapter_info": {
                "name": adapter_name,
                "version": "1.0.0",
                "type": "lora_adapter",
                "created_at": datetime.now().isoformat(),
                "description": "Zishu-sensei base adapter - å®³ç¾å¯çˆ±çš„AIåŠ©æ‰‹"
            },
            "paths": {
                "adapter_dir": str(adapter_path),
                "original_archive": str(original_archive),
                "config_file": str(self.config_dir / f"{adapter_name}_adapter.json")
            },
            "validation": validation_result,
            "security": {
                "original_hash": original_hash,
                "algorithm": "sha256"
            },
            "model_config": {
                "base_model": "Qwen/Qwen2.5-7B-Instruct",  # å‡è®¾çš„åŸºç¡€æ¨¡å‹
                "task_type": "CAUSAL_LM",
                "peft_type": "LORA",
                "inference_mode": False
            },
            "character_config": {
                "name": "ç´«èˆ’è€å¸ˆ", 
                "personality": "æ¸©æŸ”ã€è€å¿ƒã€å®³ç¾ã€æœ‰è´£ä»»å¿ƒ",
                "default_emotion": "neutral",
                "available_emotions": ["happy", "sad", "neutral", "shy", "excited"]
            },
            "usage": {
                "load_command": f"adapter_manager.load_adapter('{adapter_name}')",
                "api_endpoint": f"/models/load",
                "supported_tasks": ["chat", "emotion_chat", "roleplay"]
            }
        }

    def list_extracted_adapters(self) -> Dict[str, Any]:
        """åˆ—å‡ºæ‰€æœ‰å·²è§£å‹çš„é€‚é…å™¨"""
        adapters = {}
        
        if not self.extracted_dir.exists():
            return adapters
            
        for adapter_dir in self.extracted_dir.iterdir():
            if adapter_dir.is_dir():
                config_file = self.config_dir / f"{adapter_dir.name}_adapter.json"
                
                adapter_info = {
                    "name": adapter_dir.name,
                    "path": str(adapter_dir),
                    "config_exists": config_file.exists()
                }
                
                # è¯»å–é…ç½®æ–‡ä»¶ä¿¡æ¯
                if config_file.exists():
                    try:
                        with open(config_file, "r", encoding="utf-8") as f:
                            config_data = json.load(f)
                        adapter_info["config"] = config_data.get("adapter_info", {})
                        adapter_info["character"] = config_data.get("character_config", {})
                        adapter_info["validation"] = config_data.get("validation", {})
                    except Exception as e:
                        adapter_info["config_error"] = str(e)
                
                adapters[adapter_dir.name] = adapter_info
                
        return adapters


def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œé€‚é…å™¨è§£å‹æµç¨‹"""
    
    print("ğŸš€ Zishu-sensei é€‚é…å™¨è§£å‹å’Œé›†æˆè„šæœ¬")
    print("=" * 50)
    
    try:
        # åˆ›å»ºè§£å‹å™¨
        extractor = AdapterExtractor()
        
        # æŸ¥æ‰¾é€‚é…å™¨æ–‡ä»¶
        archive_path = extractor.find_adapter_archive()
        if not archive_path:
            print("âŒ æœªæ‰¾åˆ°é€‚é…å™¨å‹ç¼©æ–‡ä»¶")
            print("è¯·ç¡®ä¿ zishu-base-adapter_*.tar.gz æ–‡ä»¶åœ¨ä»¥ä¸‹ç›®å½•ä¹‹ä¸€ï¼š")
            print(f"  - {extractor.models_dir}")
            print(f"  - {extractor.models_dir}/zishu-base/")
            print(f"  - {extractor.project_root}")
            return False
            
        print(f"âœ… æ‰¾åˆ°é€‚é…å™¨æ–‡ä»¶: {archive_path}")
        
        # è§£å‹é€‚é…å™¨
        print("\nğŸ“¦ å¼€å§‹è§£å‹é€‚é…å™¨...")
        result = extractor.extract_adapter(archive_path)
        
        if result["success"]:
            print("âœ… é€‚é…å™¨è§£å‹æˆåŠŸ!")
            print(f"   é€‚é…å™¨åç§°: {result['adapter_name']}")
            print(f"   è§£å‹è·¯å¾„: {result['adapter_path']}")
            print(f"   é…ç½®æ–‡ä»¶: {result['config_file']}")
            print(f"   æ–‡ä»¶æ•°é‡: {result['extracted_files_count']}")
            print(f"   éªŒè¯çŠ¶æ€: {'é€šè¿‡' if result['validation_result']['valid'] else 'å¤±è´¥'}")
            
            if result['validation_result']['warnings']:
                print(f"   è­¦å‘Šæ•°é‡: {len(result['validation_result']['warnings'])}")
                
        else:
            print("âŒ é€‚é…å™¨è§£å‹å¤±è´¥!")
            return False
            
        # åˆ—å‡ºæ‰€æœ‰é€‚é…å™¨
        print("\nğŸ“‹ å½“å‰å¯ç”¨çš„é€‚é…å™¨:")
        adapters = extractor.list_extracted_adapters()
        
        if not adapters:
            print("   (æ²¡æœ‰æ‰¾åˆ°å·²è§£å‹çš„é€‚é…å™¨)")
        else:
            for name, info in adapters.items():
                print(f"   - {name}")
                if "character" in info:
                    char_info = info["character"]
                    print(f"     è§’è‰²: {char_info.get('name', 'Unknown')}")
                    print(f"     æ€§æ ¼: {char_info.get('personality', 'Unknown')}")
                    
        print("\nğŸ‰ é€‚é…å™¨é›†æˆå®Œæˆ!")
        print("ç°åœ¨å¯ä»¥é€šè¿‡ AdapterManager åŠ è½½å’Œä½¿ç”¨é€‚é…å™¨äº†")
        
        return True
        
    except Exception as e:
        logger.error(f"Extraction failed: {e}")
        print(f"âŒ è§£å‹è¿‡ç¨‹å‡ºé”™: {e}")
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
