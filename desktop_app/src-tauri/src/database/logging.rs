//! # æ—¥å¿—è®°å½•æ•°æ®åº“æ¨¡å— (PostgreSQL)
//! 
//! æä¾›ç»“æ„åŒ–æ—¥å¿—å­˜å‚¨ã€æŸ¥è¯¢ã€ç»Ÿè®¡å’Œè‡ªåŠ¨æ¸…ç†åŠŸèƒ½

use serde::{Deserialize, Serialize};
use crate::database::DbPool;
use tracing::{info, error, warn, debug};
use chrono::Utc;
use std::collections::HashMap;

// ================================
// æ•°æ®ç»“æ„å®šä¹‰
// ================================

/// æ—¥å¿—çº§åˆ«
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "lowercase")]
pub enum LogLevel {
    Trace,
    Debug,
    Info,
    Warn,
    Error,
    Fatal,
}

impl std::fmt::Display for LogLevel {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            LogLevel::Trace => write!(f, "trace"),
            LogLevel::Debug => write!(f, "debug"),
            LogLevel::Info => write!(f, "info"),
            LogLevel::Warn => write!(f, "warn"),
            LogLevel::Error => write!(f, "error"),
            LogLevel::Fatal => write!(f, "fatal"),
        }
    }
}

impl std::str::FromStr for LogLevel {
    type Err = String;
    
    fn from_str(s: &str) -> Result<Self, Self::Err> {
        match s.to_lowercase().as_str() {
            "trace" => Ok(LogLevel::Trace),
            "debug" => Ok(LogLevel::Debug),
            "info" => Ok(LogLevel::Info),
            "warn" => Ok(LogLevel::Warn),
            "error" => Ok(LogLevel::Error),
            "fatal" => Ok(LogLevel::Fatal),
            _ => Err(format!("æ— æ•ˆçš„æ—¥å¿—çº§åˆ«: {}", s)),
        }
    }
}

/// æ—¥å¿—æ¡ç›®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LogEntry {
    pub level: String,
    pub message: String,
    pub module: Option<String>,
    pub timestamp: i64,
}

/// æ‰©å±•æ—¥å¿—æ¡ç›®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LogEntryExtended {
    pub id: i64,
    pub level: String,
    pub message: String,
    pub module: Option<String>,
    pub file: Option<String>,
    pub line: Option<i32>,
    pub thread: Option<String>,
    pub context: Option<String>,
    pub timestamp: String,
}

/// æ—¥å¿—è¿‡æ»¤å™¨
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LogFilter {
    pub level: Option<String>,
    pub module: Option<String>,
    pub start_time: Option<i64>,
    pub end_time: Option<i64>,
    pub keyword: Option<String>,
    pub limit: Option<i32>,
    pub offset: Option<i32>,
}

/// æ—¥å¿—ç»Ÿè®¡
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LogStatistics {
    pub total_logs: i64,
    pub level_counts: HashMap<String, i64>,
    pub module_counts: HashMap<String, i64>,
    pub recent_errors: i64,
    pub recent_warnings: i64,
}

// ================================
// æ—¥å¿—æ³¨å†Œè¡¨
// ================================

pub struct LoggingRegistry {
    pool: DbPool,
}

// Type alias for backward compatibility
pub type LogDatabase = LoggingRegistry;

impl LoggingRegistry {
    pub fn new(pool: DbPool) -> Self {
        Self { pool }
    }

    /// åˆå§‹åŒ–æ•°æ®åº“è¡¨
    pub async fn init_tables(&self) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;

        // åˆ›å»ºæ—¥å¿—è¡¨ï¼ˆæ”¯æŒæ—¶é—´åˆ†åŒºï¼‰
        client.execute(
            "CREATE TABLE IF NOT EXISTS logs (
                id BIGSERIAL PRIMARY KEY,
                level TEXT NOT NULL,
                message TEXT NOT NULL,
                module TEXT,
                file TEXT,
                line INTEGER,
                thread TEXT,
                context TEXT,
                timestamp TIMESTAMP NOT NULL DEFAULT NOW()
            )",
            &[],
        ).await?;

        // åˆ›å»ºç´¢å¼•
        let indexes = vec![
            "CREATE INDEX IF NOT EXISTS idx_logs_level ON logs(level)",
            "CREATE INDEX IF NOT EXISTS idx_logs_module ON logs(module)",
            "CREATE INDEX IF NOT EXISTS idx_logs_timestamp ON logs(timestamp DESC)",
            "CREATE INDEX IF NOT EXISTS idx_logs_level_timestamp ON logs(level, timestamp DESC)",
        ];

        for index_sql in indexes {
            client.execute(index_sql, &[]).await?;
        }

        info!("âœ… æ—¥å¿—è®°å½•è¡¨åˆå§‹åŒ–å®Œæˆ");
        Ok(())
    }

    /// è®°å½•æ—¥å¿—
    pub fn log(&self, entry: LogEntry) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        let handle = tokio::runtime::Handle::current();
        handle.block_on(async {
            self.log_async(entry).await
        })
    }

    /// è®°å½•æ—¥å¿—ï¼ˆå¼‚æ­¥ï¼‰
    pub async fn log_async(&self, entry: LogEntry) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;

        let timestamp = chrono::DateTime::from_timestamp(entry.timestamp, 0)
            .unwrap_or_else(|| Utc::now());

        client.execute(
            "INSERT INTO logs (level, message, module, timestamp)
            VALUES ($1, $2, $3, $4)",
            &[&entry.level, &entry.message, &entry.module, &timestamp],
        ).await?;

        Ok(())
    }

    /// æ‰¹é‡è®°å½•æ—¥å¿—
    pub async fn log_batch_async(&self, entries: Vec<LogEntry>) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        if entries.is_empty() {
            return Ok(());
        }

        let entry_count = entries.len();
        let mut client = self.pool.get().await?;

        // ä½¿ç”¨äº‹åŠ¡æ‰¹é‡æ’å…¥
        let transaction = client.transaction().await?;

        for entry in entries {
            let timestamp = chrono::DateTime::from_timestamp(entry.timestamp, 0)
                .unwrap_or_else(|| Utc::now());

            transaction.execute(
                "INSERT INTO logs (level, message, module, timestamp)
                VALUES ($1, $2, $3, $4)",
                &[&entry.level, &entry.message, &entry.module, &timestamp],
            ).await?;
        }

        transaction.commit().await?;

        debug!("ğŸ“ æ‰¹é‡è®°å½•äº† {} æ¡æ—¥å¿—", entry_count);
        Ok(())
    }

    /// æ‰©å±•æ—¥å¿—è®°å½•
    pub async fn log_extended_async(
        &self,
        level: &str,
        message: &str,
        module: Option<&str>,
        file: Option<&str>,
        line: Option<i32>,
        thread: Option<&str>,
        context: Option<&str>,
    ) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;

        client.execute(
            "INSERT INTO logs (level, message, module, file, line, thread, context, timestamp)
            VALUES ($1, $2, $3, $4, $5, $6, $7, NOW())",
            &[&level, &message, &module, &file, &line, &thread, &context],
        ).await?;

        Ok(())
    }

    /// è·å–æ—¥å¿—
    pub fn get_logs(&self, limit: usize) -> Result<Vec<LogEntry>, Box<dyn std::error::Error + Send + Sync>> {
        let handle = tokio::runtime::Handle::current();
        handle.block_on(async {
            self.get_logs_async(limit as i32).await
        })
    }

    /// è·å–æ—¥å¿—ï¼ˆå¼‚æ­¥ï¼‰
    pub async fn get_logs_async(&self, limit: i32) -> Result<Vec<LogEntry>, Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;

        let rows = client.query(
            "SELECT level, message, module, EXTRACT(EPOCH FROM timestamp)::BIGINT as timestamp
            FROM logs
            ORDER BY timestamp DESC
            LIMIT $1",
            &[&limit],
        ).await?;

        let logs = rows.iter().map(|row| LogEntry {
            level: row.get("level"),
            message: row.get("message"),
            module: row.get("module"),
            timestamp: row.get("timestamp"),
        }).collect();

        Ok(logs)
    }

    /// æŒ‰è¿‡æ»¤å™¨æŸ¥è¯¢æ—¥å¿—
    pub async fn query_logs_async(&self, filter: LogFilter) -> Result<Vec<LogEntryExtended>, Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;

        let mut query = String::from(
            "SELECT id, level, message, module, file, line, thread, context, timestamp
            FROM logs
            WHERE 1=1"
        );

        let mut params: Vec<Box<dyn tokio_postgres::types::ToSql + Send + Sync>> = vec![];
        let mut param_idx = 1;

        if let Some(ref level) = filter.level {
            query.push_str(&format!(" AND level = ${}", param_idx));
            params.push(Box::new(level.clone()));
            param_idx += 1;
        }

        if let Some(ref module) = filter.module {
            query.push_str(&format!(" AND module = ${}", param_idx));
            params.push(Box::new(module.clone()));
            param_idx += 1;
        }

        if let Some(start) = filter.start_time {
            let start_dt = chrono::DateTime::from_timestamp(start, 0).unwrap_or_else(|| Utc::now());
            query.push_str(&format!(" AND timestamp >= ${}", param_idx));
            params.push(Box::new(start_dt));
            param_idx += 1;
        }

        if let Some(end) = filter.end_time {
            let end_dt = chrono::DateTime::from_timestamp(end, 0).unwrap_or_else(|| Utc::now());
            query.push_str(&format!(" AND timestamp <= ${}", param_idx));
            params.push(Box::new(end_dt));
            param_idx += 1;
        }

        if let Some(ref keyword) = filter.keyword {
            let pattern = format!("%{}%", keyword);
            query.push_str(&format!(" AND message ILIKE ${}", param_idx));
            params.push(Box::new(pattern));
            param_idx += 1;
        }

        query.push_str(" ORDER BY timestamp DESC");

        if let Some(limit) = filter.limit {
            query.push_str(&format!(" LIMIT ${}", param_idx));
            params.push(Box::new(limit));
            param_idx += 1;
        }

        if let Some(offset) = filter.offset {
            query.push_str(&format!(" OFFSET ${}", param_idx));
            params.push(Box::new(offset));
        }

        let param_refs: Vec<&(dyn tokio_postgres::types::ToSql + Sync)> = 
            params.iter().map(|p| p.as_ref() as &(dyn tokio_postgres::types::ToSql + Sync)).collect();

        let rows = client.query(&query, &param_refs).await?;

        let logs: Vec<LogEntryExtended> = rows.iter().map(|row| LogEntryExtended {
            id: row.get("id"),
            level: row.get("level"),
            message: row.get("message"),
            module: row.get("module"),
            file: row.get("file"),
            line: row.get("line"),
            thread: row.get("thread"),
            context: row.get("context"),
            timestamp: row.get::<_, chrono::DateTime<Utc>>("timestamp").to_rfc3339(),
        }).collect();

        debug!("ğŸ” æŸ¥è¯¢åˆ° {} æ¡æ—¥å¿—", logs.len());
        Ok(logs)
    }

    /// è·å–æ—¥å¿—ç»Ÿè®¡
    pub async fn get_statistics_async(&self) -> Result<LogStatistics, Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;

        // æ€»æ—¥å¿—æ•°
        let total_row = client.query_one(
            "SELECT COUNT(*) as count FROM logs",
            &[],
        ).await?;
        let total_logs: i64 = total_row.get("count");

        // æŒ‰çº§åˆ«ç»Ÿè®¡
        let level_rows = client.query(
            "SELECT level, COUNT(*) as count FROM logs GROUP BY level",
            &[],
        ).await?;

        let mut level_counts = HashMap::new();
        for row in level_rows {
            let level: String = row.get("level");
            let count: i64 = row.get("count");
            level_counts.insert(level, count);
        }

        // æŒ‰æ¨¡å—ç»Ÿè®¡
        let module_rows = client.query(
            "SELECT COALESCE(module, 'unknown') as module, COUNT(*) as count 
            FROM logs 
            GROUP BY module 
            ORDER BY count DESC 
            LIMIT 20",
            &[],
        ).await?;

        let mut module_counts = HashMap::new();
        for row in module_rows {
            let module: String = row.get("module");
            let count: i64 = row.get("count");
            module_counts.insert(module, count);
        }

        // æœ€è¿‘24å°æ—¶çš„é”™è¯¯å’Œè­¦å‘Š
        let recent_cutoff = Utc::now() - chrono::Duration::hours(24);
        
        let recent_errors_row = client.query_one(
            "SELECT COUNT(*) as count FROM logs WHERE level = 'error' AND timestamp >= $1",
            &[&recent_cutoff],
        ).await?;
        let recent_errors: i64 = recent_errors_row.get("count");

        let recent_warnings_row = client.query_one(
            "SELECT COUNT(*) as count FROM logs WHERE level = 'warn' AND timestamp >= $1",
            &[&recent_cutoff],
        ).await?;
        let recent_warnings: i64 = recent_warnings_row.get("count");

        Ok(LogStatistics {
            total_logs,
            level_counts,
            module_counts,
            recent_errors,
            recent_warnings,
        })
    }

    /// æ¸…ç†æ—§æ—¥å¿—
    pub async fn cleanup_old_logs_async(&self, days: i64) -> Result<usize, Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;

        let cutoff = Utc::now() - chrono::Duration::days(days);

        let affected = client.execute(
            "DELETE FROM logs WHERE timestamp < $1",
            &[&cutoff],
        ).await?;

        info!("ğŸ—‘ï¸  æ¸…ç†äº† {} æ¡æ—§æ—¥å¿—ï¼ˆ{}å¤©å‰ï¼‰", affected, days);
        Ok(affected as usize)
    }

    /// æŒ‰çº§åˆ«æ¸…ç†æ—¥å¿—
    pub async fn cleanup_logs_by_level_async(&self, level: &str, days: i64) -> Result<usize, Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;

        let cutoff = Utc::now() - chrono::Duration::days(days);

        let affected = client.execute(
            "DELETE FROM logs WHERE level = $1 AND timestamp < $2",
            &[&level, &cutoff],
        ).await?;

        info!("ğŸ—‘ï¸  æ¸…ç†äº† {} æ¡ {} çº§åˆ«çš„æ—§æ—¥å¿—", affected, level);
        Ok(affected as usize)
    }

    /// å‹ç¼©æ—¥å¿—ï¼ˆå°†æ—§æ—¥å¿—å¯¼å‡ºåˆ°å½’æ¡£è¡¨ï¼‰
    pub async fn archive_old_logs_async(&self, days: i64) -> Result<usize, Box<dyn std::error::Error + Send + Sync>> {
        let mut client = self.pool.get().await?;

        // åˆ›å»ºå½’æ¡£è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        client.execute(
            "CREATE TABLE IF NOT EXISTS logs_archive (
                id BIGINT PRIMARY KEY,
                level TEXT NOT NULL,
                message TEXT NOT NULL,
                module TEXT,
                file TEXT,
                line INTEGER,
                thread TEXT,
                context TEXT,
                timestamp TIMESTAMP NOT NULL,
                archived_at TIMESTAMP NOT NULL DEFAULT NOW()
            )",
            &[],
        ).await?;

        let cutoff = Utc::now() - chrono::Duration::days(days);

        // å¤åˆ¶åˆ°å½’æ¡£è¡¨
        let transaction = client.transaction().await?;

        let archived = transaction.execute(
            "INSERT INTO logs_archive 
            SELECT id, level, message, module, file, line, thread, context, timestamp, NOW()
            FROM logs
            WHERE timestamp < $1",
            &[&cutoff],
        ).await?;

        // åˆ é™¤å·²å½’æ¡£çš„æ—¥å¿—
        transaction.execute(
            "DELETE FROM logs WHERE timestamp < $1",
            &[&cutoff],
        ).await?;

        transaction.commit().await?;

        info!("ğŸ“¦ å½’æ¡£äº† {} æ¡æ—§æ—¥å¿—", archived);
        Ok(archived as usize)
    }

    /// æŒ‰æ¨¡å—è·å–æ—¥å¿—
    pub async fn get_logs_by_module_async(&self, module: &str, limit: i32) -> Result<Vec<LogEntryExtended>, Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;

        let rows = client.query(
            "SELECT id, level, message, module, file, line, thread, context, timestamp
            FROM logs
            WHERE module = $1
            ORDER BY timestamp DESC
            LIMIT $2",
            &[&module, &limit],
        ).await?;

        let logs = rows.iter().map(|row| LogEntryExtended {
            id: row.get("id"),
            level: row.get("level"),
            message: row.get("message"),
            module: row.get("module"),
            file: row.get("file"),
            line: row.get("line"),
            thread: row.get("thread"),
            context: row.get("context"),
            timestamp: row.get::<_, chrono::DateTime<Utc>>("timestamp").to_rfc3339(),
        }).collect();

        Ok(logs)
    }

    /// æŒ‰çº§åˆ«è·å–æ—¥å¿—
    pub async fn get_logs_by_level_async(&self, level: &str, limit: i32) -> Result<Vec<LogEntryExtended>, Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;

        let rows = client.query(
            "SELECT id, level, message, module, file, line, thread, context, timestamp
            FROM logs
            WHERE level = $1
            ORDER BY timestamp DESC
            LIMIT $2",
            &[&level, &limit],
        ).await?;

        let logs = rows.iter().map(|row| LogEntryExtended {
            id: row.get("id"),
            level: row.get("level"),
            message: row.get("message"),
            module: row.get("module"),
            file: row.get("file"),
            line: row.get("line"),
            thread: row.get("thread"),
            context: row.get("context"),
            timestamp: row.get::<_, chrono::DateTime<Utc>>("timestamp").to_rfc3339(),
        }).collect();

        Ok(logs)
    }

    /// è·å–æœ€è¿‘çš„é”™è¯¯æ—¥å¿—
    pub async fn get_recent_errors_async(&self, limit: i32) -> Result<Vec<LogEntryExtended>, Box<dyn std::error::Error + Send + Sync>> {
        self.get_logs_by_level_async("error", limit).await
    }

    /// è·å–æœ€è¿‘çš„è­¦å‘Šæ—¥å¿—
    pub async fn get_recent_warnings_async(&self, limit: i32) -> Result<Vec<LogEntryExtended>, Box<dyn std::error::Error + Send + Sync>> {
        self.get_logs_by_level_async("warn", limit).await
    }

    /// æœç´¢æ—¥å¿—
    pub async fn search_logs_async(&self, keyword: &str, limit: i32) -> Result<Vec<LogEntryExtended>, Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;

        let pattern = format!("%{}%", keyword);

        let rows = client.query(
            "SELECT id, level, message, module, file, line, thread, context, timestamp
            FROM logs
            WHERE message ILIKE $1 OR module ILIKE $1 OR context ILIKE $1
            ORDER BY timestamp DESC
            LIMIT $2",
            &[&pattern, &limit],
        ).await?;

        let logs: Vec<LogEntryExtended> = rows.iter().map(|row| LogEntryExtended {
            id: row.get("id"),
            level: row.get("level"),
            message: row.get("message"),
            module: row.get("module"),
            file: row.get("file"),
            line: row.get("line"),
            thread: row.get("thread"),
            context: row.get("context"),
            timestamp: row.get::<_, chrono::DateTime<Utc>>("timestamp").to_rfc3339(),
        }).collect();

        debug!("ğŸ” æœç´¢åˆ° {} æ¡æ—¥å¿—ï¼ˆå…³é”®è¯: {}ï¼‰", logs.len(), keyword);
        Ok(logs)
    }

    /// è·å–æ—¥å¿—æ€»æ•°
    pub async fn get_log_count_async(&self) -> Result<i64, Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;

        let row = client.query_one(
            "SELECT COUNT(*) as count FROM logs",
            &[],
        ).await?;

        Ok(row.get("count"))
    }

    /// æ¸…ç©ºæ‰€æœ‰æ—¥å¿—ï¼ˆå±é™©æ“ä½œï¼‰
    pub async fn truncate_logs_async(&self) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;

        client.execute("TRUNCATE TABLE logs", &[]).await?;

        warn!("âš ï¸  å·²æ¸…ç©ºæ‰€æœ‰æ—¥å¿—");
        Ok(())
    }

    /// æœç´¢æ—¥å¿—ï¼ˆå¸¦åˆ†é¡µï¼‰
    pub async fn search_logs(
        &self,
        filter: Option<LogFilter>,
        page: usize,
        page_size: usize,
        _sort_by: &str,
        _sort_order: &str,
    ) -> Result<(Vec<crate::utils::logger::LogEntry>, usize), Box<dyn std::error::Error + Send + Sync>> {
        let offset = (page - 1) * page_size;
        let limit = page_size as i32;
        
        let mut query_filter = filter.unwrap_or(LogFilter {
            level: None,
            module: None,
            start_time: None,
            end_time: None,
            keyword: None,
            limit: Some(limit),
            offset: Some(offset as i32),
        });
        
        query_filter.limit = Some(limit);
        query_filter.offset = Some(offset as i32);
        
        let logs_extended = self.query_logs_async(query_filter).await?;
        
        // è½¬æ¢ä¸ºç®€å•çš„ LogEntry
        let logs: Vec<crate::utils::logger::LogEntry> = logs_extended.into_iter().map(|log| {
            let level = crate::utils::logger::LogLevel::from_str(&log.level).unwrap_or(crate::utils::logger::LogLevel::Info);
            let timestamp = chrono::DateTime::parse_from_rfc3339(&log.timestamp)
                .ok()
                .map(|dt| dt.with_timezone(&Utc))
                .unwrap_or_else(|| Utc::now());
            
            crate::utils::logger::LogEntry {
                timestamp,
                local_time: chrono::Local::now(),
                level,
                message: log.message,
                module: log.module,
                file: log.file,
                line: log.line.map(|l| l as u32),
                thread: log.thread,
                data: None,
                stack: None,
                tags: Vec::new(),
            }
        }).collect();
        
        // è·å–æ€»æ•°
        let total = self.get_log_count_async().await? as usize;
        
        Ok((logs, total))
    }

    /// è·å–æ—¥å¿—ç»Ÿè®¡ï¼ˆå¸¦è¿‡æ»¤å™¨ï¼‰
    pub async fn get_statistics(
        &self,
        _filter: Option<LogFilter>,
    ) -> Result<crate::utils::logger::LogStatistics, Box<dyn std::error::Error + Send + Sync>> {
        let stats = self.get_statistics_async().await?;
        
        Ok(crate::utils::logger::LogStatistics {
            total_count: stats.total_logs as usize,
            error_count: *stats.level_counts.get("error").unwrap_or(&0) as usize,
            warning_count: *stats.level_counts.get("warn").unwrap_or(&0) as usize,
            info_count: *stats.level_counts.get("info").unwrap_or(&0) as usize,
            debug_count: *stats.level_counts.get("debug").unwrap_or(&0) as usize,
            trace_count: *stats.level_counts.get("trace").unwrap_or(&0) as usize,
        })
    }

    /// å¯¼å‡ºæ—¥å¿—
    pub async fn export_logs(
        &self,
        filter: Option<LogFilter>,
        format: &str,
        file_path: &str,
    ) -> Result<usize, Box<dyn std::error::Error + Send + Sync>> {
        use std::fs::File;
        use std::io::Write;
        
        let query_filter = filter.unwrap_or(LogFilter {
            level: None,
            module: None,
            start_time: None,
            end_time: None,
            keyword: None,
            limit: None,
            offset: None,
        });
        
        let logs = self.query_logs_async(query_filter).await?;
        let count = logs.len();
        
        let mut file = File::create(file_path)?;
        
        match format {
            "json" => {
                let json = serde_json::to_string_pretty(&logs)?;
                file.write_all(json.as_bytes())?;
            }
            "csv" => {
                writeln!(file, "ID,Level,Module,Message,Timestamp")?;
                for log in &logs {
                    writeln!(
                        file,
                        "{},{},{:?},{},{}",
                        log.id, log.level, log.module, log.message.replace(",", ";"), log.timestamp
                    )?;
                }
            }
            "txt" => {
                for log in &logs {
                    writeln!(
                        file,
                        "[{}] [{}] {} - {}",
                        log.timestamp, log.level, log.module.as_deref().unwrap_or("unknown"), log.message
                    )?;
                }
            }
            _ => return Err("ä¸æ”¯æŒçš„æ ¼å¼".into()),
        }
        
        info!("ğŸ“¤ å¯¼å‡ºäº† {} æ¡æ—¥å¿—åˆ° {}", count, file_path);
        Ok(count)
    }

    /// æ¸…ç†æ—§æ—¥å¿—ï¼ˆå…¼å®¹åŒæ­¥è°ƒç”¨ï¼‰
    pub async fn cleanup_old_logs(&self, retention_days: u32) -> Result<usize, Box<dyn std::error::Error + Send + Sync>> {
        self.cleanup_old_logs_async(retention_days as i64).await
    }

    /// è·å–è¿œç¨‹æ—¥å¿—é…ç½®
    pub async fn get_remote_config(&self) -> Result<crate::commands::logging::RemoteLogConfig, Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;
        
        let row_opt = client.query_opt(
            "SELECT config FROM remote_log_config WHERE id = 1",
            &[],
        ).await?;
        
        if let Some(row) = row_opt {
            let config_json: serde_json::Value = row.get("config");
            let config = serde_json::from_value(config_json)?;
            Ok(config)
        } else {
            Ok(crate::commands::logging::RemoteLogConfig::default())
        }
    }

    /// ä¿å­˜è¿œç¨‹æ—¥å¿—é…ç½®
    pub async fn save_remote_config(&self, config: crate::commands::logging::RemoteLogConfig) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;
        
        // åˆ›å»ºé…ç½®è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        client.execute(
            "CREATE TABLE IF NOT EXISTS remote_log_config (
                id INTEGER PRIMARY KEY DEFAULT 1,
                config JSONB NOT NULL,
                updated_at TIMESTAMP NOT NULL DEFAULT NOW()
            )",
            &[],
        ).await?;
        
        let config_json = serde_json::to_value(&config)?;
        
        client.execute(
            "INSERT INTO remote_log_config (id, config, updated_at)
            VALUES (1, $1, NOW())
            ON CONFLICT (id) DO UPDATE SET config = $1, updated_at = NOW()",
            &[&config_json],
        ).await?;
        
        Ok(())
    }

    /// ç»Ÿè®¡å¾…ä¸Šä¼ çš„æ—¥å¿—æ•°é‡
    pub async fn count_pending_upload_logs(&self) -> Result<usize, Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;
        
        // å°è¯•æŸ¥è¯¢ uploaded åˆ—ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› 0
        let row_result = client.query_one(
            "SELECT COUNT(*) as count FROM logs WHERE uploaded = FALSE",
            &[],
        ).await;
        
        let count: i64 = match row_result {
            Ok(row) => row.get("count"),
            Err(_) => {
                // å¦‚æœåˆ—ä¸å­˜åœ¨ï¼Œè¿”å› 0
                let fallback_row = client.query_one("SELECT 0::BIGINT as count", &[]).await?;
                fallback_row.get("count")
            }
        };
        
        Ok(count as usize)
    }

    /// è·å–æœ€åä¸Šä¼ æ—¶é—´
    pub async fn get_last_upload_time(&self) -> Result<i64, Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;
        
        let row_opt = client.query_opt(
            "SELECT last_upload_time FROM remote_log_upload_status WHERE id = 1",
            &[],
        ).await?;
        
        if let Some(row) = row_opt {
            let timestamp: chrono::DateTime<Utc> = row.get("last_upload_time");
            Ok(timestamp.timestamp())
        } else {
            Ok(0)
        }
    }

    /// è·å–å¾…ä¸Šä¼ çš„æ—¥å¿—
    pub async fn get_pending_upload_logs(&self, limit: usize) -> Result<Vec<crate::commands::logging::LogEntryWithId>, Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;
        
        let rows = client.query(
            "SELECT id, level, message, module, timestamp, EXTRACT(EPOCH FROM timestamp)::BIGINT as ts_epoch
            FROM logs
            WHERE uploaded = FALSE
            ORDER BY timestamp ASC
            LIMIT $1",
            &[&(limit as i64)],
        ).await.unwrap_or_else(|_| vec![]);
        
        let logs = rows.iter().map(|row| {
            let id: i64 = row.get("id");
            let level_str: String = row.get("level");
            let level = crate::utils::logger::LogLevel::from_str(&level_str)
                .unwrap_or(crate::utils::logger::LogLevel::Info);
            let ts_epoch: i64 = row.get("ts_epoch");
            let timestamp: chrono::DateTime<Utc> = row.get("timestamp");
            
            crate::commands::logging::LogEntryWithId {
                entry: crate::utils::logger::LogEntry {
                    timestamp,
                    local_time: chrono::Local::now(),
                    level,
                    message: row.get("message"),
                    module: row.get("module"),
                    file: None,
                    line: None,
                    thread: None,
                    data: None,
                    stack: None,
                    tags: Vec::new(),
                },
                id: Some(id),
                uploaded: false,
                created_at: Some(ts_epoch),
            }
        }).collect();
        
        Ok(logs)
    }

    /// æ ‡è®°æ—¥å¿—ä¸ºå·²ä¸Šä¼ 
    pub async fn mark_logs_as_uploaded(&self, log_ids: Vec<i64>) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        if log_ids.is_empty() {
            return Ok(());
        }
        
        let client = self.pool.get().await?;
        
        // ç¡®ä¿ uploaded åˆ—å­˜åœ¨
        client.execute(
            "ALTER TABLE logs ADD COLUMN IF NOT EXISTS uploaded BOOLEAN DEFAULT FALSE",
            &[],
        ).await?;
        
        let ids_str = log_ids.iter()
            .map(|id| id.to_string())
            .collect::<Vec<_>>()
            .join(",");
        
        let query = format!("UPDATE logs SET uploaded = TRUE WHERE id IN ({})", ids_str);
        client.execute(&query, &[]).await?;
        
        Ok(())
    }

    /// æ›´æ–°æœ€åä¸Šä¼ æ—¶é—´
    pub async fn update_last_upload_time(&self) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        let client = self.pool.get().await?;
        
        // åˆ›å»ºä¸Šä¼ çŠ¶æ€è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        client.execute(
            "CREATE TABLE IF NOT EXISTS remote_log_upload_status (
                id INTEGER PRIMARY KEY DEFAULT 1,
                last_upload_time TIMESTAMP NOT NULL DEFAULT NOW()
            )",
            &[],
        ).await?;
        
        client.execute(
            "INSERT INTO remote_log_upload_status (id, last_upload_time)
            VALUES (1, NOW())
            ON CONFLICT (id) DO UPDATE SET last_upload_time = NOW()",
            &[],
        ).await?;
        
        Ok(())
    }
}

// ================================
// æµ‹è¯•æ¨¡å—
// ================================

#[cfg(test)]
mod tests {
    use super::*;
    use std::sync::Arc;
    use tokio_postgres::NoTls;
    use deadpool_postgres::{Config, Pool, PoolConfig, Runtime};
    use chrono::{Utc, DateTime, Duration};
    use uuid::Uuid;
    
    // æµ‹è¯•æ•°æ®åº“é…ç½®
    fn get_test_db_config() -> Config {
        let mut cfg = Config::new();
        cfg.host = Some("localhost".to_string());
        cfg.port = Some(5432);
        cfg.user = Some("postgres".to_string());
        cfg.password = Some("postgres".to_string());
        cfg.dbname = Some("zishu_test".to_string());
        cfg
    }
    
    async fn create_test_pool() -> DbPool {
        let cfg = get_test_db_config();
        let pool_config = PoolConfig::new(5);
        cfg.create_pool(Some(Runtime::Tokio1), NoTls)
            .expect("Failed to create test database pool")
    }
    
    async fn setup_test_db() -> LoggingRegistry {
        let pool = create_test_pool().await;
        let registry = LoggingRegistry::new(pool);
        
        // åˆå§‹åŒ–æµ‹è¯•è¡¨ï¼ˆåœ¨ç‹¬ç«‹çš„æµ‹è¯• schema ä¸­ï¼‰
        if let Ok(client) = registry.pool.get().await {
            let _ = client.execute("CREATE SCHEMA IF NOT EXISTS test_logging", &[]).await;
            let _ = client.execute("SET search_path TO test_logging", &[]).await;
            registry.init_tables().await.expect("Failed to init tables");
        }
        
        registry
    }
    
    async fn cleanup_test_data(registry: &LoggingRegistry) {
        if let Ok(client) = registry.pool.get().await {
            let _ = client.execute("TRUNCATE TABLE test_logging.logs CASCADE", &[]).await;
            let _ = client.execute("DROP TABLE IF EXISTS test_logging.logs_archive CASCADE", &[]).await;
            let _ = client.execute("DROP TABLE IF EXISTS test_logging.remote_log_config CASCADE", &[]).await;
            let _ = client.execute("DROP TABLE IF EXISTS test_logging.remote_log_upload_status CASCADE", &[]).await;
        }
    }
    
    fn create_test_log_entry() -> LogEntry {
        LogEntry {
            level: "info".to_string(),
            message: format!("Test log message {}", Uuid::new_v4()),
            module: Some("test_module".to_string()),
            timestamp: Utc::now().timestamp(),
        }
    }
    
    fn create_test_log_filter() -> LogFilter {
        LogFilter {
            level: Some("info".to_string()),
            module: Some("test_module".to_string()),
            start_time: Some((Utc::now() - Duration::hours(1)).timestamp()),
            end_time: Some(Utc::now().timestamp()),
            keyword: Some("test".to_string()),
            limit: Some(10),
            offset: Some(0),
        }
    }
    
    // ================================
    // LogLevel å•å…ƒæµ‹è¯•
    // ================================
    
    #[test]
    fn test_log_level_display() {
        assert_eq!(LogLevel::Trace.to_string(), "trace");
        assert_eq!(LogLevel::Debug.to_string(), "debug");
        assert_eq!(LogLevel::Info.to_string(), "info");
        assert_eq!(LogLevel::Warn.to_string(), "warn");
        assert_eq!(LogLevel::Error.to_string(), "error");
        assert_eq!(LogLevel::Fatal.to_string(), "fatal");
    }
    
    #[test]
    fn test_log_level_from_str() {
        assert_eq!("trace".parse::<LogLevel>().unwrap(), LogLevel::Trace);
        assert_eq!("debug".parse::<LogLevel>().unwrap(), LogLevel::Debug);
        assert_eq!("info".parse::<LogLevel>().unwrap(), LogLevel::Info);
        assert_eq!("warn".parse::<LogLevel>().unwrap(), LogLevel::Warn);
        assert_eq!("error".parse::<LogLevel>().unwrap(), LogLevel::Error);
        assert_eq!("fatal".parse::<LogLevel>().unwrap(), LogLevel::Fatal);
        
        // æµ‹è¯•å¤§å°å†™ä¸æ•æ„Ÿ
        assert_eq!("INFO".parse::<LogLevel>().unwrap(), LogLevel::Info);
        assert_eq!("Error".parse::<LogLevel>().unwrap(), LogLevel::Error);
        
        // æµ‹è¯•æ— æ•ˆè¾“å…¥
        assert!("invalid".parse::<LogLevel>().is_err());
        assert!("".parse::<LogLevel>().is_err());
    }
    
    // ================================
    // LoggingRegistry å•å…ƒæµ‹è¯•
    // ================================
    
    #[tokio::test]
    async fn test_logging_registry_new() {
        // ç®€åŒ–æµ‹è¯•ï¼Œé¿å…ä¾èµ–çœŸå®æ•°æ®åº“è¿æ¥
        if let Ok(pool) = std::panic::catch_unwind(|| {
            tokio::runtime::Runtime::new().unwrap().block_on(async {
                create_test_pool().await
            })
        }) {
            let registry = LoggingRegistry::new(pool);
            // éªŒè¯ registry ç»“æ„ä½“åˆ›å»ºæˆåŠŸ
            // æ³¨æ„ï¼šä¸éªŒè¯è¿æ¥æ± çŠ¶æ€ï¼Œå› ä¸ºæµ‹è¯•ç¯å¢ƒå¯èƒ½æ²¡æœ‰æ•°æ®åº“
        } else {
            // å¦‚æœæ— æ³•è¿æ¥æ•°æ®åº“ï¼Œè·³è¿‡æµ‹è¯•
            println!("âš ï¸  è·³è¿‡æ—¥å¿—æµ‹è¯•ï¼šæ— æ³•è¿æ¥åˆ°æµ‹è¯•æ•°æ®åº“");
        }
    }
    
    // æ³¨æ„ï¼šä»¥ä¸‹æµ‹è¯•éœ€è¦çœŸå®æ•°æ®åº“è¿æ¥ï¼Œåœ¨CI/CDç¯å¢ƒä¸­å¯èƒ½éœ€è¦è·³è¿‡
    
    #[tokio::test]
    #[ignore] // è·³è¿‡éœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_init_tables_success() {
        let registry = setup_test_db().await;
        
        // éªŒè¯è¡¨å·²åˆ›å»º
        let result = registry.init_tables().await;
        assert!(result.is_ok(), "æ—¥å¿—è¡¨åˆå§‹åŒ–åº”è¯¥æˆåŠŸ");
    }
    
    #[tokio::test]
    #[ignore] // è·³è¿‡éœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_log_success() {
        let registry = setup_test_db().await;
        cleanup_test_data(&registry).await;
        
        let log_entry = create_test_log_entry();
        
        // è®°å½•æ—¥å¿—
        let result = registry.log(log_entry.clone());
        assert!(result.is_ok(), "æ—¥å¿—è®°å½•åº”è¯¥æˆåŠŸ");
        
        // éªŒè¯æ—¥å¿—å·²è®°å½•
        let logs = registry.get_logs(10).unwrap();
        assert!(!logs.is_empty(), "åº”è¯¥èƒ½æŸ¥è¯¢åˆ°è®°å½•çš„æ—¥å¿—");
        assert_eq!(logs[0].message, log_entry.message);
        assert_eq!(logs[0].level, log_entry.level);
        
        cleanup_test_data(&registry).await;
    }
    
    #[tokio::test]
    #[ignore] // è·³è¿‡éœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_log_async_success() {
        let registry = setup_test_db().await;
        cleanup_test_data(&registry).await;
        
        let log_entry = create_test_log_entry();
        
        // å¼‚æ­¥è®°å½•æ—¥å¿—
        let result = registry.log_async(log_entry.clone()).await;
        assert!(result.is_ok(), "å¼‚æ­¥æ—¥å¿—è®°å½•åº”è¯¥æˆåŠŸ");
        
        // éªŒè¯æ—¥å¿—å·²è®°å½•
        let logs = registry.get_logs_async(10).await.unwrap();
        assert!(!logs.is_empty(), "åº”è¯¥èƒ½æŸ¥è¯¢åˆ°è®°å½•çš„æ—¥å¿—");
        assert_eq!(logs[0].message, log_entry.message);
        
        cleanup_test_data(&registry).await;
    }
    
    #[tokio::test]
    #[ignore] // è·³è¿‡éœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_log_batch_async_success() {
        let registry = setup_test_db().await;
        cleanup_test_data(&registry).await;
        
        // åˆ›å»ºæ‰¹é‡æ—¥å¿—
        let entries: Vec<LogEntry> = (0..5).map(|i| LogEntry {
            level: "info".to_string(),
            message: format!("Batch log entry {}", i),
            module: Some("batch_test".to_string()),
            timestamp: Utc::now().timestamp(),
        }).collect();
        
        // æ‰¹é‡è®°å½•æ—¥å¿—
        let result = registry.log_batch_async(entries.clone()).await;
        assert!(result.is_ok(), "æ‰¹é‡æ—¥å¿—è®°å½•åº”è¯¥æˆåŠŸ");
        
        // éªŒè¯æ‰€æœ‰æ—¥å¿—å·²è®°å½•
        let logs = registry.get_logs_async(10).await.unwrap();
        assert!(logs.len() >= 5, "åº”è¯¥è®°å½•äº†è‡³å°‘5æ¡æ—¥å¿—");
        
        cleanup_test_data(&registry).await;
    }
    
    #[tokio::test]
    #[ignore] // è·³è¿‡éœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_log_extended_async_success() {
        let registry = setup_test_db().await;
        cleanup_test_data(&registry).await;
        
        // æ‰©å±•æ—¥å¿—è®°å½•
        let result = registry.log_extended_async(
            "warn",
            "Extended log message",
            Some("extended_module"),
            Some("test.rs"),
            Some(42),
            Some("main"),
            Some("context_info"),
        ).await;
        
        assert!(result.is_ok(), "æ‰©å±•æ—¥å¿—è®°å½•åº”è¯¥æˆåŠŸ");
        
        // æŸ¥è¯¢æ‰©å±•æ—¥å¿—
        let filter = LogFilter {
            level: Some("warn".to_string()),
            module: Some("extended_module".to_string()),
            ..Default::default()
        };
        
        let logs = registry.query_logs_async(filter).await.unwrap();
        assert!(!logs.is_empty(), "åº”è¯¥èƒ½æŸ¥è¯¢åˆ°æ‰©å±•æ—¥å¿—");
        
        let log = &logs[0];
        assert_eq!(log.level, "warn");
        assert_eq!(log.message, "Extended log message");
        assert_eq!(log.module, Some("extended_module".to_string()));
        assert_eq!(log.file, Some("test.rs".to_string()));
        assert_eq!(log.line, Some(42));
        
        cleanup_test_data(&registry).await;
    }
    
    #[tokio::test]
    #[ignore] // è·³è¿‡éœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_query_logs_with_filter() {
        let registry = setup_test_db().await;
        cleanup_test_data(&registry).await;
        
        // åˆ›å»ºä¸åŒç±»å‹çš„æ—¥å¿—
        let entries = vec![
            LogEntry {
                level: "info".to_string(),
                message: "Info message".to_string(),
                module: Some("module_a".to_string()),
                timestamp: Utc::now().timestamp(),
            },
            LogEntry {
                level: "error".to_string(),
                message: "Error message".to_string(),
                module: Some("module_b".to_string()),
                timestamp: Utc::now().timestamp(),
            },
            LogEntry {
                level: "warn".to_string(),
                message: "Warning message".to_string(),
                module: Some("module_a".to_string()),
                timestamp: Utc::now().timestamp(),
            },
        ];
        
        // æ‰¹é‡è®°å½•
        registry.log_batch_async(entries).await.unwrap();
        
        // æŒ‰çº§åˆ«è¿‡æ»¤
        let filter = LogFilter {
            level: Some("error".to_string()),
            ..Default::default()
        };
        
        let logs = registry.query_logs_async(filter).await.unwrap();
        assert_eq!(logs.len(), 1, "åº”è¯¥åªæœ‰1æ¡é”™è¯¯æ—¥å¿—");
        assert_eq!(logs[0].level, "error");
        
        // æŒ‰æ¨¡å—è¿‡æ»¤
        let filter = LogFilter {
            module: Some("module_a".to_string()),
            ..Default::default()
        };
        
        let logs = registry.query_logs_async(filter).await.unwrap();
        assert_eq!(logs.len(), 2, "module_aåº”è¯¥æœ‰2æ¡æ—¥å¿—");
        
        // æŒ‰å…³é”®è¯è¿‡æ»¤
        let filter = LogFilter {
            keyword: Some("Error".to_string()),
            ..Default::default()
        };
        
        let logs = registry.query_logs_async(filter).await.unwrap();
        assert_eq!(logs.len(), 1, "åŒ…å«'Error'çš„åº”è¯¥æœ‰1æ¡æ—¥å¿—");
        
        cleanup_test_data(&registry).await;
    }
    
    #[tokio::test]
    #[ignore] // è·³è¿‡éœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_get_statistics() {
        let registry = setup_test_db().await;
        cleanup_test_data(&registry).await;
        
        // åˆ›å»ºç»Ÿè®¡æµ‹è¯•æ•°æ®
        let entries = vec![
            LogEntry { level: "info".to_string(), message: "Info 1".to_string(), module: Some("mod1".to_string()), timestamp: Utc::now().timestamp() },
            LogEntry { level: "info".to_string(), message: "Info 2".to_string(), module: Some("mod1".to_string()), timestamp: Utc::now().timestamp() },
            LogEntry { level: "error".to_string(), message: "Error 1".to_string(), module: Some("mod2".to_string()), timestamp: Utc::now().timestamp() },
            LogEntry { level: "warn".to_string(), message: "Warn 1".to_string(), module: Some("mod1".to_string()), timestamp: Utc::now().timestamp() },
        ];
        
        registry.log_batch_async(entries).await.unwrap();
        
        let stats = registry.get_statistics_async().await.unwrap();
        
        assert_eq!(stats.total_logs, 4, "æ€»æ—¥å¿—æ•°åº”è¯¥æ˜¯4");
        assert_eq!(*stats.level_counts.get("info").unwrap_or(&0), 2, "infoçº§åˆ«åº”è¯¥æœ‰2æ¡");
        assert_eq!(*stats.level_counts.get("error").unwrap_or(&0), 1, "errorçº§åˆ«åº”è¯¥æœ‰1æ¡");
        assert_eq!(*stats.level_counts.get("warn").unwrap_or(&0), 1, "warnçº§åˆ«åº”è¯¥æœ‰1æ¡");
        
        cleanup_test_data(&registry).await;
    }
    
    #[tokio::test]
    #[ignore] // è·³è¿‡éœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_cleanup_old_logs() {
        let registry = setup_test_db().await;
        cleanup_test_data(&registry).await;
        
        // åˆ›å»ºä¸€äº›æ—§æ—¥å¿—ï¼ˆæ¨¡æ‹Ÿï¼‰
        let old_timestamp = (Utc::now() - Duration::days(10)).timestamp();
        let entries = vec![
            LogEntry {
                level: "info".to_string(),
                message: "Old log 1".to_string(),
                module: Some("old_module".to_string()),
                timestamp: old_timestamp,
            },
            LogEntry {
                level: "info".to_string(),
                message: "New log 1".to_string(),
                module: Some("new_module".to_string()),
                timestamp: Utc::now().timestamp(),
            },
        ];
        
        registry.log_batch_async(entries).await.unwrap();
        
        // æ¸…ç†7å¤©å‰çš„æ—¥å¿—
        let cleaned = registry.cleanup_old_logs_async(7).await.unwrap();
        assert_eq!(cleaned, 1, "åº”è¯¥æ¸…ç†1æ¡æ—§æ—¥å¿—");
        
        // éªŒè¯æ–°æ—¥å¿—è¿˜åœ¨
        let remaining_logs = registry.get_logs_async(10).await.unwrap();
        assert_eq!(remaining_logs.len(), 1, "åº”è¯¥è¿˜å‰©1æ¡æ–°æ—¥å¿—");
        assert_eq!(remaining_logs[0].message, "New log 1");
        
        cleanup_test_data(&registry).await;
    }
    
    #[tokio::test]
    #[ignore] // è·³è¿‡éœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_search_logs() {
        let registry = setup_test_db().await;
        cleanup_test_data(&registry).await;
        
        // åˆ›å»ºæœç´¢æµ‹è¯•æ•°æ®
        let entries = vec![
            LogEntry {
                level: "info".to_string(),
                message: "Database connection established".to_string(),
                module: Some("database".to_string()),
                timestamp: Utc::now().timestamp(),
            },
            LogEntry {
                level: "error".to_string(),
                message: "Failed to connect to API".to_string(),
                module: Some("api".to_string()),
                timestamp: Utc::now().timestamp(),
            },
            LogEntry {
                level: "info".to_string(),
                message: "User authentication successful".to_string(),
                module: Some("auth".to_string()),
                timestamp: Utc::now().timestamp(),
            },
        ];
        
        registry.log_batch_async(entries).await.unwrap();
        
        // æœç´¢åŒ…å«"connection"çš„æ—¥å¿—
        let results = registry.search_logs_async("connection", 10).await.unwrap();
        assert_eq!(results.len(), 1, "åº”è¯¥æ‰¾åˆ°1æ¡åŒ…å«'connection'çš„æ—¥å¿—");
        assert!(results[0].message.contains("connection"));
        
        // æœç´¢åŒ…å«"API"çš„æ—¥å¿—
        let results = registry.search_logs_async("API", 10).await.unwrap();
        assert_eq!(results.len(), 1, "åº”è¯¥æ‰¾åˆ°1æ¡åŒ…å«'API'çš„æ—¥å¿—");
        
        cleanup_test_data(&registry).await;
    }
    
    #[tokio::test]
    #[ignore] // è·³è¿‡éœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_get_logs_by_level() {
        let registry = setup_test_db().await;
        cleanup_test_data(&registry).await;
        
        // åˆ›å»ºä¸åŒçº§åˆ«çš„æ—¥å¿—
        let entries = vec![
            LogEntry { level: "error".to_string(), message: "Error 1".to_string(), module: Some("mod1".to_string()), timestamp: Utc::now().timestamp() },
            LogEntry { level: "error".to_string(), message: "Error 2".to_string(), module: Some("mod2".to_string()), timestamp: Utc::now().timestamp() },
            LogEntry { level: "info".to_string(), message: "Info 1".to_string(), module: Some("mod1".to_string()), timestamp: Utc::now().timestamp() },
        ];
        
        registry.log_batch_async(entries).await.unwrap();
        
        // è·å–é”™è¯¯æ—¥å¿—
        let error_logs = registry.get_logs_by_level_async("error", 10).await.unwrap();
        assert_eq!(error_logs.len(), 2, "åº”è¯¥æœ‰2æ¡é”™è¯¯æ—¥å¿—");
        assert!(error_logs.iter().all(|log| log.level == "error"));
        
        // è·å–ä¿¡æ¯æ—¥å¿—
        let info_logs = registry.get_logs_by_level_async("info", 10).await.unwrap();
        assert_eq!(info_logs.len(), 1, "åº”è¯¥æœ‰1æ¡ä¿¡æ¯æ—¥å¿—");
        assert_eq!(info_logs[0].level, "info");
        
        cleanup_test_data(&registry).await;
    }
    
    #[tokio::test]
    #[ignore] // è·³è¿‡éœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_get_logs_by_module() {
        let registry = setup_test_db().await;
        cleanup_test_data(&registry).await;
        
        // åˆ›å»ºä¸åŒæ¨¡å—çš„æ—¥å¿—
        let entries = vec![
            LogEntry { level: "info".to_string(), message: "Module A log 1".to_string(), module: Some("module_a".to_string()), timestamp: Utc::now().timestamp() },
            LogEntry { level: "info".to_string(), message: "Module A log 2".to_string(), module: Some("module_a".to_string()), timestamp: Utc::now().timestamp() },
            LogEntry { level: "info".to_string(), message: "Module B log 1".to_string(), module: Some("module_b".to_string()), timestamp: Utc::now().timestamp() },
        ];
        
        registry.log_batch_async(entries).await.unwrap();
        
        // è·å–æ¨¡å—Açš„æ—¥å¿—
        let module_a_logs = registry.get_logs_by_module_async("module_a", 10).await.unwrap();
        assert_eq!(module_a_logs.len(), 2, "module_aåº”è¯¥æœ‰2æ¡æ—¥å¿—");
        assert!(module_a_logs.iter().all(|log| log.module == Some("module_a".to_string())));
        
        // è·å–æ¨¡å—Bçš„æ—¥å¿—
        let module_b_logs = registry.get_logs_by_module_async("module_b", 10).await.unwrap();
        assert_eq!(module_b_logs.len(), 1, "module_båº”è¯¥æœ‰1æ¡æ—¥å¿—");
        
        cleanup_test_data(&registry).await;
    }
    
    #[tokio::test]
    #[ignore] // è·³è¿‡éœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_archive_old_logs() {
        let registry = setup_test_db().await;
        cleanup_test_data(&registry).await;
        
        // åˆ›å»ºæ—§æ—¥å¿—
        let old_timestamp = (Utc::now() - Duration::days(10)).timestamp();
        let entries = vec![
            LogEntry {
                level: "info".to_string(),
                message: "Old log to archive".to_string(),
                module: Some("archive_test".to_string()),
                timestamp: old_timestamp,
            },
            LogEntry {
                level: "info".to_string(),
                message: "New log to keep".to_string(),
                module: Some("keep_test".to_string()),
                timestamp: Utc::now().timestamp(),
            },
        ];
        
        registry.log_batch_async(entries).await.unwrap();
        
        // å½’æ¡£7å¤©å‰çš„æ—¥å¿—
        let archived = registry.archive_old_logs_async(7).await.unwrap();
        assert_eq!(archived, 1, "åº”è¯¥å½’æ¡£1æ¡æ—§æ—¥å¿—");
        
        // éªŒè¯ä¸»è¡¨ä¸­åªå‰©æ–°æ—¥å¿—
        let remaining_logs = registry.get_logs_async(10).await.unwrap();
        assert_eq!(remaining_logs.len(), 1, "ä¸»è¡¨åº”è¯¥åªå‰©1æ¡æ—¥å¿—");
        assert_eq!(remaining_logs[0].message, "New log to keep");
        
        cleanup_test_data(&registry).await;
    }
    
    // ================================
    // é”™è¯¯å¤„ç†æµ‹è¯•
    // ================================
    
    #[tokio::test]
    #[ignore] // è·³è¿‡éœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_log_batch_empty() {
        let registry = setup_test_db().await;
        
        // æµ‹è¯•ç©ºæ‰¹æ¬¡
        let result = registry.log_batch_async(vec![]).await;
        assert!(result.is_ok(), "ç©ºæ‰¹æ¬¡åº”è¯¥æˆåŠŸå¤„ç†");
    }
    
    #[tokio::test]
    #[ignore] // è·³è¿‡éœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_query_logs_empty_filter() {
        let registry = setup_test_db().await;
        cleanup_test_data(&registry).await;
        
        // æµ‹è¯•ç©ºè¿‡æ»¤å™¨
        let filter = LogFilter {
            level: None,
            module: None,
            start_time: None,
            end_time: None,
            keyword: None,
            limit: Some(10),
            offset: Some(0),
        };
        
        let result = registry.query_logs_async(filter).await;
        assert!(result.is_ok(), "ç©ºè¿‡æ»¤å™¨æŸ¥è¯¢åº”è¯¥æˆåŠŸ");
        
        cleanup_test_data(&registry).await;
    }
    
    #[tokio::test]
    #[ignore] // è·³è¿‡éœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_cleanup_logs_by_level() {
        let registry = setup_test_db().await;
        cleanup_test_data(&registry).await;
        
        // åˆ›å»ºä¸åŒçº§åˆ«çš„æ—§æ—¥å¿—
        let old_timestamp = (Utc::now() - Duration::days(10)).timestamp();
        let entries = vec![
            LogEntry { level: "debug".to_string(), message: "Old debug".to_string(), module: None, timestamp: old_timestamp },
            LogEntry { level: "error".to_string(), message: "Old error".to_string(), module: None, timestamp: old_timestamp },
            LogEntry { level: "debug".to_string(), message: "New debug".to_string(), module: None, timestamp: Utc::now().timestamp() },
        ];
        
        registry.log_batch_async(entries).await.unwrap();
        
        // æ¸…ç†7å¤©å‰çš„debugæ—¥å¿—
        let cleaned = registry.cleanup_logs_by_level_async("debug", 7).await.unwrap();
        assert_eq!(cleaned, 1, "åº”è¯¥æ¸…ç†1æ¡æ—§çš„debugæ—¥å¿—");
        
        // éªŒè¯å…¶ä»–æ—¥å¿—è¿˜åœ¨
        let remaining_logs = registry.get_logs_async(10).await.unwrap();
        assert_eq!(remaining_logs.len(), 2, "åº”è¯¥è¿˜å‰©2æ¡æ—¥å¿—");
        
        cleanup_test_data(&registry).await;
    }
    
    // ================================
    // æ€§èƒ½æµ‹è¯•
    // ================================
    
    #[tokio::test]
    #[ignore] // è·³è¿‡æ€§èƒ½æµ‹è¯•å’Œéœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_performance_batch_insert() {
        let registry = setup_test_db().await;
        cleanup_test_data(&registry).await;
        
        let start = std::time::Instant::now();
        
        // æ‰¹é‡æ’å…¥æµ‹è¯•
        let entries: Vec<LogEntry> = (0..100).map(|i| LogEntry {
            level: "info".to_string(),
            message: format!("Performance test log {}", i),
            module: Some("performance".to_string()),
            timestamp: Utc::now().timestamp(),
        }).collect();
        
        let result = registry.log_batch_async(entries).await;
        let duration = start.elapsed();
        
        assert!(result.is_ok(), "æ‰¹é‡æ’å…¥åº”è¯¥æˆåŠŸ");
        assert!(duration.as_millis() < 3000, "100æ¡æ—¥å¿—æ’å…¥åº”è¯¥åœ¨3ç§’å†…å®Œæˆ"); // æ€§èƒ½è¦æ±‚
        
        cleanup_test_data(&registry).await;
    }
    
    // ================================
    // å¹¶å‘æµ‹è¯•
    // ================================
    
    #[tokio::test]
    #[ignore] // è·³è¿‡å¹¶å‘æµ‹è¯•å’Œéœ€è¦æ•°æ®åº“çš„é›†æˆæµ‹è¯•
    async fn test_logging_registry_concurrent_logging() {
        let registry = Arc::new(setup_test_db().await);
        cleanup_test_data(&*registry).await;
        
        // å¹¶å‘æ—¥å¿—è®°å½•
        let handles: Vec<_> = (0..10).map(|i| {
            let registry_clone = Arc::clone(&registry);
            tokio::spawn(async move {
                let entry = LogEntry {
                    level: "info".to_string(),
                    message: format!("Concurrent log {}", i),
                    module: Some("concurrent".to_string()),
                    timestamp: Utc::now().timestamp(),
                };
                registry_clone.log_async(entry).await
            })
        }).collect();
        
        // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for handle in handles {
            let result = handle.await;
            assert!(result.is_ok(), "å¹¶å‘ä»»åŠ¡åº”è¯¥æˆåŠŸ");
            assert!(result.unwrap().is_ok(), "æ—¥å¿—è®°å½•åº”è¯¥æˆåŠŸ");
        }
        
        // éªŒè¯æ‰€æœ‰æ—¥å¿—éƒ½å·²è®°å½•
        let logs = registry.get_logs_async(15).await.unwrap();
        assert!(logs.len() >= 10, "åº”è¯¥è®°å½•äº†è‡³å°‘10æ¡å¹¶å‘æ—¥å¿—");
        
        cleanup_test_data(&*registry).await;
    }
}

impl Default for LogFilter {
    fn default() -> Self {
        Self {
            level: None,
            module: None,
            start_time: None,
            end_time: None,
            keyword: None,
            limit: None,
            offset: None,
        }
    }
}
