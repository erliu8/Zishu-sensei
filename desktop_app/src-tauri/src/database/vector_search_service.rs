//! Qdrant å‘é‡æœç´¢æœåŠ¡
//!
//! æä¾›é«˜å±‚å‘é‡æœç´¢æŠ½è±¡ï¼ŒåŒ…æ‹¬ï¼š
//! - è¯­ä¹‰æœç´¢
//! - å‘é‡ç›¸ä¼¼åº¦åŒ¹é…
//! - AIå¯¹è¯å†å²æ£€ç´¢
//! - æ–‡æ¡£å‘é‡åŒ–å­˜å‚¨

use std::sync::Arc;
use tokio::sync::RwLock;
use serde::{Deserialize, Serialize};
use tracing::{info, warn, error};

use super::backends::{VectorDatabaseBackend, DatabaseResult, DatabaseError, VectorSearchResult};
use super::qdrant_backend::QdrantBackend;

/// å‘é‡æœç´¢æœåŠ¡
pub struct VectorSearchService {
    backend: Arc<RwLock<QdrantBackend>>,
}

impl VectorSearchService {
    /// åˆ›å»ºæ–°çš„å‘é‡æœç´¢æœåŠ¡
    pub fn new(backend: Arc<RwLock<QdrantBackend>>) -> Self {
        Self { backend }
    }
    
    // ========================================
    // é›†åˆç®¡ç†
    // ========================================
    
    /// åˆ›å»ºå‘é‡é›†åˆ
    pub async fn create_collection(
        &self,
        name: &str,
        vector_size: usize,
    ) -> DatabaseResult<()> {
        use super::backends::DatabaseBackend;
        
        let schema = serde_json::json!({
            "vector_size": vector_size
        });
        let schema_str = serde_json::to_string(&schema)?;
        
        self.backend
            .read()
            .await
            .create_collection(name, Some(&schema_str))
            .await
    }
    
    /// åˆ é™¤å‘é‡é›†åˆ
    pub async fn delete_collection(&self, name: &str) -> DatabaseResult<()> {
        use super::backends::DatabaseBackend;
        self.backend.read().await.drop_collection(name).await
    }
    
    /// æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
    pub async fn collection_exists(&self, name: &str) -> DatabaseResult<bool> {
        use super::backends::DatabaseBackend;
        self.backend.read().await.collection_exists(name).await
    }
    
    // ========================================
    // å‘é‡æ“ä½œ
    // ========================================
    
    /// æ’å…¥å‘é‡
    pub async fn insert_vector<T: Serialize>(
        &self,
        collection: &str,
        id: &str,
        vector: Vec<f32>,
        payload: &T,
    ) -> DatabaseResult<()> {
        let json_payload = serde_json::to_value(payload)?;
        
        self.backend
            .read()
            .await
            .insert_vector(collection, id, vector, &json_payload)
            .await
    }
    
    /// æ‰¹é‡æ’å…¥å‘é‡
    pub async fn batch_insert_vectors<T: Serialize>(
        &self,
        collection: &str,
        items: Vec<(String, Vec<f32>, T)>,
    ) -> DatabaseResult<()> {
        let converted_items: Result<Vec<_>, _> = items
            .into_iter()
            .map(|(id, vector, payload)| {
                serde_json::to_value(&payload).map(|json| (id, vector, json))
            })
            .collect();
        
        let converted_items = converted_items?;
        
        self.backend
            .read()
            .await
            .batch_insert_vectors(collection, converted_items)
            .await
    }
    
    /// åˆ é™¤å‘é‡
    pub async fn delete_vector(&self, collection: &str, id: &str) -> DatabaseResult<()> {
        self.backend.read().await.delete_vector(collection, id).await
    }
    
    // ========================================
    // å‘é‡æœç´¢
    // ========================================
    
    /// å‘é‡ç›¸ä¼¼åº¦æœç´¢
    pub async fn search(
        &self,
        collection: &str,
        query_vector: Vec<f32>,
        limit: usize,
    ) -> DatabaseResult<Vec<VectorSearchResult>> {
        self.backend
            .read()
            .await
            .vector_search(collection, query_vector, limit, None)
            .await
    }
    
    /// å‘é‡æœç´¢ï¼ˆå¸¦è¿‡æ»¤ï¼‰
    pub async fn search_with_filter(
        &self,
        collection: &str,
        query_vector: Vec<f32>,
        limit: usize,
        filter: &super::backends::QueryOptions,
    ) -> DatabaseResult<Vec<VectorSearchResult>> {
        self.backend
            .read()
            .await
            .vector_search(collection, query_vector, limit, Some(filter))
            .await
    }
    
    // ========================================
    // å¯¹è¯å†å²ç®¡ç†
    // ========================================
    
    /// å­˜å‚¨å¯¹è¯æ¶ˆæ¯
    pub async fn store_conversation_message(
        &self,
        message_id: &str,
        message_vector: Vec<f32>,
        message_data: &ConversationMessage,
    ) -> DatabaseResult<()> {
        const COLLECTION: &str = "conversations";
        
        // ç¡®ä¿é›†åˆå­˜åœ¨
        if !self.collection_exists(COLLECTION).await? {
            self.create_collection(COLLECTION, 384).await?;
        }
        
        self.insert_vector(COLLECTION, message_id, message_vector, message_data)
            .await
    }
    
    /// æœç´¢ç›¸ä¼¼å¯¹è¯
    pub async fn search_similar_conversations(
        &self,
        query_vector: Vec<f32>,
        limit: usize,
    ) -> DatabaseResult<Vec<VectorSearchResult>> {
        const COLLECTION: &str = "conversations";
        
        self.search(COLLECTION, query_vector, limit).await
    }
    
    /// æœç´¢ç”¨æˆ·çš„å¯¹è¯å†å²
    pub async fn search_user_conversations(
        &self,
        user_id: &str,
        query_vector: Vec<f32>,
        limit: usize,
    ) -> DatabaseResult<Vec<VectorSearchResult>> {
        use crate::database::backends::{QueryCondition, QueryOperator, QueryOptions};
        
        const COLLECTION: &str = "conversations";
        
        let filter = QueryOptions {
            conditions: vec![QueryCondition {
                field: "user_id".to_string(),
                operator: QueryOperator::Eq,
                value: serde_json::Value::String(user_id.to_string()),
            }],
            limit: Some(limit),
            offset: None,
            order_by: None,
        };
        
        self.search_with_filter(COLLECTION, query_vector, limit, &filter)
            .await
    }
    
    /// åˆ é™¤å¯¹è¯æ¶ˆæ¯
    pub async fn delete_conversation_message(&self, message_id: &str) -> DatabaseResult<()> {
        const COLLECTION: &str = "conversations";
        self.delete_vector(COLLECTION, message_id).await
    }
    
    // ========================================
    // æ–‡æ¡£ç®¡ç†
    // ========================================
    
    /// å­˜å‚¨æ–‡æ¡£
    pub async fn store_document(
        &self,
        document_id: &str,
        document_vector: Vec<f32>,
        document_data: &Document,
    ) -> DatabaseResult<()> {
        const COLLECTION: &str = "documents";
        
        // ç¡®ä¿é›†åˆå­˜åœ¨
        if !self.collection_exists(COLLECTION).await? {
            self.create_collection(COLLECTION, 384).await?;
        }
        
        self.insert_vector(COLLECTION, document_id, document_vector, document_data)
            .await
    }
    
    /// æ‰¹é‡å­˜å‚¨æ–‡æ¡£
    pub async fn batch_store_documents(
        &self,
        documents: Vec<(String, Vec<f32>, Document)>,
    ) -> DatabaseResult<()> {
        const COLLECTION: &str = "documents";
        
        // ç¡®ä¿é›†åˆå­˜åœ¨
        if !self.collection_exists(COLLECTION).await? {
            self.create_collection(COLLECTION, 384).await?;
        }
        
        self.batch_insert_vectors(COLLECTION, documents).await
    }
    
    /// è¯­ä¹‰æœç´¢æ–‡æ¡£
    pub async fn semantic_search_documents(
        &self,
        query_vector: Vec<f32>,
        limit: usize,
    ) -> DatabaseResult<Vec<VectorSearchResult>> {
        const COLLECTION: &str = "documents";
        
        self.search(COLLECTION, query_vector, limit).await
    }
    
    /// æœç´¢ç‰¹å®šç±»å‹çš„æ–‡æ¡£
    pub async fn search_documents_by_type(
        &self,
        document_type: &str,
        query_vector: Vec<f32>,
        limit: usize,
    ) -> DatabaseResult<Vec<VectorSearchResult>> {
        use crate::database::backends::{QueryCondition, QueryOperator, QueryOptions};
        
        const COLLECTION: &str = "documents";
        
        let filter = QueryOptions {
            conditions: vec![QueryCondition {
                field: "type".to_string(),
                operator: QueryOperator::Eq,
                value: serde_json::Value::String(document_type.to_string()),
            }],
            limit: Some(limit),
            offset: None,
            order_by: None,
        };
        
        self.search_with_filter(COLLECTION, query_vector, limit, &filter)
            .await
    }
    
    /// åˆ é™¤æ–‡æ¡£
    pub async fn delete_document(&self, document_id: &str) -> DatabaseResult<()> {
        const COLLECTION: &str = "documents";
        self.delete_vector(COLLECTION, document_id).await
    }
    
    // ========================================
    // çŸ¥è¯†åº“ç®¡ç†
    // ========================================
    
    /// å­˜å‚¨çŸ¥è¯†åº“æ¡ç›®
    pub async fn store_knowledge(
        &self,
        knowledge_id: &str,
        knowledge_vector: Vec<f32>,
        knowledge_data: &Knowledge,
    ) -> DatabaseResult<()> {
        const COLLECTION: &str = "knowledge_base";
        
        // ç¡®ä¿é›†åˆå­˜åœ¨
        if !self.collection_exists(COLLECTION).await? {
            self.create_collection(COLLECTION, 384).await?;
        }
        
        self.insert_vector(COLLECTION, knowledge_id, knowledge_vector, knowledge_data)
            .await
    }
    
    /// æœç´¢çŸ¥è¯†åº“
    pub async fn search_knowledge(
        &self,
        query_vector: Vec<f32>,
        limit: usize,
    ) -> DatabaseResult<Vec<VectorSearchResult>> {
        const COLLECTION: &str = "knowledge_base";
        
        self.search(COLLECTION, query_vector, limit).await
    }
    
    /// åˆ é™¤çŸ¥è¯†åº“æ¡ç›®
    pub async fn delete_knowledge(&self, knowledge_id: &str) -> DatabaseResult<()> {
        const COLLECTION: &str = "knowledge_base";
        self.delete_vector(COLLECTION, knowledge_id).await
    }
}

// ========================================
// æ•°æ®æ¨¡å‹
// ========================================

/// å¯¹è¯æ¶ˆæ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ConversationMessage {
    /// æ¶ˆæ¯ID
    pub message_id: String,
    /// ç”¨æˆ·ID
    pub user_id: String,
    /// ä¼šè¯ID
    pub session_id: String,
    /// æ¶ˆæ¯å†…å®¹
    pub content: String,
    /// æ¶ˆæ¯ç±»å‹ï¼ˆuser/assistant/systemï¼‰
    pub message_type: String,
    /// æ—¶é—´æˆ³
    pub timestamp: i64,
    /// å…ƒæ•°æ®
    pub metadata: Option<serde_json::Value>,
}

/// æ–‡æ¡£
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Document {
    /// æ–‡æ¡£ID
    pub document_id: String,
    /// æ–‡æ¡£æ ‡é¢˜
    pub title: String,
    /// æ–‡æ¡£å†…å®¹
    pub content: String,
    /// æ–‡æ¡£ç±»å‹
    #[serde(rename = "type")]
    pub document_type: String,
    /// ä½œè€…
    pub author: Option<String>,
    /// æ ‡ç­¾
    pub tags: Vec<String>,
    /// åˆ›å»ºæ—¶é—´
    pub created_at: i64,
    /// å…ƒæ•°æ®
    pub metadata: Option<serde_json::Value>,
}

/// çŸ¥è¯†åº“æ¡ç›®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Knowledge {
    /// çŸ¥è¯†ID
    pub knowledge_id: String,
    /// é—®é¢˜
    pub question: String,
    /// ç­”æ¡ˆ
    pub answer: String,
    /// åˆ†ç±»
    pub category: String,
    /// ä¼˜å…ˆçº§
    pub priority: i32,
    /// æ ‡ç­¾
    pub tags: Vec<String>,
    /// åˆ›å»ºæ—¶é—´
    pub created_at: i64,
    /// å…ƒæ•°æ®
    pub metadata: Option<serde_json::Value>,
}

/// å‘é‡åŒ–å·¥å…·
pub struct VectorEmbedding;

impl VectorEmbedding {
    /// ç”Ÿæˆæ–‡æœ¬å‘é‡ï¼ˆéœ€è¦æ¥å…¥å®é™…çš„åµŒå…¥æ¨¡å‹ï¼‰
    /// è¿™é‡Œæä¾›ä¸€ä¸ªå ä½å®ç°ï¼Œå®é™…ä½¿ç”¨æ—¶åº”æ›¿æ¢ä¸ºçœŸå®çš„åµŒå…¥æ¨¡å‹
    pub async fn embed_text(text: &str) -> DatabaseResult<Vec<f32>> {
        // TODO: æ¥å…¥å®é™…çš„åµŒå…¥æ¨¡å‹ï¼ˆå¦‚ OpenAI Embeddings, Sentence Transformers ç­‰ï¼‰
        // è¿™é‡Œè¿”å›ä¸€ä¸ªç®€å•çš„å ä½å‘é‡
        warn!("ä½¿ç”¨å ä½å‘é‡åµŒå…¥ï¼Œè¯·æ¥å…¥å®é™…çš„åµŒå…¥æ¨¡å‹");
        
        // ä½¿ç”¨ç®€å•çš„å“ˆå¸Œç”Ÿæˆä¼ªå‘é‡ï¼ˆä»…ç”¨äºå¼€å‘æµ‹è¯•ï¼‰
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};
        
        let mut hasher = DefaultHasher::new();
        text.hash(&mut hasher);
        let hash = hasher.finish();
        
        // ç”Ÿæˆ384ç»´å‘é‡ï¼ˆé»˜è®¤ç»´åº¦ï¼‰
        let mut vector = vec![0.0f32; 384];
        for i in 0..384 {
            let seed = hash.wrapping_add(i as u64);
            vector[i] = ((seed % 10000) as f32 / 10000.0) - 0.5;
        }
        
        // å½’ä¸€åŒ–
        let magnitude: f32 = vector.iter().map(|x| x * x).sum::<f32>().sqrt();
        if magnitude > 0.0 {
            for v in &mut vector {
                *v /= magnitude;
            }
        }
        
        Ok(vector)
    }
    
    /// æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡
    pub async fn batch_embed_texts(texts: Vec<&str>) -> DatabaseResult<Vec<Vec<f32>>> {
        let mut vectors = Vec::new();
        for text in texts {
            vectors.push(Self::embed_text(text).await?);
        }
        Ok(vectors)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::time::{sleep, Duration};
    use std::collections::HashMap;
    
    // åˆ›å»ºMockåç«¯ç”¨äºæµ‹è¯•
    fn create_mock_backend() -> Arc<RwLock<QdrantBackend>> {
        Arc::new(RwLock::new(QdrantBackend::new()))
    }
    
    // åˆ›å»ºæµ‹è¯•å‘é‡
    fn create_test_vector(size: usize) -> Vec<f32> {
        (0..size).map(|i| (i as f32) / (size as f32)).collect()
    }
    
    // åˆ›å»ºå½’ä¸€åŒ–æµ‹è¯•å‘é‡
    fn create_normalized_vector(size: usize) -> Vec<f32> {
        let mut vector = create_test_vector(size);
        let magnitude: f32 = vector.iter().map(|x| x * x).sum::<f32>().sqrt();
        if magnitude > 0.0 {
            for v in &mut vector {
                *v /= magnitude;
            }
        }
        vector
    }
    
    // ========================================
    // VectorEmbeddingæµ‹è¯•
    // ========================================
    
    #[tokio::test]
    async fn test_vector_embedding() {
        let text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬";
        let vector = VectorEmbedding::embed_text(text).await.unwrap();
        
        assert_eq!(vector.len(), 384);
        
        // æ£€æŸ¥å½’ä¸€åŒ–
        let magnitude: f32 = vector.iter().map(|x| x * x).sum::<f32>().sqrt();
        assert!((magnitude - 1.0).abs() < 0.001);
    }
    
    #[tokio::test]
    async fn test_batch_embedding() {
        let texts = vec!["æ–‡æœ¬1", "æ–‡æœ¬2", "æ–‡æœ¬3"];
        let vectors = VectorEmbedding::batch_embed_texts(texts).await.unwrap();
        
        assert_eq!(vectors.len(), 3);
        for vector in vectors {
            assert_eq!(vector.len(), 384);
        }
    }
    
    #[tokio::test]
    async fn test_embedding_consistency() {
        let text = "ç›¸åŒçš„æ–‡æœ¬åº”è¯¥äº§ç”Ÿç›¸åŒçš„å‘é‡";
        
        let vector1 = VectorEmbedding::embed_text(text).await.unwrap();
        let vector2 = VectorEmbedding::embed_text(text).await.unwrap();
        
        assert_eq!(vector1, vector2, "ç›¸åŒæ–‡æœ¬åº”è¯¥äº§ç”Ÿç›¸åŒå‘é‡");
    }
    
    #[tokio::test]
    async fn test_embedding_different_texts() {
        let text1 = "ç¬¬ä¸€ä¸ªæ–‡æœ¬";
        let text2 = "ç¬¬äºŒä¸ªæ–‡æœ¬";
        
        let vector1 = VectorEmbedding::embed_text(text1).await.unwrap();
        let vector2 = VectorEmbedding::embed_text(text2).await.unwrap();
        
        assert_ne!(vector1, vector2, "ä¸åŒæ–‡æœ¬åº”è¯¥äº§ç”Ÿä¸åŒå‘é‡");
    }
    
    #[tokio::test]
    async fn test_embedding_edge_cases() {
        // ç©ºå­—ç¬¦ä¸²
        let empty_vector = VectorEmbedding::embed_text("").await.unwrap();
        assert_eq!(empty_vector.len(), 384);
        
        // é•¿æ–‡æœ¬
        let long_text = "é•¿".repeat(10000);
        let long_vector = VectorEmbedding::embed_text(&long_text).await.unwrap();
        assert_eq!(long_vector.len(), 384);
        
        // ç‰¹æ®Šå­—ç¬¦
        let special_text = "!@#$%^&*()_+-={}|[]\\:\";'<>?,./";
        let special_vector = VectorEmbedding::embed_text(special_text).await.unwrap();
        assert_eq!(special_vector.len(), 384);
        
        // Unicodeå­—ç¬¦
        let unicode_text = "ğŸš€ğŸ¦€ğŸ’»ğŸŒŸ";
        let unicode_vector = VectorEmbedding::embed_text(unicode_text).await.unwrap();
        assert_eq!(unicode_vector.len(), 384);
    }
    
    #[tokio::test]
    async fn test_batch_embedding_empty() {
        let empty_texts: Vec<&str> = vec![];
        let vectors = VectorEmbedding::batch_embed_texts(empty_texts).await.unwrap();
        assert_eq!(vectors.len(), 0);
    }
    
    #[tokio::test]
    async fn test_batch_embedding_large() {
        let texts: Vec<String> = (0..100).map(|i| format!("æ–‡æœ¬{}", i)).collect();
        let text_refs: Vec<&str> = texts.iter().map(|s| s.as_str()).collect();
        
        let vectors = VectorEmbedding::batch_embed_texts(text_refs).await.unwrap();
        assert_eq!(vectors.len(), 100);
        
        for (i, vector) in vectors.iter().enumerate() {
            assert_eq!(vector.len(), 384, "å‘é‡{}é•¿åº¦ä¸æ­£ç¡®", i);
        }
    }
    
    // ========================================
    // VectorSearchServiceåŸºç¡€æµ‹è¯•
    // ========================================
    
    #[tokio::test]
    async fn test_service_creation() {
        let backend = create_mock_backend();
        let service = VectorSearchService::new(backend);
        
        // æµ‹è¯•æœåŠ¡åˆ›å»ºæˆåŠŸ
        // ç”±äºVectorSearchServiceæ²¡æœ‰å…¬å¼€å­—æ®µï¼Œæˆ‘ä»¬åªèƒ½æµ‹è¯•åˆ›å»ºä¸ä¼španic
        assert!(true);
    }
    
    // ========================================
    // é›†åˆç®¡ç†æµ‹è¯•
    // ========================================
    
    #[tokio::test]
    async fn test_collection_operations() {
        let backend = create_mock_backend();
        let service = VectorSearchService::new(backend);
        
        let collection_name = "test_collection";
        let vector_size = 384;
        
        // æµ‹è¯•åˆ›å»ºé›†åˆ
        let result = service.create_collection(collection_name, vector_size).await;
        assert!(result.is_err() || result.is_ok());
        
        // æµ‹è¯•æ£€æŸ¥é›†åˆå­˜åœ¨
        let result = service.collection_exists(collection_name).await;
        assert!(result.is_err() || result.is_ok());
        
        // æµ‹è¯•åˆ é™¤é›†åˆ
        let result = service.delete_collection(collection_name).await;
        assert!(result.is_err() || result.is_ok());
    }
    
    #[tokio::test]
    async fn test_collection_edge_cases() {
        let backend = create_mock_backend();
        let service = VectorSearchService::new(backend);
        
        // æµ‹è¯•è¾¹ç•Œæƒ…å†µ
        let test_cases = vec![
            ("", 384),                    // ç©ºåç§°
            ("normal_collection", 0),     // é›¶ç»´å‘é‡
            ("large_collection", 10000),  // å¤§ç»´åº¦
            ("unicode_é›†åˆ", 384),        // Unicodeåç§°
            ("special-chars_123", 384),   // ç‰¹æ®Šå­—ç¬¦
        ];
        
        for (name, size) in test_cases {
            let result = service.create_collection(name, size).await;
            assert!(result.is_err() || result.is_ok());
        }
    }
    
    // ========================================
    // å‘é‡æ“ä½œæµ‹è¯•
    // ========================================
    
    #[tokio::test]
    async fn test_vector_operations() {
        let backend = create_mock_backend();
        let service = VectorSearchService::new(backend);
        
        let collection = "vectors_test";
        let vector_id = "vec_001";
        let test_vector = create_normalized_vector(384);
        let payload = ConversationMessage {
            message_id: "msg_001".to_string(),
            user_id: "user_001".to_string(),
            session_id: "session_001".to_string(),
            content: "æµ‹è¯•æ¶ˆæ¯".to_string(),
            message_type: "user".to_string(),
            timestamp: 1640995200,
            metadata: None,
        };
        
        // æµ‹è¯•æ’å…¥å‘é‡
        let result = service.insert_vector(collection, vector_id, test_vector.clone(), &payload).await;
        assert!(result.is_err() || result.is_ok());
        
        // æµ‹è¯•åˆ é™¤å‘é‡
        let result = service.delete_vector(collection, vector_id).await;
        assert!(result.is_err() || result.is_ok());
    }
    
    #[tokio::test]
    async fn test_batch_vector_operations() {
        let backend = create_mock_backend();
        let service = VectorSearchService::new(backend);
        
        let collection = "batch_test";
        
        // å‡†å¤‡æ‰¹é‡æ•°æ®
        let mut batch_items = Vec::new();
        for i in 0..10 {
            let id = format!("batch_vec_{}", i);
            let vector = create_normalized_vector(384);
            let payload = ConversationMessage {
                message_id: format!("batch_msg_{}", i),
                user_id: format!("user_{}", i),
                session_id: "batch_session".to_string(),
                content: format!("æ‰¹é‡æ¶ˆæ¯{}", i),
                message_type: "user".to_string(),
                timestamp: 1640995200 + i as i64,
                metadata: None,
            };
            batch_items.push((id, vector, payload));
        }
        
        // æµ‹è¯•æ‰¹é‡æ’å…¥
        let result = service.batch_insert_vectors(collection, batch_items).await;
        assert!(result.is_err() || result.is_ok());
    }
    
    #[tokio::test]
    async fn test_vector_operations_edge_cases() {
        let backend = create_mock_backend();
        let service = VectorSearchService::new(backend);
        
        let collection = "edge_test";
        let payload = ConversationMessage {
            message_id: "edge_msg".to_string(),
            user_id: "edge_user".to_string(),
            session_id: "edge_session".to_string(),
            content: "è¾¹ç•Œæµ‹è¯•".to_string(),
            message_type: "system".to_string(),
            timestamp: 0,
            metadata: Some(serde_json::json!({"test": true})),
        };
        
        // æµ‹è¯•å„ç§å‘é‡å¤§å°
        let test_cases = vec![
            ("empty_vec", vec![]),           // ç©ºå‘é‡
            ("single_vec", vec![1.0]),       // å•å…ƒç´ å‘é‡
            ("large_vec", vec![0.5; 2048]),  // å¤§å‘é‡
        ];
        
        for (id, vector) in test_cases {
            let result = service.insert_vector(collection, id, vector, &payload).await;
            assert!(result.is_err() || result.is_ok());
        }
    }
    
    // ========================================
    // å‘é‡æœç´¢æµ‹è¯•
    // ========================================
    
    #[tokio::test]
    async fn test_vector_search() {
        let backend = create_mock_backend();
        let service = VectorSearchService::new(backend);
        
        let collection = "search_test";
        let query_vector = create_normalized_vector(384);
        let limit = 10;
        
        // æµ‹è¯•åŸºæœ¬æœç´¢
        let result = service.search(collection, query_vector.clone(), limit).await;
        assert!(result.is_err() || result.is_ok());
        
        // æµ‹è¯•å¸¦è¿‡æ»¤çš„æœç´¢
        use crate::database::backends::{QueryCondition, QueryOperator, QueryOptions};
        let filter = QueryOptions {
            conditions: vec![QueryCondition {
                field: "user_id".to_string(),
                operator: QueryOperator::Eq,
                value: serde_json::Value::String("test_user".to_string()),
            }],
            limit: Some(limit),
            offset: None,
            order_by: None,
        };
        
        let result = service.search_with_filter(collection, query_vector, limit, &filter).await;
        assert!(result.is_err() || result.is_ok());
    }
    
    #[tokio::test]
    async fn test_search_edge_cases() {
        let backend = create_mock_backend();
        let service = VectorSearchService::new(backend);
        
        let collection = "search_edge_test";
        
        // æµ‹è¯•å„ç§æœç´¢å‚æ•°
        let test_cases = vec![
            (vec![], 0),                           // ç©ºå‘é‡ï¼Œé›¶é™åˆ¶
            (create_test_vector(1), 1),           // å°å‘é‡ï¼Œå°é™åˆ¶
            (create_test_vector(384), usize::MAX), // æ­£å¸¸å‘é‡ï¼Œæœ€å¤§é™åˆ¶
        ];
        
        for (query_vector, limit) in test_cases {
            let result = service.search(collection, query_vector, limit).await;
            assert!(result.is_err() || result.is_ok());
        }
    }
    
    // ========================================
    // å¯¹è¯å†å²ç®¡ç†æµ‹è¯•
    // ========================================
    
    #[tokio::test]
    async fn test_conversation_management() {
        let backend = create_mock_backend();
        let service = VectorSearchService::new(backend);
        
        let message_id = "conv_msg_001";
        let message_vector = create_normalized_vector(384);
        let message_data = ConversationMessage {
            message_id: message_id.to_string(),
            user_id: "conv_user_001".to_string(),
            session_id: "conv_session_001".to_string(),
            content: "å¯¹è¯æµ‹è¯•æ¶ˆæ¯".to_string(),
            message_type: "user".to_string(),
            timestamp: 1640995200,
            metadata: Some(serde_json::json!({"test": "conversation"})),
        };
        
        // æµ‹è¯•å­˜å‚¨å¯¹è¯æ¶ˆæ¯
        let result = service.store_conversation_message(message_id, message_vector.clone(), &message_data).await;
        assert!(result.is_err() || result.is_ok());
        
        // æµ‹è¯•æœç´¢ç›¸ä¼¼å¯¹è¯
        let result = service.search_similar_conversations(message_vector.clone(), 5).await;
        assert!(result.is_err() || result.is_ok());
        
        // æµ‹è¯•æœç´¢ç”¨æˆ·å¯¹è¯å†å²
        let result = service.search_user_conversations("conv_user_001", message_vector, 10).await;
        assert!(result.is_err() || result.is_ok());
        
        // æµ‹è¯•åˆ é™¤å¯¹è¯æ¶ˆæ¯
        let result = service.delete_conversation_message(message_id).await;
        assert!(result.is_err() || result.is_ok());
    }
    
    #[tokio::test]
    async fn test_conversation_edge_cases() {
        let backend = create_mock_backend();
        let service = VectorSearchService::new(backend);
        
        // æµ‹è¯•å„ç§è¾¹ç•Œæƒ…å†µ
        let edge_cases = vec![
            ConversationMessage {
                message_id: "".to_string(),                    // ç©ºID
                user_id: "".to_string(),                       // ç©ºç”¨æˆ·ID
                session_id: "".to_string(),                    // ç©ºä¼šè¯ID
                content: "".to_string(),                       // ç©ºå†…å®¹
                message_type: "".to_string(),                  // ç©ºç±»å‹
                timestamp: 0,                                   // é›¶æ—¶é—´æˆ³
                metadata: None,
            },
            ConversationMessage {
                message_id: "long_id".repeat(100),             // é•¿ID
                user_id: "long_user".repeat(100),              // é•¿ç”¨æˆ·ID
                session_id: "long_session".repeat(100),        // é•¿ä¼šè¯ID
                content: "é•¿å†…å®¹".repeat(1000),                // é•¿å†…å®¹
                message_type: "custom_type".to_string(),       // è‡ªå®šä¹‰ç±»å‹
                timestamp: i64::MAX,                           // æœ€å¤§æ—¶é—´æˆ³
                metadata: Some(serde_json::json!({"complex": {"nested": {"data": [1, 2, 3]}}})),
            },
        ];
        
        for (i, message_data) in edge_cases.iter().enumerate() {
            let message_id = format!("edge_msg_{}", i);
            let message_vector = create_normalized_vector(384);
            let result = service.store_conversation_message(&message_id, message_vector, message_data).await;
            assert!(result.is_err() || result.is_ok());
        }
    }
    
    // ========================================
    // æ–‡æ¡£ç®¡ç†æµ‹è¯•
    // ========================================
    
    #[tokio::test]
    async fn test_document_management() {
        let backend = create_mock_backend();
        let service = VectorSearchService::new(backend);
        
        let document_id = "doc_001";
        let document_vector = create_normalized_vector(384);
        let document_data = Document {
            document_id: document_id.to_string(),
            title: "æµ‹è¯•æ–‡æ¡£".to_string(),
            content: "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£çš„å†…å®¹".to_string(),
            document_type: "text".to_string(),
            author: Some("æµ‹è¯•ä½œè€…".to_string()),
            tags: vec!["æµ‹è¯•".to_string(), "æ–‡æ¡£".to_string()],
            created_at: 1640995200,
            metadata: Some(serde_json::json!({"category": "test"})),
        };
        
        // æµ‹è¯•å­˜å‚¨æ–‡æ¡£
        let result = service.store_document(document_id, document_vector.clone(), &document_data).await;
        assert!(result.is_err() || result.is_ok());
        
        // æµ‹è¯•è¯­ä¹‰æœç´¢æ–‡æ¡£
        let result = service.semantic_search_documents(document_vector.clone(), 10).await;
        assert!(result.is_err() || result.is_ok());
        
        // æµ‹è¯•æŒ‰ç±»å‹æœç´¢æ–‡æ¡£
        let result = service.search_documents_by_type("text", document_vector, 5).await;
        assert!(result.is_err() || result.is_ok());
        
        // æµ‹è¯•åˆ é™¤æ–‡æ¡£
        let result = service.delete_document(document_id).await;
        assert!(result.is_err() || result.is_ok());
    }
    
    #[tokio::test]
    async fn test_batch_document_operations() {
        let backend = create_mock_backend();
        let service = VectorSearchService::new(backend);
        
        // å‡†å¤‡æ‰¹é‡æ–‡æ¡£æ•°æ®
        let mut documents = Vec::new();
        for i in 0..5 {
            let document_id = format!("batch_doc_{}", i);
            let document_vector = create_normalized_vector(384);
            let document_data = Document {
                document_id: document_id.clone(),
                title: format!("æ‰¹é‡æ–‡æ¡£{}", i),
                content: format!("è¿™æ˜¯ç¬¬{}ä¸ªæ‰¹é‡æ–‡æ¡£çš„å†…å®¹", i),
                document_type: "batch".to_string(),
                author: Some(format!("ä½œè€…{}", i)),
                tags: vec![format!("æ ‡ç­¾{}", i), "æ‰¹é‡".to_string()],
                created_at: 1640995200 + i as i64,
                metadata: Some(serde_json::json!({"index": i})),
            };
            documents.push((document_id, document_vector, document_data));
        }
        
        // æµ‹è¯•æ‰¹é‡å­˜å‚¨
        let result = service.batch_store_documents(documents).await;
        assert!(result.is_err() || result.is_ok());
    }
    
    // ========================================
    // çŸ¥è¯†åº“ç®¡ç†æµ‹è¯•
    // ========================================
    
    #[tokio::test]
    async fn test_knowledge_management() {
        let backend = create_mock_backend();
        let service = VectorSearchService::new(backend);
        
        let knowledge_id = "knowledge_001";
        let knowledge_vector = create_normalized_vector(384);
        let knowledge_data = Knowledge {
            knowledge_id: knowledge_id.to_string(),
            question: "ä»€ä¹ˆæ˜¯Rustç¼–ç¨‹è¯­è¨€ï¼Ÿ".to_string(),
            answer: "Rustæ˜¯ä¸€ç§ç³»ç»Ÿç¼–ç¨‹è¯­è¨€ï¼Œä¸“æ³¨äºå®‰å…¨ã€é€Ÿåº¦å’Œå¹¶å‘ã€‚".to_string(),
            category: "ç¼–ç¨‹è¯­è¨€".to_string(),
            priority: 1,
            tags: vec!["Rust".to_string(), "ç¼–ç¨‹".to_string(), "ç³»ç»Ÿè¯­è¨€".to_string()],
            created_at: 1640995200,
            metadata: Some(serde_json::json!({"source": "manual"})),
        };
        
        // æµ‹è¯•å­˜å‚¨çŸ¥è¯†åº“æ¡ç›®
        let result = service.store_knowledge(knowledge_id, knowledge_vector.clone(), &knowledge_data).await;
        assert!(result.is_err() || result.is_ok());
        
        // æµ‹è¯•æœç´¢çŸ¥è¯†åº“
        let result = service.search_knowledge(knowledge_vector, 10).await;
        assert!(result.is_err() || result.is_ok());
        
        // æµ‹è¯•åˆ é™¤çŸ¥è¯†åº“æ¡ç›®
        let result = service.delete_knowledge(knowledge_id).await;
        assert!(result.is_err() || result.is_ok());
    }
    
    #[tokio::test]
    async fn test_knowledge_edge_cases() {
        let backend = create_mock_backend();
        let service = VectorSearchService::new(backend);
        
        let edge_knowledge = Knowledge {
            knowledge_id: "".to_string(),                      // ç©ºID
            question: "".to_string(),                          // ç©ºé—®é¢˜
            answer: "".to_string(),                            // ç©ºç­”æ¡ˆ
            category: "".to_string(),                          // ç©ºåˆ†ç±»
            priority: i32::MIN,                                // æœ€å°ä¼˜å…ˆçº§
            tags: vec![],                                      // ç©ºæ ‡ç­¾
            created_at: i64::MIN,                              // æœ€å°æ—¶é—´æˆ³
            metadata: None,
        };
        
        let knowledge_vector = create_normalized_vector(384);
        let result = service.store_knowledge("edge_knowledge", knowledge_vector, &edge_knowledge).await;
        assert!(result.is_err() || result.is_ok());
    }
    
    // ========================================
    // å¹¶å‘å’Œæ€§èƒ½æµ‹è¯•
    // ========================================
    
    #[tokio::test]
    async fn test_concurrent_operations() {
        let backend = create_mock_backend();
        let service = Arc::new(VectorSearchService::new(backend));
        
        let mut handles = vec![];
        
        // åˆ›å»ºå¤šä¸ªå¹¶å‘ä»»åŠ¡
        for i in 0..10 {
            let service_clone = Arc::clone(&service);
            let handle = tokio::spawn(async move {
                let collection = format!("concurrent_collection_{}", i);
                let vector = create_normalized_vector(384);
                let document = Document {
                    document_id: format!("concurrent_doc_{}", i),
                    title: format!("å¹¶å‘æ–‡æ¡£{}", i),
                    content: format!("å¹¶å‘å†…å®¹{}", i),
                    document_type: "concurrent".to_string(),
                    author: None,
                    tags: vec![],
                    created_at: 1640995200,
                    metadata: None,
                };
                
                // å¹¶å‘æ‰§è¡Œå¤šç§æ“ä½œ
                let _ = service_clone.create_collection(&collection, 384).await;
                let _ = service_clone.store_document(&format!("doc_{}", i), vector.clone(), &document).await;
                let _ = service_clone.semantic_search_documents(vector, 5).await;
                let _ = service_clone.delete_collection(&collection).await;
            });
            handles.push(handle);
        }
        
        // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for handle in handles {
            let _ = handle.await;
        }
        
        // æµ‹è¯•é€šè¿‡ - æ²¡æœ‰æ­»é”
        assert!(true);
    }
    
    #[tokio::test]
    async fn test_no_deadlock_scenario() {
        let backend = create_mock_backend();
        let service = Arc::new(VectorSearchService::new(backend));
        
        let service1 = Arc::clone(&service);
        let service2 = Arc::clone(&service);
        
        let handle1 = tokio::spawn(async move {
            for i in 0..5 {
                let vector = create_normalized_vector(384);
                let _ = service1.semantic_search_documents(vector, 10).await;
                tokio::task::yield_now().await;
            }
        });
        
        let handle2 = tokio::spawn(async move {
            for i in 0..5 {
                let vector = create_normalized_vector(384);
                let _ = service2.search_knowledge(vector, 10).await;
                tokio::task::yield_now().await;
            }
        });
        
        // è®¾ç½®è¶…æ—¶ä»¥é˜²æ­¢æµ‹è¯•å¡ä½
        let timeout_result = tokio::time::timeout(
            Duration::from_secs(5),
            async {
                let (_r1, _r2) = tokio::join!(handle1, handle2);
            }
        ).await;
        
        assert!(timeout_result.is_ok(), "æµ‹è¯•åº”è¯¥åœ¨è¶…æ—¶å‰å®Œæˆï¼Œæ²¡æœ‰æ­»é”");
    }
    
    // ========================================
    // æ•°æ®æ¨¡å‹æµ‹è¯•
    // ========================================
    
    #[test]
    fn test_conversation_message_serialization() {
        let message = ConversationMessage {
            message_id: "test_msg".to_string(),
            user_id: "test_user".to_string(),
            session_id: "test_session".to_string(),
            content: "æµ‹è¯•å†…å®¹".to_string(),
            message_type: "user".to_string(),
            timestamp: 1640995200,
            metadata: Some(serde_json::json!({"test": true})),
        };
        
        // æµ‹è¯•åºåˆ—åŒ–
        let serialized = serde_json::to_string(&message).unwrap();
        assert!(!serialized.is_empty());
        
        // æµ‹è¯•ååºåˆ—åŒ–
        let deserialized: ConversationMessage = serde_json::from_str(&serialized).unwrap();
        assert_eq!(deserialized.message_id, message.message_id);
        assert_eq!(deserialized.content, message.content);
    }
    
    #[test]
    fn test_document_serialization() {
        let document = Document {
            document_id: "test_doc".to_string(),
            title: "æµ‹è¯•æ–‡æ¡£".to_string(),
            content: "æµ‹è¯•å†…å®¹".to_string(),
            document_type: "test".to_string(),
            author: Some("æµ‹è¯•ä½œè€…".to_string()),
            tags: vec!["tag1".to_string(), "tag2".to_string()],
            created_at: 1640995200,
            metadata: Some(serde_json::json!({"category": "test"})),
        };
        
        // æµ‹è¯•åºåˆ—åŒ–
        let serialized = serde_json::to_string(&document).unwrap();
        assert!(!serialized.is_empty());
        
        // æµ‹è¯•ååºåˆ—åŒ–
        let deserialized: Document = serde_json::from_str(&serialized).unwrap();
        assert_eq!(deserialized.document_id, document.document_id);
        assert_eq!(deserialized.title, document.title);
        assert_eq!(deserialized.tags, document.tags);
    }
    
    #[test]
    fn test_knowledge_serialization() {
        let knowledge = Knowledge {
            knowledge_id: "test_knowledge".to_string(),
            question: "æµ‹è¯•é—®é¢˜".to_string(),
            answer: "æµ‹è¯•ç­”æ¡ˆ".to_string(),
            category: "æµ‹è¯•åˆ†ç±»".to_string(),
            priority: 1,
            tags: vec!["çŸ¥è¯†".to_string()],
            created_at: 1640995200,
            metadata: Some(serde_json::json!({"source": "test"})),
        };
        
        // æµ‹è¯•åºåˆ—åŒ–
        let serialized = serde_json::to_string(&knowledge).unwrap();
        assert!(!serialized.is_empty());
        
        // æµ‹è¯•ååºåˆ—åŒ–
        let deserialized: Knowledge = serde_json::from_str(&serialized).unwrap();
        assert_eq!(deserialized.knowledge_id, knowledge.knowledge_id);
        assert_eq!(deserialized.question, knowledge.question);
        assert_eq!(deserialized.answer, knowledge.answer);
    }
}

