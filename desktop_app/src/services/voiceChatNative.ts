/**
 * åŸç”Ÿè¯­éŸ³å¯¹è¯æœåŠ¡ï¼ˆä½¿ç”¨ Tauri éŸ³é¢‘ APIï¼‰
 * ä¸ä¾èµ–æµè§ˆå™¨ getUserMediaï¼Œå®Œå…¨ä½¿ç”¨åç«¯éŸ³é¢‘æ•è·
 */

import { invoke } from '@tauri-apps/api/tauri'

/**
 * ç”Ÿæˆ UUID
 */
function generateUUID(): string {
    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
        const r = Math.random() * 16 | 0
        const v = c === 'x' ? r : (r & 0x3 | 0x8)
        return v.toString(16)
    })
}

/**
 * éŸ³é¢‘é…ç½®
 */
export interface AudioConfig {
    sample_rate: number
    channels: number
    bits_per_sample: number
}

/**
 * è¯­éŸ³å¯¹è¯é…ç½®
 */
export interface VoiceChatNativeConfig {
    /** WebSocket URL */
    wsUrl: string
    /** éŸ³é¢‘é…ç½® */
    audio?: AudioConfig
    /** è§’è‰²é…ç½® */
    character?: {
        characterId?: string
        adapterId?: string
        systemPrompt?: string
        model?: string
    }
    /** STT é…ç½® */
    stt?: {
        model?: string
        language?: string
    }
    /** TTS é…ç½® */
    tts?: {
        voice?: string
        rate?: string
        volume?: string
        pitch?: string
    }
}

/**
 * è¯­éŸ³å¯¹è¯äº‹ä»¶
 */
export interface VoiceChatNativeEvents {
    onReady?: () => void
    onTranscription?: (text: string, isFinal: boolean) => void
    onResponse?: (text: string) => void
    onAudioData?: (audioData: Blob) => void
    onSpeechEnd?: () => void
    onInterrupted?: () => void
    onError?: (error: string) => void
    onDisconnect?: () => void
}

/**
 * WebSocket æ¶ˆæ¯ç±»å‹
 */
enum MessageType {
    CONFIG = 'config',
    AUDIO = 'audio',
    TEXT = 'text',
    INTERRUPT = 'interrupt',
    CLOSE = 'close',
    READY = 'ready',
    CONFIGURED = 'configured',
    TRANSCRIPTION = 'transcription',
    RESPONSE = 'response',
    SPEECH_END = 'speech_end',
    INTERRUPTED = 'interrupted',
    ERROR = 'error',
}

/**
 * åŸç”Ÿè¯­éŸ³å¯¹è¯æœåŠ¡ç±»
 */
export class VoiceChatNativeService {
    private ws: WebSocket | null = null
    private sessionId: string
    private config: VoiceChatNativeConfig
    private events: VoiceChatNativeEvents
    private isRecording = false
    private isSpeaking = false
    private audioQueue: Blob[] = []
    private isPlaying = false
    private recordingTimer: number | null = null

    constructor(config: VoiceChatNativeConfig, events: VoiceChatNativeEvents = {}) {
        this.sessionId = generateUUID()
        this.config = config
        this.events = events
    }

    /**
     * è¿æ¥åˆ°è¯­éŸ³å¯¹è¯æœåŠ¡
     */
    async connect(): Promise<void> {
        return new Promise((resolve, reject) => {
            try {
                const wsUrl = `${this.config.wsUrl}/ws/${this.sessionId}`
                console.log(`ğŸ”Œ è¿æ¥åˆ°: ${wsUrl}`)
                this.ws = new WebSocket(wsUrl)

                this.ws.onopen = () => {
                    console.log('âœ… WebSocket å·²è¿æ¥')
                }

                this.ws.onmessage = async (event) => {
                    const message = JSON.parse(event.data)
                    await this.handleMessage(message)

                    // ç¬¬ä¸€æ¬¡æ”¶åˆ° ready æ¶ˆæ¯åè§£æ promise
                    if (message.type === MessageType.READY) {
                        this.sendConfig()
                        resolve()
                    }
                }

                this.ws.onerror = (error) => {
                    console.error('âŒ WebSocket é”™è¯¯:', error)
                    this.events.onError?.('WebSocket è¿æ¥å¤±è´¥')
                    reject(error)
                }

                this.ws.onclose = () => {
                    console.log('ğŸ”Œ WebSocket å·²æ–­å¼€')
                    this.cleanup()
                    this.events.onDisconnect?.()
                }
            } catch (error) {
                console.error('è¿æ¥å¤±è´¥:', error)
                reject(error)
            }
        })
    }

    /**
     * å‘é€é…ç½®åˆ°æœåŠ¡å™¨
     */
    private sendConfig(): void {
        this.send({
            type: MessageType.CONFIG,
            data: {
                stt: this.config.stt || {},
                tts: this.config.tts || {},
                character_id: this.config.character?.characterId,
                adapter_id: this.config.character?.adapterId,
                system_prompt: this.config.character?.systemPrompt,
                model: this.config.character?.model || 'default',
            },
        })
    }

    /**
     * å¼€å§‹å½•éŸ³ï¼ˆä½¿ç”¨ Tauri åŸç”Ÿ APIï¼‰
     */
    async startRecording(): Promise<void> {
        if (this.isRecording) {
            console.warn('å·²ç»åœ¨å½•éŸ³ä¸­')
            return
        }

        try {
            // è·å–éŸ³é¢‘è®¾å¤‡åˆ—è¡¨
            const devices = await invoke<string[]>('list_audio_devices')
            console.log('ğŸ“‹ å¯ç”¨éŸ³é¢‘è®¾å¤‡:', devices)

            if (devices.length === 0) {
                throw new Error('æœªæ‰¾åˆ°éŸ³é¢‘è¾“å…¥è®¾å¤‡')
            }

            // å‡†å¤‡éŸ³é¢‘é…ç½®
            const audioConfig: AudioConfig = {
                sample_rate: this.config.audio?.sample_rate || 16000,
                channels: this.config.audio?.channels || 1,
                bits_per_sample: this.config.audio?.bits_per_sample || 16,
            }

            // å¯åŠ¨å½•éŸ³
            await invoke('start_recording', { config: audioConfig })
            this.isRecording = true
            console.log('ğŸ¤ å¼€å§‹å½•éŸ³ï¼ˆTauri åŸç”Ÿï¼‰')

            // å¯åŠ¨å®šæ—¶å™¨ï¼Œæ¯ 500ms è·å–éŸ³é¢‘æ•°æ®å¹¶å‘é€
            this.recordingTimer = window.setInterval(async () => {
                try {
                    const audioData = await invoke<string>('get_recording_data')
                    if (audioData && audioData.length > 0) {
                        // å‘é€éŸ³é¢‘æ•°æ®åˆ°æœåŠ¡å™¨
                        this.send({
                            type: MessageType.AUDIO,
                            data: audioData,
                        })
                    }
                } catch (error) {
                    console.error('è·å–å½•éŸ³æ•°æ®å¤±è´¥:', error)
                }
            }, 500)

        } catch (error) {
            console.error('å¯åŠ¨å½•éŸ³å¤±è´¥:', error)
            this.events.onError?.(`æ— æ³•å¯åŠ¨å½•éŸ³: ${error}`)
            throw error
        }
    }

    /**
     * åœæ­¢å½•éŸ³
     */
    async stopRecording(): Promise<void> {
        if (!this.isRecording) {
            return
        }

        // åœæ­¢å®šæ—¶å™¨
        if (this.recordingTimer) {
            clearInterval(this.recordingTimer)
            this.recordingTimer = null
        }

        try {
            // è·å–æœ€åçš„éŸ³é¢‘æ•°æ®
            const finalData = await invoke<string>('stop_recording')
            if (finalData && finalData.length > 0) {
                // å‘é€æœ€åçš„éŸ³é¢‘æ•°æ®
                this.send({
                    type: MessageType.AUDIO,
                    data: finalData,
                })
            }

            this.isRecording = false
            console.log('ğŸ›‘ åœæ­¢å½•éŸ³')
        } catch (error) {
            console.error('åœæ­¢å½•éŸ³å¤±è´¥:', error)
            // å³ä½¿å¤±è´¥ä¹Ÿå–æ¶ˆå½•éŸ³
            await invoke('cancel_recording').catch(console.error)
            this.isRecording = false
        }
    }

    /**
     * å‘é€æ–‡æœ¬æ¶ˆæ¯
     */
    sendText(text: string): void {
        this.send({
            type: MessageType.TEXT,
            data: text,
        })
    }

    /**
     * æ‰“æ–­å½“å‰è¯­éŸ³æ’­æ”¾
     */
    interrupt(): void {
        // åœæ­¢æœ¬åœ°æ’­æ”¾
        this.stopAudioPlayback()

        // é€šçŸ¥æœåŠ¡å™¨æ‰“æ–­
        this.send({
            type: MessageType.INTERRUPT,
        })

        this.isSpeaking = false
        console.log('â¸ï¸ æ‰“æ–­è¯­éŸ³æ’­æ”¾')
    }

    /**
     * å¤„ç†æœåŠ¡å™¨æ¶ˆæ¯
     */
    private async handleMessage(message: any): Promise<void> {
        switch (message.type) {
            case MessageType.READY:
                console.log('âœ… ä¼šè¯å·²å°±ç»ª:', message.session_id)
                this.events.onReady?.()
                break

            case MessageType.CONFIGURED:
                console.log('âœ… é…ç½®å·²åº”ç”¨')
                break

            case MessageType.TRANSCRIPTION:
                console.log('ğŸ“ è¯†åˆ«ç»“æœ:', message.data)
                this.events.onTranscription?.(message.data, message.isFinal ?? false)
                break

            case MessageType.RESPONSE:
                console.log('ğŸ’¬ AI å“åº”:', message.data)
                this.events.onResponse?.(message.data)
                this.isSpeaking = true
                break

            case MessageType.AUDIO:
                // æ¥æ”¶å¹¶æ’­æ”¾éŸ³é¢‘
                if (message.data) {
                    const audioBlob = this.base64ToBlob(message.data, 'audio/mpeg')
                    await this.playAudio(audioBlob)
                    this.events.onAudioData?.(audioBlob)
                }
                break

            case MessageType.SPEECH_END:
                console.log('ğŸ”‡ è¯­éŸ³æ’­æ”¾ç»“æŸ')
                this.isSpeaking = false
                this.events.onSpeechEnd?.()
                break

            case MessageType.INTERRUPTED:
                console.log('â¸ï¸ è¯­éŸ³å·²æ‰“æ–­')
                this.isSpeaking = false
                this.events.onInterrupted?.()
                break

            case MessageType.ERROR:
                console.error('âŒ æœåŠ¡å™¨é”™è¯¯:', message.message)
                this.events.onError?.(message.message || 'æœªçŸ¥é”™è¯¯')
                break

            default:
                console.warn('æœªçŸ¥æ¶ˆæ¯ç±»å‹:', message.type)
        }
    }

    /**
     * æ’­æ”¾éŸ³é¢‘
     */
    private async playAudio(audioBlob: Blob): Promise<void> {
        try {
            // æ·»åŠ åˆ°æ’­æ”¾é˜Ÿåˆ—
            this.audioQueue.push(audioBlob)

            // å¦‚æœæ²¡æœ‰æ­£åœ¨æ’­æ”¾ï¼Œå¼€å§‹æ’­æ”¾
            if (!this.isPlaying) {
                await this.processAudioQueue()
            }
        } catch (error) {
            console.error('æ’­æ”¾éŸ³é¢‘å¤±è´¥:', error)
        }
    }

    /**
     * å¤„ç†éŸ³é¢‘æ’­æ”¾é˜Ÿåˆ—
     */
    private async processAudioQueue(): Promise<void> {
        if (this.audioQueue.length === 0 || !this.isSpeaking) {
            this.isPlaying = false
            return
        }

        this.isPlaying = true
        const audioBlob = this.audioQueue.shift()!

        try {
            const audioUrl = URL.createObjectURL(audioBlob)
            const audio = new Audio(audioUrl)

            await new Promise<void>((resolve, reject) => {
                audio.onended = () => {
                    URL.revokeObjectURL(audioUrl)
                    resolve()
                }

                audio.onerror = (error) => {
                    URL.revokeObjectURL(audioUrl)
                    reject(error)
                }

                audio.play().catch(reject)
            })

            // æ’­æ”¾ä¸‹ä¸€ä¸ª
            await this.processAudioQueue()
        } catch (error) {
            console.error('å¤„ç†éŸ³é¢‘é˜Ÿåˆ—å¤±è´¥:', error)
            this.isPlaying = false
        }
    }

    /**
     * åœæ­¢éŸ³é¢‘æ’­æ”¾
     */
    private stopAudioPlayback(): void {
        this.audioQueue = []
        this.isPlaying = false
    }

    /**
     * å‘é€æ¶ˆæ¯åˆ°æœåŠ¡å™¨
     */
    private send(message: Partial<any>): void {
        if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
            console.error('WebSocket æœªè¿æ¥')
            return
        }

        this.ws.send(JSON.stringify(message))
    }

    /**
     * æ–­å¼€è¿æ¥
     */
    async disconnect(): Promise<void> {
        // åœæ­¢å½•éŸ³
        if (this.isRecording) {
            await this.stopRecording().catch(console.error)
        }

        this.stopAudioPlayback()

        if (this.ws) {
            this.send({ type: MessageType.CLOSE })
            this.ws.close()
            this.ws = null
        }

        this.cleanup()
    }

    /**
     * æ¸…ç†èµ„æº
     */
    private cleanup(): void {
        if (this.recordingTimer) {
            clearInterval(this.recordingTimer)
            this.recordingTimer = null
        }

        this.stopAudioPlayback()
        this.isRecording = false
        this.isSpeaking = false
    }

    /**
     * Base64 è½¬ Blob
     */
    private base64ToBlob(base64: string, mimeType: string): Blob {
        const byteCharacters = atob(base64)
        const byteNumbers = new Array(byteCharacters.length)

        for (let i = 0; i < byteCharacters.length; i++) {
            byteNumbers[i] = byteCharacters.charCodeAt(i)
        }

        const byteArray = new Uint8Array(byteNumbers)
        return new Blob([byteArray], { type: mimeType })
    }

    /**
     * è·å–å½“å‰çŠ¶æ€
     */
    getState() {
        return {
            isConnected: this.ws?.readyState === WebSocket.OPEN,
            isRecording: this.isRecording,
            isSpeaking: this.isSpeaking,
            isPlaying: this.isPlaying,
            sessionId: this.sessionId,
        }
    }
}

export default VoiceChatNativeService
