/**
 * è¯­éŸ³è®¾ç½®ç»„ä»¶æµ‹è¯•
 * 
 * æµ‹è¯•ä¸»è¦åŠŸèƒ½ï¼š
 * - ğŸ¤ TTSï¼ˆæ–‡æœ¬è½¬è¯­éŸ³ï¼‰å¼•æ“é…ç½®
 * - ğŸ§ STTï¼ˆè¯­éŸ³è½¬æ–‡æœ¬ï¼‰å¼•æ“é…ç½®
 * - ğŸ”Š éŸ³é‡å’Œè¯­é€Ÿè°ƒæ•´
 * - ğŸµ è¯­éŸ³æ ·æœ¬æµ‹è¯•å’Œé¢„è§ˆ
 * - ğŸ”§ éŸ³é¢‘è®¾å¤‡ç®¡ç†
 * - ğŸŒ å¤šè¯­è¨€è¯­éŸ³æ”¯æŒ
 * - ğŸ›ï¸ é«˜çº§éŸ³é¢‘å‚æ•°è°ƒæ•´
 * - ğŸ“Š éŸ³é¢‘è´¨é‡ç›‘æ§
 * 
 * @module Tests/Components/Settings/VoiceSettings
 */

import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest'
import { render, screen, fireEvent, waitFor, within } from '@testing-library/react'
import userEvent from '@testing-library/user-event'
import { TestProvider } from '@/tests/utils/test-utils'
import { 
  createMockUseSettings, 
  createMockUseTauri,
  createMockVoiceSettings,
  mockToast 
} from '@/tests/mocks/settings-mocks'

// æ¨¡æ‹Ÿä¾èµ–
vi.mock('@/hooks/useSettings')
vi.mock('@/hooks/useTauri')
vi.mock('@/hooks/useVoice')
vi.mock('react-hot-toast', () => ({ default: mockToast }))
vi.mock('framer-motion', () => ({
  motion: {
    div: vi.fn(({ children, ...props }) => <div {...props}>{children}</div>),
    section: vi.fn(({ children, ...props }) => <section {...props}>{children}</section>)
  }
}))

// æ¨¡æ‹ŸéŸ³é¢‘API
Object.defineProperty(window, 'SpeechSynthesis', {
  writable: true,
  value: {
    getVoices: vi.fn(() => [
      { name: 'Microsoft Yaoyao', lang: 'zh-CN', default: true },
      { name: 'Microsoft Kangkang', lang: 'zh-CN', default: false },
      { name: 'Google US English', lang: 'en-US', default: false }
    ]),
    speak: vi.fn(),
    cancel: vi.fn(),
    pause: vi.fn(),
    resume: vi.fn()
  }
})

Object.defineProperty(window, 'SpeechRecognition', {
  writable: true,
  value: vi.fn().mockImplementation(() => ({
    start: vi.fn(),
    stop: vi.fn(),
    abort: vi.fn(),
    addEventListener: vi.fn(),
    removeEventListener: vi.fn()
  }))
})

// Mock useVoice Hook
const mockUseVoice = {
  ttsSettings: {
    engine: 'system',
    voice: 'Microsoft Yaoyao',
    speed: 1.0,
    volume: 0.8,
    enabled: true
  },
  sttSettings: {
    engine: 'browser',
    language: 'zh-CN',
    sensitivity: 0.5,
    enabled: true
  },
  availableVoices: [
    { id: 'yaoyao', name: 'Microsoft Yaoyao', language: 'zh-CN', gender: 'female' },
    { id: 'kangkang', name: 'Microsoft Kangkang', language: 'zh-CN', gender: 'male' }
  ],
  availableEngines: [
    { id: 'system', name: 'ç³»ç»Ÿè¯­éŸ³', type: 'tts' },
    { id: 'azure', name: 'Azure è®¤çŸ¥æœåŠ¡', type: 'tts' },
    { id: 'browser', name: 'æµè§ˆå™¨è¯†åˆ«', type: 'stt' },
    { id: 'whisper', name: 'OpenAI Whisper', type: 'stt' }
  ],
  audioDevices: {
    input: [
      { deviceId: 'default', label: 'é»˜è®¤éº¦å…‹é£' },
      { deviceId: 'mic1', label: 'å†…ç½®éº¦å…‹é£' }
    ],
    output: [
      { deviceId: 'default', label: 'é»˜è®¤æ‰¬å£°å™¨' },
      { deviceId: 'speaker1', label: 'å†…ç½®æ‰¬å£°å™¨' }
    ]
  },
  isRecording: false,
  isSpeaking: false,
  error: null,
  updateTTSSettings: vi.fn(),
  updateSTTSettings: vi.fn(),
  testTTS: vi.fn(),
  testSTT: vi.fn(),
  requestMicrophonePermission: vi.fn(),
  getAudioDevices: vi.fn(),
  setAudioDevice: vi.fn()
}

vi.mock('@/hooks/useVoice', () => ({
  useVoice: () => mockUseVoice
}))

// å¯¼å…¥è¦æµ‹è¯•çš„ç»„ä»¶
import { VoiceSettings } from '@/components/Settings/VoiceSettings'
import { useSettings } from '@/hooks/useSettings'
import { useTauri } from '@/hooks/useTauri'

describe('VoiceSettings - è¯­éŸ³è®¾ç½®ç»„ä»¶', () => {
  let mockUseSettings: ReturnType<typeof createMockUseSettings>
  let mockUseTauri: ReturnType<typeof createMockUseTauri>
  let user: ReturnType<typeof userEvent.setup>
  let mockVoiceSettings: ReturnType<typeof createMockVoiceSettings>
  let mockOnSettingsChange: ReturnType<typeof vi.fn>

  beforeEach(() => {
    mockUseSettings = createMockUseSettings()
    mockUseTauri = createMockUseTauri()
    mockVoiceSettings = createMockVoiceSettings()
    mockOnSettingsChange = vi.fn()
    user = userEvent.setup()

    vi.mocked(useSettings).mockReturnValue(mockUseSettings)
    vi.mocked(useTauri).mockReturnValue(mockUseTauri)
    
    vi.clearAllMocks()
  })

  afterEach(() => {
    vi.resetAllMocks()
  })

  const renderVoiceSettings = (overrideProps = {}) => {
    const defaultProps = {
      voiceSettings: mockVoiceSettings,
      onSettingsChange: mockOnSettingsChange,
      ...overrideProps
    }
    
    return render(
      <TestProvider>
        <VoiceSettings {...defaultProps} />
      </TestProvider>
    )
  }

  // ==================== æ¸²æŸ“æµ‹è¯• ====================

  describe('æ¸²æŸ“æµ‹è¯•', () => {
    it('åº”è¯¥æ­£ç¡®æ¸²æŸ“è¯­éŸ³è®¾ç½®ç»„ä»¶', () => {
      renderVoiceSettings()

      expect(screen.getByText('TTS è®¾ç½®')).toBeInTheDocument()
      expect(screen.getByText('STT è®¾ç½®')).toBeInTheDocument()
      expect(screen.getByText('éŸ³é¢‘è®¾å¤‡')).toBeInTheDocument()
      expect(screen.getByText('é«˜çº§è®¾ç½®')).toBeInTheDocument()
    })

    it('åº”è¯¥æ˜¾ç¤ºæ‰€æœ‰ä¸»è¦è®¾ç½®åˆ†ç»„', () => {
      renderVoiceSettings()

      const sections = [
        'TTS è®¾ç½®',
        'STT è®¾ç½®',
        'éŸ³é¢‘è®¾å¤‡',
        'æƒé™ç®¡ç†',
        'æµ‹è¯•å·¥å…·'
      ]

      sections.forEach(section => {
        expect(screen.getByText(section)).toBeInTheDocument()
      })
    })

    it('åº”è¯¥åº”ç”¨è‡ªå®šä¹‰æ ·å¼ç±»å', () => {
      const { container } = renderVoiceSettings({ className: 'custom-voice-settings' })
      
      expect(container.firstChild).toHaveClass('custom-voice-settings')
    })
  })

  // ==================== TTSè®¾ç½®æµ‹è¯• ====================

  describe('TTSè®¾ç½®æµ‹è¯•', () => {
    it('åº”è¯¥æ˜¾ç¤ºTTSå¼•æ“é€‰æ‹©å™¨', () => {
      renderVoiceSettings()

      expect(screen.getByLabelText('TTSå¼•æ“')).toBeInTheDocument()
    })

    it('åº”è¯¥æ˜¾ç¤ºå½“å‰é€‰ä¸­çš„TTSå¼•æ“', () => {
      renderVoiceSettings()

      const engineSelect = screen.getByLabelText('TTSå¼•æ“') as HTMLSelectElement
      expect(engineSelect.value).toBe(mockVoiceSettings.tts.engine)
    })

    it('åº”è¯¥åˆ‡æ¢TTSå¼•æ“', async () => {
      renderVoiceSettings()

      const engineSelect = screen.getByLabelText('TTSå¼•æ“')
      await user.selectOptions(engineSelect, 'azure')

      expect(mockUseVoice.updateTTSSettings).toHaveBeenCalledWith({
        engine: 'azure'
      })
    })

    it('åº”è¯¥æ˜¾ç¤ºè¯­éŸ³é€‰æ‹©å™¨', () => {
      renderVoiceSettings()

      expect(screen.getByLabelText('è¯­éŸ³')).toBeInTheDocument()
    })

    it('åº”è¯¥æ˜¾ç¤ºå¯ç”¨è¯­éŸ³åˆ—è¡¨', () => {
      renderVoiceSettings()

      const voiceSelect = screen.getByLabelText('è¯­éŸ³')
      fireEvent.click(voiceSelect)

      expect(screen.getByText('Microsoft Yaoyao')).toBeInTheDocument()
      expect(screen.getByText('Microsoft Kangkang')).toBeInTheDocument()
    })

    it('åº”è¯¥åˆ‡æ¢è¯­éŸ³', async () => {
      renderVoiceSettings()

      const voiceSelect = screen.getByLabelText('è¯­éŸ³')
      await user.selectOptions(voiceSelect, 'kangkang')

      expect(mockUseVoice.updateTTSSettings).toHaveBeenCalledWith({
        voice: 'kangkang'
      })
    })

    it('åº”è¯¥æ˜¾ç¤ºè¯­é€Ÿæ§åˆ¶å™¨', () => {
      renderVoiceSettings()

      expect(screen.getByLabelText('è¯­é€Ÿ')).toBeInTheDocument()
    })

    it('åº”è¯¥è°ƒæ•´è¯­é€Ÿ', async () => {
      renderVoiceSettings()

      const speedSlider = screen.getByLabelText('è¯­é€Ÿ')
      fireEvent.change(speedSlider, { target: { value: '1.5' } })

      expect(mockUseVoice.updateTTSSettings).toHaveBeenCalledWith({
        speed: 1.5
      })
    })

    it('åº”è¯¥æ˜¾ç¤ºéŸ³é‡æ§åˆ¶å™¨', () => {
      renderVoiceSettings()

      expect(screen.getByLabelText('éŸ³é‡')).toBeInTheDocument()
    })

    it('åº”è¯¥è°ƒæ•´éŸ³é‡', async () => {
      renderVoiceSettings()

      const volumeSlider = screen.getByLabelText('éŸ³é‡')
      fireEvent.change(volumeSlider, { target: { value: '0.6' } })

      expect(mockUseVoice.updateTTSSettings).toHaveBeenCalledWith({
        volume: 0.6
      })
    })

    it('åº”è¯¥åˆ‡æ¢TTSå¯ç”¨çŠ¶æ€', async () => {
      renderVoiceSettings()

      const enableSwitch = screen.getByLabelText('å¯ç”¨TTS')
      await user.click(enableSwitch)

      expect(mockUseVoice.updateTTSSettings).toHaveBeenCalledWith({
        enabled: !mockVoiceSettings.tts.enabled
      })
    })

    it('åº”è¯¥æµ‹è¯•TTSåŠŸèƒ½', async () => {
      renderVoiceSettings()

      const testButton = screen.getByText('æµ‹è¯•è¯­éŸ³')
      await user.click(testButton)

      expect(mockUseVoice.testTTS).toHaveBeenCalledWith('è¿™æ˜¯ä¸€æ®µæµ‹è¯•è¯­éŸ³ã€‚')
    })

    it('åº”è¯¥å…è®¸è‡ªå®šä¹‰æµ‹è¯•æ–‡æœ¬', async () => {
      renderVoiceSettings()

      const testInput = screen.getByLabelText('æµ‹è¯•æ–‡æœ¬')
      await user.clear(testInput)
      await user.type(testInput, 'è‡ªå®šä¹‰æµ‹è¯•æ–‡æœ¬')

      const testButton = screen.getByText('æµ‹è¯•è¯­éŸ³')
      await user.click(testButton)

      expect(mockUseVoice.testTTS).toHaveBeenCalledWith('è‡ªå®šä¹‰æµ‹è¯•æ–‡æœ¬')
    })

    it('åº”è¯¥æ˜¾ç¤ºTTSçŠ¶æ€æŒ‡ç¤ºå™¨', () => {
      mockUseVoice.isSpeaking = true
      
      renderVoiceSettings()

      expect(screen.getByText(/æ­£åœ¨æ’­æ”¾/i)).toBeInTheDocument()
    })

    it('åº”è¯¥åœæ­¢æ­£åœ¨æ’­æ”¾çš„TTS', async () => {
      mockUseVoice.isSpeaking = true
      
      renderVoiceSettings()

      const stopButton = screen.getByText('åœæ­¢')
      await user.click(stopButton)

      expect(window.speechSynthesis.cancel).toHaveBeenCalled()
    })
  })

  // ==================== STTè®¾ç½®æµ‹è¯• ====================

  describe('STTè®¾ç½®æµ‹è¯•', () => {
    it('åº”è¯¥æ˜¾ç¤ºSTTå¼•æ“é€‰æ‹©å™¨', () => {
      renderVoiceSettings()

      expect(screen.getByLabelText('STTå¼•æ“')).toBeInTheDocument()
    })

    it('åº”è¯¥æ˜¾ç¤ºå½“å‰é€‰ä¸­çš„STTå¼•æ“', () => {
      renderVoiceSettings()

      const engineSelect = screen.getByLabelText('STTå¼•æ“') as HTMLSelectElement
      expect(engineSelect.value).toBe(mockVoiceSettings.stt.engine)
    })

    it('åº”è¯¥åˆ‡æ¢STTå¼•æ“', async () => {
      renderVoiceSettings()

      const engineSelect = screen.getByLabelText('STTå¼•æ“')
      await user.selectOptions(engineSelect, 'whisper')

      expect(mockUseVoice.updateSTTSettings).toHaveBeenCalledWith({
        engine: 'whisper'
      })
    })

    it('åº”è¯¥æ˜¾ç¤ºè¯†åˆ«è¯­è¨€é€‰æ‹©å™¨', () => {
      renderVoiceSettings()

      expect(screen.getByLabelText('è¯†åˆ«è¯­è¨€')).toBeInTheDocument()
    })

    it('åº”è¯¥åˆ‡æ¢è¯†åˆ«è¯­è¨€', async () => {
      renderVoiceSettings()

      const languageSelect = screen.getByLabelText('è¯†åˆ«è¯­è¨€')
      await user.selectOptions(languageSelect, 'en-US')

      expect(mockUseVoice.updateSTTSettings).toHaveBeenCalledWith({
        language: 'en-US'
      })
    })

    it('åº”è¯¥æ˜¾ç¤ºçµæ•åº¦æ§åˆ¶å™¨', () => {
      renderVoiceSettings()

      expect(screen.getByLabelText('è¯†åˆ«çµæ•åº¦')).toBeInTheDocument()
    })

    it('åº”è¯¥è°ƒæ•´è¯†åˆ«çµæ•åº¦', async () => {
      renderVoiceSettings()

      const sensitivitySlider = screen.getByLabelText('è¯†åˆ«çµæ•åº¦')
      fireEvent.change(sensitivitySlider, { target: { value: '0.8' } })

      expect(mockUseVoice.updateSTTSettings).toHaveBeenCalledWith({
        sensitivity: 0.8
      })
    })

    it('åº”è¯¥åˆ‡æ¢STTå¯ç”¨çŠ¶æ€', async () => {
      renderVoiceSettings()

      const enableSwitch = screen.getByLabelText('å¯ç”¨STT')
      await user.click(enableSwitch)

      expect(mockUseVoice.updateSTTSettings).toHaveBeenCalledWith({
        enabled: !mockVoiceSettings.stt.enabled
      })
    })

    it('åº”è¯¥æµ‹è¯•STTåŠŸèƒ½', async () => {
      renderVoiceSettings()

      const testButton = screen.getByText('æµ‹è¯•è¯†åˆ«')
      await user.click(testButton)

      expect(mockUseVoice.testSTT).toHaveBeenCalled()
    })

    it('åº”è¯¥æ˜¾ç¤ºSTTçŠ¶æ€æŒ‡ç¤ºå™¨', () => {
      mockUseVoice.isRecording = true
      
      renderVoiceSettings()

      expect(screen.getByText(/æ­£åœ¨å½•éŸ³/i)).toBeInTheDocument()
    })

    it('åº”è¯¥åœæ­¢STTå½•éŸ³', async () => {
      mockUseVoice.isRecording = true
      
      renderVoiceSettings()

      const stopButton = screen.getByText('åœæ­¢å½•éŸ³')
      await user.click(stopButton)

      // STTåœæ­¢é€»è¾‘åœ¨ useVoice hook ä¸­å¤„ç†
      expect(mockUseVoice.testSTT).toHaveBeenCalled()
    })

    it('åº”è¯¥æ˜¾ç¤ºè¯†åˆ«ç»“æœ', () => {
      renderVoiceSettings()

      // æ¨¡æ‹Ÿè¯†åˆ«ç»“æœ
      const resultArea = screen.getByLabelText('è¯†åˆ«ç»“æœ')
      expect(resultArea).toBeInTheDocument()
    })

    it('åº”è¯¥æ¸…é™¤è¯†åˆ«ç»“æœ', async () => {
      renderVoiceSettings()

      const clearButton = screen.getByText('æ¸…é™¤ç»“æœ')
      await user.click(clearButton)

      const resultArea = screen.getByLabelText('è¯†åˆ«ç»“æœ') as HTMLTextAreaElement
      expect(resultArea.value).toBe('')
    })
  })

  // ==================== éŸ³é¢‘è®¾å¤‡æµ‹è¯• ====================

  describe('éŸ³é¢‘è®¾å¤‡æµ‹è¯•', () => {
    it('åº”è¯¥æ˜¾ç¤ºè¾“å…¥è®¾å¤‡é€‰æ‹©å™¨', () => {
      renderVoiceSettings()

      expect(screen.getByLabelText('éº¦å…‹é£')).toBeInTheDocument()
    })

    it('åº”è¯¥æ˜¾ç¤ºè¾“å‡ºè®¾å¤‡é€‰æ‹©å™¨', () => {
      renderVoiceSettings()

      expect(screen.getByLabelText('æ‰¬å£°å™¨')).toBeInTheDocument()
    })

    it('åº”è¯¥æ˜¾ç¤ºå¯ç”¨éŸ³é¢‘è®¾å¤‡', () => {
      renderVoiceSettings()

      const micSelect = screen.getByLabelText('éº¦å…‹é£')
      fireEvent.click(micSelect)

      expect(screen.getByText('é»˜è®¤éº¦å…‹é£')).toBeInTheDocument()
      expect(screen.getByText('å†…ç½®éº¦å…‹é£')).toBeInTheDocument()
    })

    it('åº”è¯¥åˆ‡æ¢éŸ³é¢‘è®¾å¤‡', async () => {
      renderVoiceSettings()

      const micSelect = screen.getByLabelText('éº¦å…‹é£')
      await user.selectOptions(micSelect, 'mic1')

      expect(mockUseVoice.setAudioDevice).toHaveBeenCalledWith('input', 'mic1')
    })

    it('åº”è¯¥åˆ·æ–°éŸ³é¢‘è®¾å¤‡åˆ—è¡¨', async () => {
      renderVoiceSettings()

      const refreshButton = screen.getByText('åˆ·æ–°è®¾å¤‡')
      await user.click(refreshButton)

      expect(mockUseVoice.getAudioDevices).toHaveBeenCalled()
    })

    it('åº”è¯¥æµ‹è¯•éŸ³é¢‘è®¾å¤‡', async () => {
      renderVoiceSettings()

      const testMicButton = screen.getByText('æµ‹è¯•éº¦å…‹é£')
      await user.click(testMicButton)

      expect(mockUseTauri.commands.test_audio_device).toHaveBeenCalledWith('input')
    })

    it('åº”è¯¥æ˜¾ç¤ºéŸ³é¢‘è®¾å¤‡çŠ¶æ€', () => {
      renderVoiceSettings()

      expect(screen.getByText('è®¾å¤‡çŠ¶æ€')).toBeInTheDocument()
      expect(screen.getByText(/æ­£å¸¸/i)).toBeInTheDocument()
    })

    it('åº”è¯¥æ˜¾ç¤ºéŸ³é¢‘ç”µå¹³æŒ‡ç¤ºå™¨', () => {
      renderVoiceSettings()

      expect(screen.getByTestId('audio-level-meter')).toBeInTheDocument()
    })
  })

  // ==================== æƒé™ç®¡ç†æµ‹è¯• ====================

  describe('æƒé™ç®¡ç†æµ‹è¯•', () => {
    it('åº”è¯¥æ˜¾ç¤ºéº¦å…‹é£æƒé™çŠ¶æ€', () => {
      renderVoiceSettings()

      expect(screen.getByText('éº¦å…‹é£æƒé™')).toBeInTheDocument()
    })

    it('åº”è¯¥è¯·æ±‚éº¦å…‹é£æƒé™', async () => {
      renderVoiceSettings()

      const requestButton = screen.getByText('è¯·æ±‚æƒé™')
      await user.click(requestButton)

      expect(mockUseVoice.requestMicrophonePermission).toHaveBeenCalled()
    })

    it('åº”è¯¥æ˜¾ç¤ºæƒé™è¢«æ‹’ç»æç¤º', () => {
      mockUseVoice.error = new Error('Permission denied')
      
      renderVoiceSettings()

      expect(screen.getByText(/æƒé™è¢«æ‹’ç»/i)).toBeInTheDocument()
    })

    it('åº”è¯¥æä¾›æƒé™è®¾ç½®æŒ‡å¼•', () => {
      renderVoiceSettings()

      const helpButton = screen.getByText('æƒé™å¸®åŠ©')
      fireEvent.click(helpButton)

      expect(screen.getByText(/å¦‚ä½•å¼€å¯æƒé™/i)).toBeInTheDocument()
    })

    it('åº”è¯¥æ˜¾ç¤ºæµè§ˆå™¨å…¼å®¹æ€§ä¿¡æ¯', () => {
      renderVoiceSettings()

      expect(screen.getByText('æµè§ˆå™¨æ”¯æŒ')).toBeInTheDocument()
    })
  })

  // ==================== é«˜çº§è®¾ç½®æµ‹è¯• ====================

  describe('é«˜çº§è®¾ç½®æµ‹è¯•', () => {
    it('åº”è¯¥æ˜¾ç¤ºé«˜çº§è®¾ç½®æŠ˜å é¢æ¿', () => {
      renderVoiceSettings()

      expect(screen.getByText('é«˜çº§è®¾ç½®')).toBeInTheDocument()
    })

    it('åº”è¯¥å±•å¼€é«˜çº§è®¾ç½®', async () => {
      renderVoiceSettings()

      const advancedToggle = screen.getByText('é«˜çº§è®¾ç½®')
      await user.click(advancedToggle)

      expect(screen.getByText('éŸ³é¢‘å‚æ•°')).toBeInTheDocument()
    })

    it('åº”è¯¥é…ç½®éŸ³é¢‘é‡‡æ ·ç‡', async () => {
      renderVoiceSettings()

      await user.click(screen.getByText('é«˜çº§è®¾ç½®'))

      const sampleRateSelect = screen.getByLabelText('é‡‡æ ·ç‡')
      await user.selectOptions(sampleRateSelect, '48000')

      expect(mockOnSettingsChange).toHaveBeenCalledWith({
        ...mockVoiceSettings,
        advanced: {
          ...mockVoiceSettings.advanced,
          sampleRate: 48000
        }
      })
    })

    it('åº”è¯¥é…ç½®éŸ³é¢‘ç¼“å†²åŒºå¤§å°', async () => {
      renderVoiceSettings()

      await user.click(screen.getByText('é«˜çº§è®¾ç½®'))

      const bufferSizeSelect = screen.getByLabelText('ç¼“å†²åŒºå¤§å°')
      await user.selectOptions(bufferSizeSelect, '1024')

      expect(mockOnSettingsChange).toHaveBeenCalledWith({
        ...mockVoiceSettings,
        advanced: {
          ...mockVoiceSettings.advanced,
          bufferSize: 1024
        }
      })
    })

    it('åº”è¯¥å¯ç”¨å™ªéŸ³æŠ‘åˆ¶', async () => {
      renderVoiceSettings()

      await user.click(screen.getByText('é«˜çº§è®¾ç½®'))

      const noiseSuppressionSwitch = screen.getByLabelText('å™ªéŸ³æŠ‘åˆ¶')
      await user.click(noiseSuppressionSwitch)

      expect(mockOnSettingsChange).toHaveBeenCalledWith({
        ...mockVoiceSettings,
        advanced: {
          ...mockVoiceSettings.advanced,
          noiseSuppression: true
        }
      })
    })

    it('åº”è¯¥å¯ç”¨å›å£°æ¶ˆé™¤', async () => {
      renderVoiceSettings()

      await user.click(screen.getByText('é«˜çº§è®¾ç½®'))

      const echoCancellationSwitch = screen.getByLabelText('å›å£°æ¶ˆé™¤')
      await user.click(echoCancellationSwitch)

      expect(mockOnSettingsChange).toHaveBeenCalledWith({
        ...mockVoiceSettings,
        advanced: {
          ...mockVoiceSettings.advanced,
          echoCancellation: true
        }
      })
    })

    it('åº”è¯¥å¯ç”¨è‡ªåŠ¨å¢ç›Šæ§åˆ¶', async () => {
      renderVoiceSettings()

      await user.click(screen.getByText('é«˜çº§è®¾ç½®'))

      const agcSwitch = screen.getByLabelText('è‡ªåŠ¨å¢ç›Šæ§åˆ¶')
      await user.click(agcSwitch)

      expect(mockOnSettingsChange).toHaveBeenCalledWith({
        ...mockVoiceSettings,
        advanced: {
          ...mockVoiceSettings.advanced,
          autoGainControl: true
        }
      })
    })

    it('åº”è¯¥é‡ç½®é«˜çº§è®¾ç½®', async () => {
      const confirmSpy = vi.spyOn(window, 'confirm').mockReturnValue(true)

      renderVoiceSettings()

      await user.click(screen.getByText('é«˜çº§è®¾ç½®'))

      const resetButton = screen.getByText('é‡ç½®é«˜çº§è®¾ç½®')
      await user.click(resetButton)

      expect(confirmSpy).toHaveBeenCalledWith('ç¡®å®šè¦é‡ç½®æ‰€æœ‰é«˜çº§è®¾ç½®å—ï¼Ÿ')

      confirmSpy.mockRestore()
    })
  })

  // ==================== é”™è¯¯å¤„ç†æµ‹è¯• ====================

  describe('é”™è¯¯å¤„ç†æµ‹è¯•', () => {
    it('åº”è¯¥æ˜¾ç¤ºTTSé”™è¯¯ä¿¡æ¯', () => {
      mockUseVoice.error = new Error('TTSå¼•æ“åˆå§‹åŒ–å¤±è´¥')
      
      renderVoiceSettings()

      expect(screen.getByText('TTSå¼•æ“åˆå§‹åŒ–å¤±è´¥')).toBeInTheDocument()
    })

    it('åº”è¯¥æ˜¾ç¤ºSTTé”™è¯¯ä¿¡æ¯', () => {
      mockUseVoice.error = new Error('è¯­éŸ³è¯†åˆ«ä¸å¯ç”¨')
      
      renderVoiceSettings()

      expect(screen.getByText('è¯­éŸ³è¯†åˆ«ä¸å¯ç”¨')).toBeInTheDocument()
    })

    it('åº”è¯¥å¤„ç†æƒé™é”™è¯¯', () => {
      mockUseVoice.error = new Error('Permission denied')
      
      renderVoiceSettings()

      expect(screen.getByText(/è¯·å…è®¸éº¦å…‹é£æƒé™/i)).toBeInTheDocument()
    })

    it('åº”è¯¥å¤„ç†è®¾å¤‡ä¸å¯ç”¨é”™è¯¯', () => {
      mockUseVoice.error = new Error('No audio devices found')
      
      renderVoiceSettings()

      expect(screen.getByText(/æœªæ‰¾åˆ°éŸ³é¢‘è®¾å¤‡/i)).toBeInTheDocument()
    })

    it('åº”è¯¥æä¾›é”™è¯¯é‡è¯•é€‰é¡¹', () => {
      mockUseVoice.error = new Error('ç½‘ç»œè¿æ¥å¤±è´¥')
      
      renderVoiceSettings()

      expect(screen.getByText('é‡è¯•')).toBeInTheDocument()
    })

    it('åº”è¯¥é‡è¯•å¤±è´¥çš„æ“ä½œ', async () => {
      mockUseVoice.error = new Error('ç½‘ç»œè¿æ¥å¤±è´¥')
      
      renderVoiceSettings()

      const retryButton = screen.getByText('é‡è¯•')
      await user.click(retryButton)

      // éªŒè¯é‡è¯•é€»è¾‘è¢«è§¦å‘
      expect(mockUseVoice.getAudioDevices).toHaveBeenCalled()
    })
  })

  // ==================== å®æ—¶ç›‘æ§æµ‹è¯• ====================

  describe('å®æ—¶ç›‘æ§æµ‹è¯•', () => {
    it('åº”è¯¥æ˜¾ç¤ºéŸ³é¢‘è´¨é‡ç›‘æ§', () => {
      renderVoiceSettings()

      expect(screen.getByText('éŸ³é¢‘è´¨é‡')).toBeInTheDocument()
    })

    it('åº”è¯¥æ˜¾ç¤ºå®æ—¶éŸ³é¢‘ç”µå¹³', () => {
      renderVoiceSettings()

      expect(screen.getByTestId('audio-level-meter')).toBeInTheDocument()
    })

    it('åº”è¯¥æ˜¾ç¤ºå»¶è¿Ÿç›‘æ§', () => {
      renderVoiceSettings()

      expect(screen.getByText('éŸ³é¢‘å»¶è¿Ÿ')).toBeInTheDocument()
      expect(screen.getByText(/ms/i)).toBeInTheDocument()
    })

    it('åº”è¯¥æ˜¾ç¤ºè¯†åˆ«å‡†ç¡®åº¦', () => {
      renderVoiceSettings()

      expect(screen.getByText('è¯†åˆ«å‡†ç¡®åº¦')).toBeInTheDocument()
    })

    it('åº”è¯¥æ˜¾ç¤ºä½¿ç”¨ç»Ÿè®¡', () => {
      renderVoiceSettings()

      expect(screen.getByText('ä½¿ç”¨ç»Ÿè®¡')).toBeInTheDocument()
      expect(screen.getByText('ä»Šæ—¥ä½¿ç”¨æ—¶é•¿')).toBeInTheDocument()
      expect(screen.getByText('è¯†åˆ«æ¬¡æ•°')).toBeInTheDocument()
    })
  })

  // ==================== å¯¼å…¥å¯¼å‡ºæµ‹è¯• ====================

  describe('å¯¼å…¥å¯¼å‡ºæµ‹è¯•', () => {
    it('åº”è¯¥å¯¼å‡ºè¯­éŸ³è®¾ç½®', async () => {
      renderVoiceSettings()

      const exportButton = screen.getByText('å¯¼å‡ºè®¾ç½®')
      await user.click(exportButton)

      expect(mockUseTauri.commands.export_voice_settings).toHaveBeenCalled()
    })

    it('åº”è¯¥å¯¼å…¥è¯­éŸ³è®¾ç½®', async () => {
      renderVoiceSettings()

      const importButton = screen.getByText('å¯¼å…¥è®¾ç½®')
      await user.click(importButton)

      expect(mockUseTauri.commands.import_voice_settings).toHaveBeenCalled()
    })

    it('åº”è¯¥éªŒè¯å¯¼å…¥çš„è®¾ç½®', async () => {
      renderVoiceSettings()

      const importButton = screen.getByText('å¯¼å…¥è®¾ç½®')
      await user.click(importButton)

      await waitFor(() => {
        expect(mockUseTauri.commands.validate_voice_settings).toHaveBeenCalled()
      })
    })

    it('åº”è¯¥å¤„ç†å¯¼å…¥é”™è¯¯', async () => {
      mockUseTauri.commands.import_voice_settings.mockRejectedValue(new Error('æ ¼å¼é”™è¯¯'))

      renderVoiceSettings()

      const importButton = screen.getByText('å¯¼å…¥è®¾ç½®')
      await user.click(importButton)

      await waitFor(() => {
        expect(mockToast.error).toHaveBeenCalledWith('è®¾ç½®å¯¼å…¥å¤±è´¥: æ ¼å¼é”™è¯¯')
      })
    })
  })
})
