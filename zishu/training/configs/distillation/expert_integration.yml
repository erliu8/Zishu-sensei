name: 专业能力蒸馏
description: 将专业能力教师模型的知识蒸馏到增强学生模型
teachers:
- rwkv
- baichuan2
base_student: zishu_base
target_student: zishu_enhanced
training:
  batch_size: 8
  gradient_accumulation_steps: 8
  epochs: 2
  learning_rate: 0.0001
  warmup_ratio: 0.05
  weight_decay: 0.01
  lr_scheduler: cosine
  save_steps: 500
  eval_steps: 250
  logging_steps: 50
  max_grad_norm: 1.0
data:
  train_path: ./data/distillation/special/train.json
  eval_path: ./data/distillation/special/eval.json
  max_seq_length: 1024
  preprocessing:
    text_cleaning: true
    deduplication: true
    shuffle: true
  task_specific_data:
    latency_sensitive: ./data/distillation/special/latency_data.json
    cultural_knowledge: ./data/distillation/special/cultural_data.json
distillation:
  temperature: 1.5
  methods:
    selective_distillation:
      enable: true
      weight: 0.6
      select_top_k: 3
    adapters_distillation:
      enable: true
      weight: 0.4
      adapters:
        low_latency_adapter:
          teacher: rwkv
          weight: 0.7
        cultural_knowledge_layer:
          teacher: baichuan2
          weight: 0.8
  preserve_base_knowledge:
    enable: true
    weight: 0.3
    regularization: elastic
  teacher_weights:
    rwkv: 0.6
    baichuan2: 0.7
evaluation:
  metrics:
  - latency
  - accuracy
  - cultural_knowledge_score
  generate_samples: true
  num_samples: 30
  save_predictions: true
