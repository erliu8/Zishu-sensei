#!/usr/bin/env python3
"""
AIè‡ªåŠ¨ç”ŸæˆäºŒæ¬¡å…ƒå¯¹è¯æ•°æ®è„šæœ¬
æ”¯æŒå¤šç§å¤§æ¨¡å‹APIï¼Œç”Ÿæˆé«˜è´¨é‡çš„è§’è‰²å¯¹è¯è®­ç»ƒæ•°æ®
"""

import os
import json
import time
import random
import asyncio
import aiohttp
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Optional
import logging
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor
import re

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("dialogue_generation.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class DialogueConfig:
    """å¯¹è¯ç”Ÿæˆé…ç½®"""
    character_type: str
    scenario: str
    num_turns: int
    temperature: float = 0.8
    max_tokens: int = 150

class DialogueGenerator:
    """AIå¯¹è¯ç”Ÿæˆå™¨"""
    
    def __init__(self, api_config_path: str = "config/api_config.json"):
        self.api_config = self._load_api_config(api_config_path)
        self.output_dir = Path("data/generated_dialogues")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è§’è‰²ç±»å‹å’Œç‰¹å¾
        self.character_types = {
            "å‚²å¨‡": {
                "personality": "è¡¨é¢é«˜å‚²ä½†å†…å¿ƒæ¸©æŸ”ï¼Œç»å¸¸è¯´åè¯ï¼Œå®¹æ˜“å®³ç¾",
                "speech_patterns": ["å“¼", "æ‰ä¸æ˜¯", "ç¬¨è›‹", "åˆ«è¯¯ä¼š", "ä¸è¿‡"],
                "topics": ["å­¦ä¹ ", "å…´è¶£çˆ±å¥½", "æ—¥å¸¸ç”Ÿæ´»", "æƒ…æ„Ÿè¡¨è¾¾"]
            },
            "å…ƒæ°”å°‘å¥³": {
                "personality": "æ´»æ³¼å¼€æœ—ï¼Œå……æ»¡æ´»åŠ›ï¼Œè¯­æ°”å¯çˆ±",
                "speech_patterns": ["å‘€", "å‘¢", "å–µ", "å“‡", "å˜¿å˜¿"],
                "topics": ["è¿åŠ¨", "ç¾é£Ÿ", "æœ‹å‹", "å­¦æ ¡æ´»åŠ¨"]
            },
            "ä¸­äºŒç—…": {
                "personality": "è‡ªè®¤ä¸ºæœ‰ç‰¹æ®Šèƒ½åŠ›ï¼Œç”¨è¯å¤¸å¼ ï¼Œå¯Œæœ‰æƒ³è±¡åŠ›",
                "speech_patterns": ["å¾", "æ±", "é»‘æš—", "åŠ›é‡", "å¥‘çº¦"],
                "topics": ["è¶…èƒ½åŠ›", "å¼‚ä¸–ç•Œ", "å‘½è¿", "ç§˜å¯†ç»„ç»‡"]
            },
            "å¤§å°å§": {
                "personality": "å‡ºèº«åé—¨ï¼Œä¼˜é›…ä½†å¶å°”å¤©ç„¶ï¼Œæœ‰è´µæ—æ°”è´¨",
                "speech_patterns": ["æœ¬å°å§", "å“¼", "å¹³æ°‘", "å½“ç„¶", "ä¼˜é›…"],
                "topics": ["è´µæ—ç”Ÿæ´»", "ç¤¼ä»ª", "è‰ºæœ¯", "ç¤¾äº¤"]
            },
            "å†·é…·": {
                "personality": "æ€§æ ¼å†·æ·¡ï¼Œä¸å–„è¡¨è¾¾ï¼Œä½†å†…å¿ƒå–„è‰¯",
                "speech_patterns": ["æ— èŠ", "éšä¾¿", "ä¸éœ€è¦", "...", "æ„šè ¢"],
                "topics": ["å­¤ç‹¬", "ç†è§£", "ä¿¡ä»»", "è¿‡å»"]
            },
            "å­¦éœ¸": {
                "personality": "èªæ˜å¥½å­¦ï¼Œè®¤çœŸè´Ÿè´£ï¼Œå¶å°”å‘†èŒ",
                "speech_patterns": ["æ ¹æ®èµ„æ–™", "å­¦ä¹ ", "æ•ˆç‡", "è®¡åˆ’"],
                "topics": ["å­¦æœ¯", "ç ”ç©¶", "å›¾ä¹¦é¦†", "è€ƒè¯•"]
            }
        }
        
        # å¯¹è¯åœºæ™¯
        self.scenarios = {
            "æ ¡å›­æ—¥å¸¸": [
                "åœ¨æ•™å®¤è®¨è®ºä½œä¸š", "åœ¨å›¾ä¹¦é¦†å­¦ä¹ ", "åœ¨é£Ÿå ‚åƒé¥­", 
                "å‚åŠ ç¤¾å›¢æ´»åŠ¨", "ä½“è‚²è¯¾å", "è€ƒè¯•å‰å‡†å¤‡"
            ],
            "æ—¥å¸¸ç”Ÿæ´»": [
                "é€›è¡—è´­ç‰©", "åœ¨å’–å•¡å…èŠå¤©", "çœ‹ç”µå½±åè®¨è®º",
                "åœ¨å…¬å›­æ•£æ­¥", "åšå®¶åŠ¡", "å‡†å¤‡æ–™ç†"
            ],
            "å…´è¶£çˆ±å¥½": [
                "è®¨è®ºåŠ¨æ¼«", "ç©æ¸¸æˆ", "é˜…è¯»è½»å°è¯´",
                "ç”»ç”»åˆ›ä½œ", "å¬éŸ³ä¹", "å­¦ä¹ æ–°æŠ€èƒ½"
            ],
            "æƒ…æ„Ÿäº’åŠ¨": [
                "å®‰æ…°æœ‹å‹", "è¡¨è¾¾æ„Ÿè°¢", "é“æ­‰å’Œè§£",
                "åº†ç¥ç”Ÿæ—¥", "åˆ†äº«ç§˜å¯†", "äº’ç›¸é¼“åŠ±"
            ],
            "ç‰¹æ®Šåœºæ™¯": [
                "æ–‡åŒ–ç¥­å‡†å¤‡", "æš‘å‡è®¡åˆ’", "é›¨å¤©é¿é›¨",
                "æ„å¤–ç›¸é‡", "è¿·è·¯æ±‚åŠ©", "ç”Ÿç—…ç…§é¡¾"
            ]
        }
        
        # ç”Ÿæˆç»Ÿè®¡
        self.generation_stats = {
            "total_generated": 0,
            "successful": 0,
            "failed": 0,
            "filtered_out": 0,
            "start_time": datetime.now()
        }
    
    def _load_api_config(self, config_path: str) -> Dict:
        """åŠ è½½APIé…ç½®"""
        default_config = {
            "providers": {
                "openai": {
                    "api_key": "your-openai-api-key",
                    "base_url": "https://api.openai.com/v1",
                    "model": "gpt-3.5-turbo",
                    "enabled": False
                },
                "deepseek": {
                    "api_key": "your-deepseek-api-key", 
                    "base_url": "https://api.deepseek.com/v1",
                    "model": "deepseek-chat",
                    "enabled": False
                },
                "qwen": {
                    "api_key": "your-qwen-api-key",
                    "base_url": "https://dashscope.aliyuncs.com/api/v1",
                    "model": "qwen-turbo",
                    "enabled": False
                },
                "local": {
                    "base_url": "http://localhost:8000/v1",
                    "model": "local-model",
                    "enabled": True,
                    "api_key": "not-required"
                }
            },
            "generation": {
                "concurrent_requests": 3,
                "retry_attempts": 3,
                "timeout": 30,
                "rate_limit_delay": 1
            }
        }
        
        config_file = Path(config_path)
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                logger.info(f"å·²åŠ è½½APIé…ç½®: {config_path}")
                return {**default_config, **config}
            except Exception as e:
                logger.warning(f"APIé…ç½®åŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        else:
            # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
            config_file.parent.mkdir(parents=True, exist_ok=True)
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(default_config, f, ensure_ascii=False, indent=2)
            logger.info(f"å·²åˆ›å»ºé»˜è®¤APIé…ç½®: {config_path}")
        
        return default_config
    
    def _get_available_provider(self) -> Optional[Dict]:
        """è·å–å¯ç”¨çš„APIæä¾›å•†"""
        for name, config in self.api_config["providers"].items():
            if config.get("enabled", False):
                return {"name": name, **config}
        return None
    
    def _create_dialogue_prompt(self, config: DialogueConfig) -> str:
        """åˆ›å»ºå¯¹è¯ç”Ÿæˆæç¤ºè¯"""
        char_info = self.character_types[config.character_type]
        scenario_list = self.scenarios[config.scenario.split("-")[0]]
        specific_scenario = random.choice(scenario_list)
        
        prompt = f"""è¯·ç”Ÿæˆä¸€æ®µäºŒæ¬¡å…ƒé£æ ¼çš„å¯¹è¯ï¼Œè¦æ±‚å¦‚ä¸‹ï¼š

è§’è‰²è®¾å®šï¼š
- è§’è‰²ç±»å‹ï¼š{config.character_type}
- æ€§æ ¼ç‰¹å¾ï¼š{char_info['personality']}
- è¯­è¨€ç‰¹è‰²ï¼šç»å¸¸ä½¿ç”¨ {', '.join(char_info['speech_patterns'])} ç­‰è¯æ±‡
- å¯¹è¯åœºæ™¯ï¼š{specific_scenario}

å¯¹è¯è¦æ±‚ï¼š
1. ç”Ÿæˆ {config.num_turns} è½®å¯¹è¯ (æ¯è½®åŒ…å«ç”¨æˆ·å’Œè§’è‰²çš„ä¸€æ¬¡äº¤äº’)
2. è§’è‰²è¯­æ°”è¦ç¬¦åˆ {config.character_type} çš„ç‰¹ç‚¹
3. å¯¹è¯è¦è‡ªç„¶æµç•…ï¼Œæœ‰è¿è´¯æ€§
4. ä½“ç°äºŒæ¬¡å…ƒæ–‡åŒ–ç‰¹è‰²
5. é¿å…è¿‡äºé‡å¤çš„è¡¨è¾¾

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š
{{
    "character_type": "{config.character_type}",
    "scenario": "{specific_scenario}",
    "turns": [
        {{
            "turn": 1,
            "user": "ç”¨æˆ·è¯´çš„è¯",
            "character": "è§’è‰²å›åº”"
        }},
        {{
            "turn": 2,
            "user": "ç”¨æˆ·è¯´çš„è¯", 
            "character": "è§’è‰²å›åº”"
        }}
        // ... æ›´å¤šè½®æ¬¡
    ]
}}

ç°åœ¨å¼€å§‹ç”Ÿæˆå¯¹è¯ï¼š"""
        
        return prompt
    
    async def _call_api(self, provider: Dict, prompt: str, config: DialogueConfig) -> Optional[str]:
        """è°ƒç”¨APIç”Ÿæˆå¯¹è¯"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {provider['api_key']}"
        }
        
        payload = {
            "model": provider["model"],
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": config.temperature,
            "max_tokens": config.max_tokens * config.num_turns  # æ ¹æ®è½®æ•°è°ƒæ•´
        }
        
        timeout = aiohttp.ClientTimeout(total=self.api_config["generation"]["timeout"])
        
        async with aiohttp.ClientSession(timeout=timeout) as session:
            try:
                async with session.post(
                    f"{provider['base_url']}/chat/completions",
                    headers=headers,
                    json=payload
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        return result["choices"][0]["message"]["content"]
                    else:
                        logger.error(f"APIè°ƒç”¨å¤±è´¥: {response.status} - {await response.text()}")
                        return None
            except Exception as e:
                logger.error(f"APIè°ƒç”¨å¼‚å¸¸: {e}")
                return None
    
    def _extract_dialogue_json(self, response: str) -> Optional[Dict]:
        """ä»APIå“åº”ä¸­æå–å¯¹è¯JSON"""
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            if response.strip().startswith('{'):
                return json.loads(response.strip())
            
            # æŸ¥æ‰¾JSONä»£ç å—
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(1))
            
            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(0))
                
            logger.warning(f"æ— æ³•ä»å“åº”ä¸­æå–JSON: {response[:200]}...")
            return None
            
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {e}")
            return None
    
    def _validate_dialogue(self, dialogue: Dict, config: DialogueConfig) -> bool:
        """éªŒè¯ç”Ÿæˆçš„å¯¹è¯è´¨é‡"""
        try:
            # æ£€æŸ¥åŸºæœ¬ç»“æ„
            if not all(key in dialogue for key in ["character_type", "scenario", "turns"]):
                return False
            
            # æ£€æŸ¥è½®æ•°
            if len(dialogue["turns"]) < config.num_turns // 2:  # å…è®¸ä¸€å®šåå·®
                return False
            
            # æ£€æŸ¥æ¯è½®å¯¹è¯
            for turn in dialogue["turns"]:
                if not all(key in turn for key in ["user", "character"]):
                    return False
                
                # æ£€æŸ¥å†…å®¹é•¿åº¦
                if len(turn["user"]) < 5 or len(turn["character"]) < 10:
                    return False
                
                # æ£€æŸ¥è§’è‰²ç‰¹å¾è¯ï¼ˆç®€å•æ£€æŸ¥ï¼‰
                char_info = self.character_types[config.character_type]
                character_text = turn["character"]
                
                # è‡³å°‘è¦æœ‰ä¸€äº›è§’è‰²ç‰¹å¾
                has_character_feature = any(
                    pattern in character_text 
                    for pattern in char_info["speech_patterns"]
                )
                
                if not has_character_feature and random.random() < 0.3:  # 30%çš„æ¦‚ç‡è¦æ±‚æœ‰ç‰¹å¾è¯
                    continue  # ç»™ä¸€äº›å®¹é”™ç©ºé—´
            
            return True
            
        except Exception as e:
            logger.error(f"å¯¹è¯éªŒè¯å¤±è´¥: {e}")
            return False
    
    async def generate_single_dialogue(self, config: DialogueConfig) -> Optional[Dict]:
        """ç”Ÿæˆå•ä¸ªå¯¹è¯"""
        provider = self._get_available_provider()
        if not provider:
            logger.error("æ²¡æœ‰å¯ç”¨çš„APIæä¾›å•†")
            return None
        
        prompt = self._create_dialogue_prompt(config)
        
        # é‡è¯•æœºåˆ¶
        for attempt in range(self.api_config["generation"]["retry_attempts"]):
            try:
                response = await self._call_api(provider, prompt, config)
                if not response:
                    continue
                
                dialogue = self._extract_dialogue_json(response)
                if not dialogue:
                    continue
                
                if self._validate_dialogue(dialogue, config):
                    # æ·»åŠ å…ƒæ•°æ®
                    dialogue["metadata"] = {
                        "generated_at": datetime.now().isoformat(),
                        "provider": provider["name"],
                        "model": provider["model"],
                        "config": config.__dict__,
                        "attempt": attempt + 1
                    }
                    
                    self.generation_stats["successful"] += 1
                    return dialogue
                else:
                    self.generation_stats["filtered_out"] += 1
                    logger.debug(f"å¯¹è¯è´¨é‡ä¸ç¬¦åˆè¦æ±‚ï¼Œé‡è¯•ç¬¬ {attempt + 1} æ¬¡")
                
            except Exception as e:
                logger.error(f"ç”Ÿæˆå¯¹è¯å¤±è´¥ (å°è¯• {attempt + 1}): {e}")
                continue
            
            # æ·»åŠ å»¶è¿Ÿé¿å…é¢‘ç‡é™åˆ¶
            await asyncio.sleep(self.api_config["generation"]["rate_limit_delay"])
        
        self.generation_stats["failed"] += 1
        return None
    
    async def generate_batch_dialogues(self, configs: List[DialogueConfig], batch_name: str = None) -> List[Dict]:
        """æ‰¹é‡ç”Ÿæˆå¯¹è¯"""
        if not batch_name:
            batch_name = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        logger.info(f"å¼€å§‹ç”Ÿæˆ {len(configs)} ä¸ªå¯¹è¯ï¼Œæ‰¹æ¬¡: {batch_name}")
        
        # æ§åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(self.api_config["generation"]["concurrent_requests"])
        
        async def generate_with_semaphore(config):
            async with semaphore:
                return await self.generate_single_dialogue(config)
        
        # æ‰§è¡Œå¹¶å‘ç”Ÿæˆ
        tasks = [generate_with_semaphore(config) for config in configs]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # è¿‡æ»¤æœ‰æ•ˆç»“æœ
        valid_dialogues = []
        for result in results:
            if isinstance(result, dict) and result is not None:
                valid_dialogues.append(result)
            elif isinstance(result, Exception):
                logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {result}")
        
        # ä¿å­˜æ‰¹æ¬¡ç»“æœ
        if valid_dialogues:
            batch_file = self.output_dir / f"{batch_name}.json"
            with open(batch_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "batch_info": {
                        "name": batch_name,
                        "generated_at": datetime.now().isoformat(),
                        "total_requested": len(configs),
                        "total_generated": len(valid_dialogues),
                        "success_rate": len(valid_dialogues) / len(configs)
                    },
                    "dialogues": valid_dialogues
                }, f, ensure_ascii=False, indent=2)
            
            logger.info(f"æ‰¹æ¬¡ {batch_name} å®Œæˆ: {len(valid_dialogues)}/{len(configs)} æˆåŠŸç”Ÿæˆ")
        
        self.generation_stats["total_generated"] += len(valid_dialogues)
        return valid_dialogues
    
    def create_training_dataset(self, output_file: str = None) -> str:
        """å°†ç”Ÿæˆçš„å¯¹è¯è½¬æ¢ä¸ºè®­ç»ƒæ•°æ®é›†æ ¼å¼"""
        if not output_file:
            output_file = f"dialogue_training_dataset_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jsonl"
        
        output_path = self.output_dir / output_file
        training_samples = []
        
        # æ”¶é›†æ‰€æœ‰å¯¹è¯æ–‡ä»¶
        dialogue_files = list(self.output_dir.glob("batch_*.json"))
        
        for file_path in dialogue_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    batch_data = json.load(f)
                
                for dialogue in batch_data.get("dialogues", []):
                    character_type = dialogue["character_type"]
                    
                    # ä¸ºæ¯è½®å¯¹è¯åˆ›å»ºè®­ç»ƒæ ·æœ¬
                    conversation_history = []
                    
                    for turn in dialogue["turns"]:
                        # æ„å»ºå½“å‰å¯¹è¯ä¸Šä¸‹æ–‡
                        context = f"ä½ æ˜¯ä¸€ä¸ª{character_type}ç±»å‹çš„äºŒæ¬¡å…ƒè§’è‰²ã€‚" if not conversation_history else ""
                        
                        # æ·»åŠ å†å²å¯¹è¯
                        for hist in conversation_history:
                            context += f"ç”¨æˆ·: {hist['user']}\nè§’è‰²: {hist['character']}\n"
                        
                        # å½“å‰ç”¨æˆ·è¾“å…¥
                        context += f"ç”¨æˆ·: {turn['user']}\nè§’è‰²: "
                        
                        # åˆ›å»ºè®­ç»ƒæ ·æœ¬
                        training_sample = {
                            "instruction": context.strip(),
                            "output": turn["character"],
                            "input": "",
                            "character_type": character_type,
                            "scenario": dialogue["scenario"],
                            "turn_id": turn.get("turn", len(conversation_history) + 1)
                        }
                        
                        training_samples.append(training_sample)
                        
                        # æ›´æ–°å¯¹è¯å†å²
                        conversation_history.append({
                            "user": turn["user"],
                            "character": turn["character"]
                        })
                        
                        # é™åˆ¶å†å²é•¿åº¦ï¼Œé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿
                        if len(conversation_history) > 3:
                            conversation_history = conversation_history[-3:]
            
            except Exception as e:
                logger.error(f"å¤„ç†å¯¹è¯æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        # ä¿å­˜è®­ç»ƒæ•°æ®é›†
        with open(output_path, 'w', encoding='utf-8') as f:
            for sample in training_samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        
        logger.info(f"è®­ç»ƒæ•°æ®é›†å·²ç”Ÿæˆ: {output_path}")
        logger.info(f"æ€»æ ·æœ¬æ•°: {len(training_samples)}")
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self._generate_dataset_report(training_samples, output_path.with_suffix('.report.json'))
        
        return str(output_path)
    
    def _generate_dataset_report(self, samples: List[Dict], report_path: Path):
        """ç”Ÿæˆæ•°æ®é›†ç»Ÿè®¡æŠ¥å‘Š"""
        from collections import Counter
        
        char_type_dist = Counter(sample["character_type"] for sample in samples)
        scenario_dist = Counter(sample["scenario"] for sample in samples)
        
        report = {
            "dataset_info": {
                "total_samples": len(samples),
                "generated_at": datetime.now().isoformat(),
                "character_type_distribution": dict(char_type_dist),
                "scenario_distribution": dict(scenario_dist)
            },
            "quality_metrics": {
                "avg_output_length": sum(len(s["output"]) for s in samples) / len(samples),
                "avg_context_length": sum(len(s["instruction"]) for s in samples) / len(samples),
                "unique_outputs": len(set(s["output"] for s in samples))
            },
            "generation_stats": self.generation_stats
        }
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
    
    def print_stats(self):
        """æ‰“å°ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        duration = datetime.now() - self.generation_stats["start_time"]
        
        print("\n" + "="*50)
        print("ğŸ“Š å¯¹è¯ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š")
        print("="*50)
        print(f"â±ï¸  è¿è¡Œæ—¶é—´: {duration}")
        print(f"âœ… æˆåŠŸç”Ÿæˆ: {self.generation_stats['successful']}")
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {self.generation_stats['failed']}")
        print(f"ğŸš« è´¨é‡è¿‡æ»¤: {self.generation_stats['filtered_out']}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        print("="*50)

def create_generation_plan(
    num_dialogues_per_character: int = 50,
    num_turns_range: tuple = (3, 8),
    scenarios_per_character: int = None
) -> List[DialogueConfig]:
    """åˆ›å»ºå¯¹è¯ç”Ÿæˆè®¡åˆ’"""
    
    configs = []
    generator = DialogueGenerator()
    
    for char_type in generator.character_types.keys():
        char_scenarios = []
        
        # æ”¶é›†è¯¥è§’è‰²é€‚åˆçš„åœºæ™¯
        for scenario_category, scenario_list in generator.scenarios.items():
            if scenarios_per_character:
                selected = random.sample(scenario_list, min(scenarios_per_character, len(scenario_list)))
            else:
                selected = scenario_list
            
            for scenario in selected:
                char_scenarios.append(f"{scenario_category}-{scenario}")
        
        # ä¸ºæ¯ä¸ªè§’è‰²ç”Ÿæˆå¤šä¸ªå¯¹è¯é…ç½®
        for i in range(num_dialogues_per_character):
            config = DialogueConfig(
                character_type=char_type,
                scenario=random.choice(char_scenarios),
                num_turns=random.randint(*num_turns_range),
                temperature=random.uniform(0.7, 0.9)
            )
            configs.append(config)
    
    random.shuffle(configs)  # éšæœºæ‰“æ•£é¡ºåº
    return configs

async def main():
    parser = argparse.ArgumentParser(description="AIè‡ªåŠ¨ç”ŸæˆäºŒæ¬¡å…ƒå¯¹è¯æ•°æ®")
    parser.add_argument("--num_per_character", type=int, default=50, help="æ¯ä¸ªè§’è‰²ç”Ÿæˆçš„å¯¹è¯æ•°é‡")
    parser.add_argument("--min_turns", type=int, default=3, help="æœ€å°‘å¯¹è¯è½®æ•°")
    parser.add_argument("--max_turns", type=int, default=8, help="æœ€å¤šå¯¹è¯è½®æ•°")
    parser.add_argument("--output_dir", type=str, default="data/generated_dialogues", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--batch_size", type=int, default=20, help="æ‰¹å¤„ç†å¤§å°")
    parser.add_argument("--create_dataset", action="store_true", help="ç”Ÿæˆå®Œæˆååˆ›å»ºè®­ç»ƒæ•°æ®é›†")
    parser.add_argument("--config_file", type=str, default="config/api_config.json", help="APIé…ç½®æ–‡ä»¶")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = DialogueGenerator(args.config_file)
    generator.output_dir = Path(args.output_dir)
    generator.output_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºç”Ÿæˆè®¡åˆ’
    configs = create_generation_plan(
        num_dialogues_per_character=args.num_per_character,
        num_turns_range=(args.min_turns, args.max_turns)
    )
    
    logger.info(f"ğŸ“‹ ç”Ÿæˆè®¡åˆ’: {len(configs)} ä¸ªå¯¹è¯")
    logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {generator.output_dir}")
    
    # åˆ†æ‰¹ç”Ÿæˆ
    for i in range(0, len(configs), args.batch_size):
        batch_configs = configs[i:i + args.batch_size]
        batch_name = f"batch_{i//args.batch_size + 1:03d}"
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹æ¬¡ {batch_name}: {len(batch_configs)} ä¸ªå¯¹è¯")
        await generator.generate_batch_dialogues(batch_configs, batch_name)
        
        # é¿å…APIé¢‘ç‡é™åˆ¶
        await asyncio.sleep(2)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    generator.print_stats()
    
    # åˆ›å»ºè®­ç»ƒæ•°æ®é›†
    if args.create_dataset:
        logger.info("ğŸ“¦ æ­£åœ¨åˆ›å»ºè®­ç»ƒæ•°æ®é›†...")
        dataset_path = generator.create_training_dataset()
        print(f"âœ… è®­ç»ƒæ•°æ®é›†å·²ä¿å­˜: {dataset_path}")

if __name__ == "__main__":
    asyncio.run(main()) 