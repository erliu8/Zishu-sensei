#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import argparse
import random
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

def load_anime_data(bangumi_dir: Path) -> List[Dict[str, Any]]:
    """åŠ è½½æ‰€æœ‰åŠ¨ç”»æ•°æ®æ–‡ä»¶"""
    all_anime = []
    
    # åŠ è½½æ‰€æœ‰åŠ¨ç”»JSONæ–‡ä»¶
    anime_files = [
        "anime_top_tier.json",
        "anime_high_quality.json", 
        "anime_good_quality.json",
        "anime_decent_quality.json",
        "anime_watchable.json"
    ]
    
    for filename in anime_files:
        file_path = bangumi_dir / filename
        if file_path.exists():
            print(f"ğŸ“ åŠ è½½æ–‡ä»¶: {filename}")
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                all_anime.extend(data)
                print(f"   - åŠ è½½ {len(data)} éƒ¨åŠ¨ç”»")
    
    print(f"ğŸ¬ æ€»è®¡åŠ è½½ {len(all_anime)} éƒ¨åŠ¨ç”»")
    return all_anime

def create_training_conversations(anime_data: List[Dict[str, Any]]) -> List[Dict[str, str]]:
    """å°†åŠ¨ç”»æ•°æ®è½¬æ¢ä¸ºè®­ç»ƒå¯¹è¯æ ¼å¼"""
    conversations = []
    
    # å®šä¹‰å„ç§é—®é¢˜æ¨¡æ¿
    question_templates = {
        "introduction": [
            "ä»‹ç»ä¸€ä¸‹åŠ¨ç”»ã€Š{name}ã€‹",
            "ã€Š{name}ã€‹è¿™éƒ¨åŠ¨ç”»æ€ä¹ˆæ ·ï¼Ÿ", 
            "èƒ½å‘Šè¯‰æˆ‘ã€Š{name}ã€‹çš„æ•…äº‹å—ï¼Ÿ",
            "ã€Š{name}ã€‹è®²çš„æ˜¯ä»€ä¹ˆï¼Ÿ",
            "è¯·è¯¦ç»†ä»‹ç»ã€Š{name}ã€‹"
        ],
        "rating": [
            "ã€Š{name}ã€‹è¯„åˆ†å¤šå°‘ï¼Ÿ",
            "ã€Š{name}ã€‹çš„è¯„ä»·å¦‚ä½•ï¼Ÿ",
            "ã€Š{name}ã€‹å€¼å¾—çœ‹å—ï¼Ÿ",
            "ã€Š{name}ã€‹è´¨é‡æ€ä¹ˆæ ·ï¼Ÿ"
        ],
        "genre": [
            "ã€Š{name}ã€‹æ˜¯ä»€ä¹ˆç±»å‹çš„åŠ¨ç”»ï¼Ÿ",
            "ã€Š{name}ã€‹å±äºå“ªä¸ªåˆ†ç±»ï¼Ÿ",
            "ã€Š{name}ã€‹æœ‰ä»€ä¹ˆæ ‡ç­¾ï¼Ÿ",
            "ã€Š{name}ã€‹çš„é£æ ¼æ˜¯ä»€ä¹ˆï¼Ÿ"
        ],
        "recommendation": [
            "æ¨èä¸€äº›ç±»ä¼¼ã€Š{name}ã€‹çš„åŠ¨ç”»",
            "è¿˜æœ‰ä»€ä¹ˆå’Œã€Š{name}ã€‹é£æ ¼ç›¸è¿‘çš„ä½œå“ï¼Ÿ",
            "å–œæ¬¢ã€Š{name}ã€‹çš„è¯è¿˜èƒ½çœ‹ä»€ä¹ˆï¼Ÿ"
        ],
        "year": [
            "ã€Š{name}ã€‹æ˜¯å“ªä¸€å¹´çš„ä½œå“ï¼Ÿ",
            "ã€Š{name}ã€‹ä»€ä¹ˆæ—¶å€™æ’­å‡ºçš„ï¼Ÿ",
            "ã€Š{name}ã€‹çš„ä¸Šæ˜ æ—¶é—´ï¼Ÿ"
        ]
    }
    
    for anime in anime_data:
        name = anime.get('name_cn') or anime.get('name', '')
        if not name or not anime.get('summary'):
            continue
            
        score = anime.get('score', 0)
        tags = anime.get('tags', [])
        date = anime.get('date', '')
        summary = anime.get('summary', '').strip()
        
        # é™åˆ¶æ‘˜è¦é•¿åº¦
        if len(summary) > 300:
            summary = summary[:300] + "..."
        
        year = date[:4] if date and len(date) >= 4 else "æœªçŸ¥"
        
        # 1. åŸºæœ¬ä»‹ç»å¯¹è¯
        for template in question_templates["introduction"]:
            question = template.format(name=name)
            
            # æ„é€ å›ç­”
            answer_parts = [f"ã€Š{name}ã€‹æ˜¯ä¸€éƒ¨"]
            
            if score >= 8.5:
                answer_parts.append("éå¸¸ä¼˜ç§€çš„")
            elif score >= 8.0:
                answer_parts.append("é«˜è´¨é‡çš„")
            elif score >= 7.5:
                answer_parts.append("ä¸é”™çš„")
            else:
                answer_parts.append("")
            
            # æ·»åŠ ç±»å‹ä¿¡æ¯
            if tags:
                genre_tags = [tag for tag in tags if tag in ['ç§‘å¹»', 'å¥‡å¹»', 'æç¬‘', 'æ²»æ„ˆ', 'æˆ˜æ–—', 'æ‹çˆ±', 'æ—¥å¸¸', 'çƒ­è¡€']]
                if genre_tags:
                    answer_parts.append(f"{genre_tags[0]}ç±»")
            
            answer_parts.append(f"åŠ¨ç”»ï¼Œè¯„åˆ†{score}/10ã€‚")
            
            if year != "æœªçŸ¥":
                answer_parts.append(f"äº{year}å¹´æ’­å‡ºã€‚")
            
            if summary:
                answer_parts.append(f"\n\nå‰§æƒ…ç®€ä»‹ï¼š{summary}")
            
            conversations.append({
                "text": f"ç”¨æˆ·: {question}\n\nåŠ©æ‰‹: {''.join(answer_parts)}"
            })
        
        # 2. è¯„åˆ†ç›¸å…³å¯¹è¯
        if score > 0:
            for template in question_templates["rating"]:
                question = template.format(name=name)
                
                if score >= 9.0:
                    quality = "ç¥ä½œçº§åˆ«"
                elif score >= 8.5:
                    quality = "éå¸¸ä¼˜ç§€"
                elif score >= 8.0:
                    quality = "é«˜è´¨é‡"
                elif score >= 7.5:
                    quality = "ç›¸å½“ä¸é”™"
                elif score >= 7.0:
                    quality = "è¿˜ç®—å¯ä»¥"
                else:
                    quality = "ä¸€èˆ¬"
                
                answer = f"ã€Š{name}ã€‹çš„è¯„åˆ†æ˜¯ {score}/10ï¼Œå±äº{quality}çš„ä½œå“ã€‚"
                
                conversations.append({
                    "text": f"ç”¨æˆ·: {question}\n\nåŠ©æ‰‹: {answer}"
                })
        
        # 3. ç±»å‹/é£æ ¼å¯¹è¯
        if tags:
            for template in question_templates["genre"]:
                question = template.format(name=name)
                
                # è¿‡æ»¤å’Œåˆ†ç±»æ ‡ç­¾
                genre_tags = []
                format_tags = []
                other_tags = []
                
                for tag in tags[:6]:  # åªå–å‰6ä¸ªæ ‡ç­¾
                    if tag in ['TV', 'å‰§åœºç‰ˆ', 'OVA', 'WEB']:
                        format_tags.append(tag)
                    elif tag in ['ç§‘å¹»', 'å¥‡å¹»', 'æç¬‘', 'æ²»æ„ˆ', 'æˆ˜æ–—', 'æ‹çˆ±', 'æ—¥å¸¸', 'çƒ­è¡€', 'æ‚¬ç–‘', 'ææ€–']:
                        genre_tags.append(tag)
                    else:
                        other_tags.append(tag)
                
                answer_parts = [f"ã€Š{name}ã€‹"]
                
                if format_tags:
                    answer_parts.append(f"æ˜¯ä¸€éƒ¨{format_tags[0]}åŠ¨ç”»")
                
                if genre_tags:
                    answer_parts.append(f"ï¼Œç±»å‹åŒ…æ‹¬ï¼š{', '.join(genre_tags)}")
                
                if other_tags:
                    answer_parts.append(f"ã€‚ç›¸å…³æ ‡ç­¾æœ‰ï¼š{', '.join(other_tags[:3])}")
                
                conversations.append({
                    "text": f"ç”¨æˆ·: {question}\n\nåŠ©æ‰‹: {''.join(answer_parts)}ã€‚"
                })
        
        # 4. å¹´ä»£å¯¹è¯
        if year != "æœªçŸ¥":
            for template in question_templates["year"]:
                question = template.format(name=name)
                answer = f"ã€Š{name}ã€‹æ˜¯{year}å¹´çš„ä½œå“ã€‚"
                
                conversations.append({
                    "text": f"ç”¨æˆ·: {question}\n\nåŠ©æ‰‹: {answer}"
                })
    
    return conversations

def create_genre_recommendations(anime_data: List[Dict[str, Any]]) -> List[Dict[str, str]]:
    """åˆ›å»ºåŸºäºç±»å‹çš„æ¨èå¯¹è¯"""
    conversations = []
    
    # æŒ‰ç±»å‹åˆ†ç»„
    genre_groups = {}
    for anime in anime_data:
        name = anime.get('name_cn') or anime.get('name', '')
        if not name:
            continue
            
        tags = anime.get('tags', [])
        score = anime.get('score', 0)
        
        for tag in ['ç§‘å¹»', 'å¥‡å¹»', 'æç¬‘', 'æ²»æ„ˆ', 'æˆ˜æ–—', 'æ‹çˆ±', 'æ—¥å¸¸', 'çƒ­è¡€']:
            if tag in tags and score >= 7.0:
                if tag not in genre_groups:
                    genre_groups[tag] = []
                genre_groups[tag].append({
                    'name': name,
                    'score': score
                })
    
    # ç”Ÿæˆæ¨èå¯¹è¯
    genre_questions = [
        "æ¨èä¸€äº›{genre}ç±»çš„åŠ¨ç”»",
        "æœ‰ä»€ä¹ˆå¥½çœ‹çš„{genre}åŠ¨ç”»ï¼Ÿ",
        "èƒ½æ¨èå‡ éƒ¨{genre}ä½œå“å—ï¼Ÿ",
        "{genre}ç±»åŠ¨ç”»æœ‰å“ªäº›ç»å…¸ï¼Ÿ"
    ]
    
    for genre, anime_list in genre_groups.items():
        if len(anime_list) < 3:  # è‡³å°‘è¦æœ‰3éƒ¨æ‰æ¨è
            continue
            
        # æŒ‰è¯„åˆ†æ’åºï¼Œå–å‰5éƒ¨
        anime_list.sort(key=lambda x: x['score'], reverse=True)
        top_anime = anime_list[:5]
        
        for template in genre_questions:
            question = template.format(genre=genre)
            
            recommendations = []
            for i, anime in enumerate(top_anime, 1):
                recommendations.append(f"{i}. ã€Š{anime['name']}ã€‹(è¯„åˆ†: {anime['score']})")
            
            answer = f"ä»¥ä¸‹æ˜¯ä¸€äº›ä¼˜ç§€çš„{genre}ç±»åŠ¨ç”»æ¨èï¼š\n\n" + "\n".join(recommendations)
            
            conversations.append({
                "text": f"ç”¨æˆ·: {question}\n\nåŠ©æ‰‹: {answer}"
            })
    
    return conversations

def create_general_conversations() -> List[Dict[str, str]]:
    """åˆ›å»ºä¸€èˆ¬æ€§åŠ¨ç”»ç›¸å…³å¯¹è¯"""
    general_conversations = [
        {
            "text": "ç”¨æˆ·: ä½ äº†è§£åŠ¨ç”»å—ï¼Ÿ\n\nåŠ©æ‰‹: æ˜¯çš„ï¼Œæˆ‘å¯¹åŠ¨ç”»æœ‰æ¯”è¾ƒæ·±å…¥çš„äº†è§£ã€‚æˆ‘çš„çŸ¥è¯†åº“åŒ…å«äº†å¤§é‡çš„åŠ¨ç”»ä½œå“ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç»å…¸è€ç•ªã€çƒ­é—¨æ–°ç•ªã€ä»¥åŠå„ç§ç±»å‹çš„åŠ¨ç”»ã€‚æ— è®ºæ˜¯æƒ³äº†è§£æŸéƒ¨å…·ä½“ä½œå“ï¼Œè¿˜æ˜¯éœ€è¦åŠ¨ç”»æ¨èï¼Œæˆ‘éƒ½å¾ˆä¹æ„å¸®åŠ©æ‚¨ã€‚"
        },
        {
            "text": "ç”¨æˆ·: ä»€ä¹ˆæ˜¯é«˜åˆ†åŠ¨ç”»ï¼Ÿ\n\nåŠ©æ‰‹: é«˜åˆ†åŠ¨ç”»é€šå¸¸æŒ‡è¯„åˆ†åœ¨8.0ä»¥ä¸Šçš„ä½œå“ã€‚è¿™äº›åŠ¨ç”»åœ¨å‰§æƒ…ã€ç”»é¢ã€éŸ³ä¹ã€å£°ä¼˜è¡¨ç°ç­‰æ–¹é¢éƒ½æ¯”è¾ƒä¼˜ç§€ï¼Œè·å¾—äº†è§‚ä¼—å’Œè¯„è®ºå®¶çš„ä¸€è‡´å¥½è¯„ã€‚æ¯”å¦‚è¯„åˆ†9.0+çš„ç¥ä½œçº§åŠ¨ç”»ï¼Œå¾€å¾€å…·æœ‰æ·±åˆ»çš„å†…æ¶µã€ç²¾è‰¯çš„åˆ¶ä½œå’ŒæŒä¹…çš„å½±å“åŠ›ã€‚"
        },
        {
            "text": "ç”¨æˆ·: åŠ¨ç”»æœ‰å“ªäº›ç±»å‹ï¼Ÿ\n\nåŠ©æ‰‹: åŠ¨ç”»å¯ä»¥æŒ‰å¤šç§æ–¹å¼åˆ†ç±»ï¼š\n\n1. æ’­å‡ºå½¢å¼ï¼šTVåŠ¨ç”»ã€å‰§åœºç‰ˆã€OVAã€WEBåŠ¨ç”»\n2. é¢˜æç±»å‹ï¼šç§‘å¹»ã€å¥‡å¹»ã€æ‹çˆ±ã€æç¬‘ã€æ²»æ„ˆã€æˆ˜æ–—ã€æ‚¬ç–‘ç­‰\n3. ç›®æ ‡å—ä¼—ï¼šå­ä¾›å‘ã€å°‘å¹´å‘ã€å°‘å¥³å‘ã€æˆäººå‘\n4. åˆ¶ä½œåœ°åŒºï¼šæ—¥æœ¬åŠ¨ç”»ã€å›½äº§åŠ¨ç”»ã€æ¬§ç¾åŠ¨ç”»ç­‰\n\næ¯ç§ç±»å‹éƒ½æœ‰å…¶ç‹¬ç‰¹çš„é­…åŠ›å’Œå—ä¼—ç¾¤ä½“ã€‚"
        }
    ]
    
    return general_conversations

def split_data(conversations: List[Dict[str, str]], train_ratio=0.8, val_ratio=0.1, seed=42):
    """åˆ†å‰²æ•°æ®ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†"""
    random.seed(seed)
    random.shuffle(conversations)
    
    total = len(conversations)
    train_size = int(total * train_ratio)
    val_size = int(total * val_ratio)
    
    return {
        "train": conversations[:train_size],
        "validation": conversations[train_size:train_size + val_size],
        "test": conversations[train_size + val_size:]
    }

def main():
    parser = argparse.ArgumentParser(description="å¤„ç† Bangumi åŠ¨ç”»æ•°æ®ç”¨äºè®­ç»ƒ")
    parser.add_argument("--bangumi_dir", type=str, default="./data/raw/bangumi", help="Bangumiæ•°æ®ç›®å½•")
    parser.add_argument("--output_dir", type=str, default="./data/train", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--max_conversations", type=int, default=10000, help="æœ€å¤§å¯¹è¯æ•°é‡")
    parser.add_argument("--date_suffix", type=str, default=None, help="æ—¥æœŸåç¼€ï¼Œæ ¼å¼å¦‚ 06082025ï¼Œé»˜è®¤ä½¿ç”¨å½“å‰æ—¥æœŸ")
    
    args = parser.parse_args()
    
    # ç”Ÿæˆæ—¥æœŸåç¼€
    if args.date_suffix:
        date_suffix = args.date_suffix
    else:
        # ä½¿ç”¨å½“å‰æ—¥æœŸï¼Œæ ¼å¼: MMDDYYYY
        now = datetime.now()
        date_suffix = now.strftime("%m%d%Y")
    
    # åˆ›å»ºå¸¦æ—¥æœŸçš„è¾“å‡ºç›®å½•
    base_output_dir = Path(args.output_dir)
    output_dir = base_output_dir / f"bangumi_{date_suffix}"
    bangumi_dir = Path(args.bangumi_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("ğŸŒ å¼€å§‹å¤„ç† Bangumi åŠ¨ç”»æ•°æ®...")
    print(f"ğŸ“… ä½¿ç”¨æ—¥æœŸåç¼€: {date_suffix}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # åŠ è½½åŠ¨ç”»æ•°æ®
    anime_data = load_anime_data(bangumi_dir)
    
    if not anime_data:
        print("âŒ æœªæ‰¾åˆ°åŠ¨ç”»æ•°æ®ï¼")
        return
    
    # ç”Ÿæˆè®­ç»ƒå¯¹è¯
    print("ğŸ’­ ç”ŸæˆåŸºç¡€å¯¹è¯...")
    basic_conversations = create_training_conversations(anime_data)
    print(f"   - ç”Ÿæˆ {len(basic_conversations)} æ¡åŸºç¡€å¯¹è¯")
    
    print("ğŸ¯ ç”Ÿæˆæ¨èå¯¹è¯...")
    recommendation_conversations = create_genre_recommendations(anime_data)
    print(f"   - ç”Ÿæˆ {len(recommendation_conversations)} æ¡æ¨èå¯¹è¯")
    
    print("ğŸŒŸ æ·»åŠ é€šç”¨å¯¹è¯...")
    general_conversations = create_general_conversations()
    print(f"   - æ·»åŠ  {len(general_conversations)} æ¡é€šç”¨å¯¹è¯")
    
    # åˆå¹¶æ‰€æœ‰å¯¹è¯
    all_conversations = basic_conversations + recommendation_conversations + general_conversations
    
    # é™åˆ¶æ•°é‡å¹¶éšæœºé‡‡æ ·
    if len(all_conversations) > args.max_conversations:
        random.shuffle(all_conversations)
        all_conversations = all_conversations[:args.max_conversations]
    
    print(f"ğŸ“Š æ€»å¯¹è¯æ•°: {len(all_conversations)}")
    
    # åˆ†å‰²æ•°æ®
    split_datasets = split_data(all_conversations)
    
    # ä¿å­˜æ•°æ®
    for split_name, data in split_datasets.items():
        output_file = output_dir / f"bangumi_{split_name}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"âœ… {split_name}é›†å·²ä¿å­˜: {output_file} ({len(data)} æ¡)")
    
    # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    stats = {
        "date_suffix": date_suffix,
        "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "total_anime": len(anime_data),
        "total_conversations": len(all_conversations),
        "train_size": len(split_datasets["train"]),
        "validation_size": len(split_datasets["validation"]),
        "test_size": len(split_datasets["test"]),
        "data_sources": [
            "anime_top_tier.json",
            "anime_high_quality.json", 
            "anime_good_quality.json",
            "anime_decent_quality.json",
            "anime_watchable.json"
        ]
    }
    
    stats_file = output_dir / "bangumi_stats.json"
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜: {stats_file}")
    print(f"ğŸ‰ Bangumi æ•°æ®å¤„ç†å®Œæˆï¼è¾“å‡ºç›®å½•: {output_dir}")

if __name__ == "__main__":
    main() 